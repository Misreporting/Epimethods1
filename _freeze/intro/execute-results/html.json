{
  "hash": "b82a5c855546f93c5fd4c1aebc94b55f",
  "result": {
    "markdown": "# Introduction: Types of studies\n\nThis is a book created from markdown and executable code.\n\nSee @knuth84 for additional discussion of literate programming.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 + 1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n:::\n\n\nEpidemiology research uses different types of research designs to test hypotheses. Once you understand the types of research design, you can understand which designs are possible to test specific hypotheses. You can also make educated guesses about the type of research design, likely data sources, and potential limitations when you hear a study described in the mass media.\n\nFurther these types of research designs are limited to epidemiology. A range of quantitative social sciences use designs with similar structure. For example, just as you can do a case-control study to understand potential causes of a disease, you can use the exact same research design in the field of education to understand potential causes of not graduating from college. Even though these are very different fields of academia studying diseases and studying college completion, many techniques transfer between all quantitative social sciences.\n\nAs another example, just as you can do a cohort study to understand the association between a health exposure and a health outcome, you can do a similar type of study tThe silo ino understand any exposure and any outcome: for example, not graduating college could be an exposure of interest in a cohort study.\n\nUnfortunately, quantitative social scientists often remain siloed in their departments or even on different campuses of the same university. Epidemiology and biostatistics departments may be in a school of public health on a medical campus, whereas statistics, economics, and sociology departments, schools of education, and other social scientists may not be at the same campus or even at the same university. On my campus, I am on a medical campus at a university that only has health sciences fields. We have no schools of arts and sciences, education, or government. By contrast, I was educated in a PhD program in a school of arts and sciences where I took courses in economics, psychology, and statistics, as well as at the school of public health across the river.\n\nYou may be in a similar situation and you may also be in social sciences for the first time. Many people come to epidemiology after deciding that public health will let them have a bigger impact on the world than medicine or biosciences would, and their undergraduate educations may have been primarily in lab sciences with limited exposure to advanced quantitative social science research methods.\n\nI am writing this book to fill a lacuna that I have noticed in epidemiology and research methods textbooks: this book concentrates on the competencies for an intermediate epidemiology methods course while integrating that perspective within the full range of quantitative social sciences. Many quantitative social science textbooks are written for economists, political scientists, and sociologists, and they use a wide variety of studies from these areas. Meanwhile, many statistics textbooks use examples from social science fields, biology, and astrophysics.\n\nIn contrast, epidemiology textbooks focus on a more narrow range of research and data. My goal with this book is to write an intermediate epidemiology research methdos book with a perspective recognizable to quantitative social scientists.\n\nI have taught from books certain by economists and psychologists and statisticians that my students have really enjoyed, but I know that my students most enjoy examples that are clearly from epidemiology itself and with that perspective.\n\n## Pretest\n\nTake a few moments to check your memory of different research designs from introductory epidemiology. I've included some example answers.\n\n| Types of study           | Advantages                          | Limitations                 |\n|:------------------|:---------------------------------|:-----------------|\n| Case study               | Can describe a rare condition       |                             |\n| Case series              | Implicit comparison with population | May highlight wrong feature |\n| Descriptive rate-based   | Can observe trends                  |                             |\n| Pre-post, no control     |                                     |                             |\n| Cross sectional          |                                     |                             |\n| Prospective cohort       |                                     |                             |\n| Retrospective cohort     |                                     |                             |\n| Case-control             |                                     |                             |\n| Ecological               |                                     |                             |\n| Randomized experiment    |                                     |                             |\n| Natural/quasi-experiment |                                     |                             |\n\n## Introduction\n\nStudies vary by:\n\n-   Unit of analysis: individual (above designs) versus population (ecological).\n\n-   Whether researcher assigns participants to the treatment or not.\n\n-   Whether participants are observed prospectively or not\n\n-   Whether all data comes from a single time point.\n\n-   Whether the primary grouping of participants is by exposure or by disease/outcome.\n\n-   Whether they test hypothesis: Descriptive (does not test hypotheses) versus analytic (tests hypotheses).\n\nA study of large entities (countries or counties) is ecological. Intermediate units of analysis may be either type of study. Examples: schools. Could do an ecological study of schools (e.g., compare test scores versus teacher-student ratio) or an experiment on schools (e.g., hire more teachers at schools in the treatment group, do nothing for control group, and observe test scores as the outcome.)\n\nDefinition: Here I use three terms to be synonymous: treatment, exposure status, and main predictor. \\`Treatment' is shorter, and I use it in quotes to indicate that it can be either assigned randomly or not.\n\nIn non-random studies, statistical methods can still allow causal inference.\n\n-   Instrumental variables: control for a factor that predicts both \\`treatment' and outcome.\n\n-   Propensity matching methods: propensity score weighting/matching, nearest-neighbor matching. Balance treatment and control groups so that only differences remaining between the two groups (treated and control) is their treatment status in an attempt to replicate the assignment mechanism to treatment versus control.\n\n-   Quasi-experiments are also sometimes called natural experiments. e.g., New York's calorie menu labeling requirement, compared with neighboring states.\n\n## Suggested answers\n\nYour answers may vary but here are some suggested answers to the quiz.\n\n| Types of study           | Advantages                           | Limitations                                         |\n|:-------------------------|:------------------------|:---------------------|\n| Case study               | Can describe a rare condition        |                                                     |\n| Case series              | Implicit comparison with population  | May highlight wrong feature                         |\n| Descriptive rate-based   | Can observe trends                   | Causality unclear                                   |\n|                          |                                      | Does not test hypotheses                            |\n| Pre-post, no control     | Can do something                     | No comparison group                                 |\n|                          | Politically easier to treat all.     | Conclusions may be incorrect.                       |\n| Cross sectional          | Data easier to find.                 | No temporal ordering.                               |\n|                          | Inexpensive.                         | Potential confounding.                              |\n| Prospective cohort       | Establishes temporal sequence.       | Self-selection/confounding limits causal inference. |\n|                          |                                      | Need to wait for disease to emerge.                 |\n|                          |                                      | Only possible for common diseases.                  |\n| Retrospective cohort     | May establish temporal sequence      | Self-selection/confounding.                         |\n|                          |                                      | Exposure status may not be accurate.                |\n|                          |                                      | Temporal sequence may not be accurate.              |\n| Case-control             | Can examine many factors.            | False significance (multiple comparisons)           |\n|                          | Useful to generate hypotheses.       | Comparison group validity.                          |\n|                          | Quick; disease already emerged.      | Measures often retrospective.                       |\n|                          | Can study rare diseases.             |                                                     |\n| Ecological               | Useful for system-level differences. | No individual-level conclusions.                    |\n|                          |                                      | Useful first step in research.                      |\n| Randomized experiment    | Causal inference.                    | Limited to tested intervention.                     |\n|                          | Can falsify initial hypotheses.      | May test \\`\\`wrong'' intervention.                  |\n|                          |                                      | Time-consuming and expensive.                       |\n| Natural/quasi-experiment | Almost as good as RCT.               | Rare and hard to identify.                          |\n|                          |                                      | Discovered rather than designed.                    |\n\n## Example case study: Should I drink more coffee?\n\nObservational evidence suggests that coffee predicts lower mortality and morbidity from a variety of diseases. Is the evidence sufficient to suggest that people should drink more coffee? How do we figure that out?\n\nOne difference you might notice when we think about the personal decisions that individuals make about their health behaviors is that individuals want good outcomes, broadly speaking. Usually when individuals take actions to try to improve their health, they're not picky about which good health outcomes results from their new health behavior. By contrast, research always has specific outcomes. These outcomes can be very specific.\n\nWhen the concern is long-term outcomes, individuals don't even know which outcomes result from which health behaviors because they don't know the counterfactuals: the outcomes in the case that they had different exposures.\n\nBecause of the difference between how individuals and reserachers talk about the effects of health behaviors and exposures, there can be a disconnect. Individuals have the question does this health behavior work? In research, that's too vague of a question.\n\nIn best practice, these outcomes are pre-specified: that is, before anybody started the research, they write down which hypotheses they plan to test. The reason it's so important to pre-specify your hypothesis is that we want research to be replicable. Many have made the analogy between research andarchery. In archery, we shoot an arrow at the center of a target that already exists; if we hit the center of the target, that suggests that we have a good chance of likewise hitting near the center of future targets under similar conditions. In other words, hitting a target with an arrow is replicable. Shooting an arrow and then drawing a target around where the arrow landed is not replicable: it doesn't demonstrate that you would be able to shoot the arrow at the target.\n\nA 1981 case-control study found an association between coffee and pancreatic cancer. Many other studies have found an association between coffee and reduced morbidity and mortality. So which direction is right? Is coffee likely to lead to better outcomes? Or is coffee likely lead to worse outcomes? Or do we just not know? How much evidence is there and what quality of evidence is there? How certain are we? How much confidence do we have in these results?\n\nWe can think about the types of studies that might be done. A case control study takes people who have a specific disease and compares them with similar people who don't have that disease. This type of study compares people with and without the disease to see which exposures are associated with the disease.\n\nA cohort study or a longitudinal study follows people over time to see which exposures they have and then sees which diseases they develop. If we think about what types of study might collect information about coffee drinking, we can see why it might be so challenging to study the effect of coffee drinking on long-term outcomes.\n\nThere is a national study called the national health and nutrition examination study or NHANES that asks people about all the different things that they eat and drink. It also does some lab studies and examinations like taking blood samples and urine samples. Then the federal researchers that run the NHANES study link it up with death records. This is one source of data that might have coffee drinking recorded and then later on have death and cause of death recorded. These data already exist, and you could actually go right now and look for these data and conduct the study.\n\n## Evidence-based health behaviors: example of yoga\n\nThe long-term effects of coffee drinking have been studied reasonably thoroughly. Other health behaviors may have sparser research.\n\nIf I take up yoga, and I find that I feel generally happier, I'll probably feel satisfied with my decision even if I have no measurable differences in any other health metric or disease risk.\n\nHealth practices like yoga could be qualitatively beneficial even in the absence of quantitative evidence that they improve specific health outcomes. Because of the way that we do research about health, each one of the possible outcomes of yoga might be studied entirely separately. For example, researchers might want to know whether yoga reduces the number of months it takes to conceive a pregnancy, reduces systolic blood pressure, reduces depression as measured by the score on a depression screening survey, or decreases sleep latency, the number of minutes it takes to fall asleep as measured by a specific device. These are all super concrete outcomes. Further, although there is one part of the national institutes of health that studies complementary medicine such as yoga, researchers might apply for funding for these outcomes from entirely different parts of the national institutes of health or similar research funding bodies.\n\nUsing observational data, we can study health behaviors like yoga, but then we need to evaluate selection into these behaviors. People who do yoga are different from people who don't.\n\n## Another example: kidney stones and roller coasters\n\nKidney stones are painful and require expensive intervention to clear if they don't pass while small. A urologist noticed that many patients who rode roller coasters seemed to pass kidney stones and not need intervention, so he devised a model kidney filled with kidney stones and his own urine and brought it to Disney World to ride a roller coaster. He noticed that the kidney stones passed more often when he was in the back of the roller coaster than in the front. He will use this information to design a randomized controlled trial to test the hypothesis that riding roller coasters helps people to pass kidney stones. Whether or not roller coasters are the next treatment for kidney stones would depend on the results of the RCT.\n\nJames Hamblin, \\`\\`A Health Benefit of Roller Coasters'', Atlantic Monthly Sep 26, 2016 http://www.theatlantic.com/health/archive/2016/09/for-kidney-health-roller-coaster-therapy/501278/\n\n## Another example: Multitasking and electronic distractions\n\nThe research cited below comes was cited in slides by Andrew Mills of Otterbein University. Some of the research he cited came from a blog post by journalist Nicholas Carr (How Smartphones Hijack Our Minds, Wall Street Journal) that gave the sources of his WSJ article (http://www.roughtype.com/?p=8195) As students, you face distractions that I and most of your faculty instructors never faced. When I was in high school, one of my chief methods of procrastination was bending a paperclip and running it between the keys to pull up dust from the keyboard (true story!).\n\nIn this class, we can use laptops and phones for productive purposes: for learning statisical computations in R, for searching the research literature, for looking up the meaning of a term. However, the presence of a screen presents a distraction for everyone, both the users and those around them.(Sana, Weston, Cepeda, 2013, Laptop multitasking hinders classroom learning for both users and nearby peers https://doi.org/10.1016/j.compedu.2012.10.003) Screens reduce learning and retention of information, (Glass and Kang 2018, Dividing attention reduces exam performance. https://doi.org/10.1080/01443410.2018.1489046; Lauren M. Singer, Patricia A. Alexander 2017, Reading Across Mediums: Effects of Reading Digital and Print Texts on Comprehension and Calibration, J Experimental Education. https://doi.org/10.1080/00220973.2016.1143794) quality of notes, test performance, (Payne Carter, Greenberg, Walker, 2016 http://seii.mit.edu/wp-content/uploads/2016/05/SEII-Discussion-Paper-2016.02-Payne-Carter-Greenberg-and-Walker-2.pdf ) and distract others. I summarize the two studies that are most striking to me.\n\nResearchers at the US military academy performed an experiment in which one section of a class was allowed unlimited use of laptops/tablets (treatment) and the other were only permited tablets that were flat on the desk (control); the average final exam scores in the treatment group were 0.18 standard deviations lower than in the control group. (Payne Carter, Greenberg, Walker, 2016 http://seii.mit.edu/wp-content/uploads/2016/05/SEII-Discussion-Paper-2016.02-Payne-Carter-Greenberg-and-Walker-2.pdf )\n\nPsychologists performed experiments in which students were instructed to listen to a lecture, and a random subset were assigned to multitask during the lecture: that is, to perform tasks unrelated to the lecture during the lecture. Both students assigned to multitask and students who could see their screen them both performed worse in an exam on the content of the lecture than students assigned not to multitask and who could not see the screen of a multitasker. (Sana, Weston, Cepeda, 2013, Laptop multitasking hinders classroom learning for both users and nearby peers https://doi.org/10.1016/j.compedu.2012.10.003)\n\nPsychologists teaching two sections of the same course performed a randomized experiment, randomly assigning half of their class sessions to `no devices allowed'' or`devices permitted'' condtions: during the no device class sessions, proctors enforced the rule of not allowing devices. The experiment used a cross-over design, so that for each class session, one section of the class banned devices and the other allowed devices. Students allowed to use devices did not differ in their scores on in-class quizzes on the material presented in class than students who were not allowed to use devices in that class, but students allowed to use devices scored lower on midterm/final exams that were in later class sessions than students not allowed to use devices. Dividing attention bewteen a laptop/tablet/phone and a lecture did not reduce short-term retention of material but reduced long-term retention of material. (Glass and Kang 2018, Dividing attention reduces exam performance. https://doi.org/10.1080/01443410.2018.1489046)\n\nAn observational study of student use of their laptops in class found that 42% of the time students had open software that was unrelated to the course, and that students underestimated their multitasking behavior in the classroom (email and instant messaging, at the time) compared with the objective measures of multitasking observed by the researchers (Kraushaar, James M.; Novak, David C. Examining the Affects of Student Multitasking with Laptops during the Lecture, Journal of Information Systems Education, v21 n2 p241-251 2010 https://eric.ed.gov/?id=EJ893903)\n\nEducational psycholgists randomly assigned students to read texts on screens and in print in a cross-over experiment, and found that students performed better on tests of retention for the material that they read in print than on screens. (Lauren M. Singer, Patricia A. Alexander 2017, Reading Across Mediums: Effects of Reading Digital and Print Texts on Comprehension and Calibration, J Experimental Education.https://doi.org/10.1080/00220973.2016.1143794)\n\nResearchers randomly assigned participants to place their cell phones nearby in view, nearby out of view, or in another room. Participants assigned to have their phone in view had lower scores on various measures of memory and cognitive capacity than participants whose phones were in another room. However, irrespective of their phone's location, most participants reported that they did not think about their phone at all while performing the tasks, and they did not think their phone's location affected their performance. (Ward, Duke, Gneezy, Bos, \\`\\`Brain Drain: The Mere Presence of One's Own Smartphone Reduces Available Cognitive Capacity,'' Journal of the Association for Consumer Research, 2017.)\n\nThe educational research suggests that students have worse learning outcomes from using electronic devices in class, and that they are completely unaware of negative outcomes. However, these studies were not specific to computer-oriented classes. In this class, students may want to use laptops during some class sessions to follow along with the statistical commands. The research suggests to me that learning outcomes for everyone will be better if students put devices out of sight when they are not needed.\n\n## Professionalism\n\nInitiation into a professional identity with norms.\n\nPlay fair --- cite others; don't plagiarize.\n\n-   Copying others' words with minimal changes.\n\n-   Failing to cite others' ideas.\n\n-   Failure to use quotation marks for exact quotes (and exact quotes should almost never be used in scientific papers.)\n\nRespect others' time.\n\n-   Communicate clearly and efficiently. Refer to books on communication and always improve.\n\n-   No such thing as a final draft: revision is always possible.\n\n### Connecting with professional associations\n\nConnecting with professional associations as a student allows you to connect with others across the country/world, share research, get job and conference announcements, and experiment with professional identities at a low cost. You can connect through professional organizations through social networking websites such as Twitter and Facebook, by submitting to professional conferences, and by joining. In the past, SPH has generally paid students' costs to present at conferences.\n\n### Job resources\n\nBecome familiar with job listings before job search. Begin job search in August for June graduation: i.e., 10 months ahead. You can prepare job materials even before that, ideally the summer before graduation, especially for doctoral students.\n\n## Exercises\n\n### Binary classification tree\n\nMake a binary classification tree to distinguish between the following study types. Hand writing it will be easier than trying to make it on the computer. See example on next page.\n\n-   Randomized experiment. Also known as randomized controlled trial (RCT).\n\n-   Quasi-experiment. Also called a natural experiment, although they are not exactly synonymous.\n\n-   Retrospective/prospective cohort study.\n\n-   Case-control study.\n\n-   Cross-sectional study.\n\n-   Descriptive rate-based study.\n\n-   Pre-post study without control group.\n\n-   Ecological study\n\n### Epidemiology overview\n\nRead and prepare to discuss George Davey Smith and Shah Ebrahim, Epidemiology --- is it time to call it a day? Int. J. Epidemiol. (2001) 30 (1): 1--11. doi: 10.1093/ije/30.1.1.  http://ije.oxfordjournals.org/content/30/1/1.full\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}