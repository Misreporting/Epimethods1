[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Epidemiology Methods lecture notes",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2\n\n\nTypes of studies"
  },
  {
    "objectID": "intro.html#pretest",
    "href": "intro.html#pretest",
    "title": "1  Introduction: Types of studies",
    "section": "1.1 Pretest",
    "text": "1.1 Pretest\nTake a few moments to check your memory of different research designs from introductory epidemiology. I’ve included some example answers.\n\n\n\n\n\n\n\n\nTypes of study\nAdvantages\nLimitations\n\n\n\n\nCase study\nCan describe a rare condition\n\n\n\nCase series\nImplicit comparison with population\nMay highlight wrong feature\n\n\nDescriptive rate-based\nCan observe trends\n\n\n\nPre-post, no control\n\n\n\n\nCross sectional\n\n\n\n\nProspective cohort\n\n\n\n\nRetrospective cohort\n\n\n\n\nCase-control\n\n\n\n\nEcological\n\n\n\n\nRandomized experiment\n\n\n\n\nNatural/quasi-experiment"
  },
  {
    "objectID": "intro.html#introduction",
    "href": "intro.html#introduction",
    "title": "1  Introduction: Types of studies",
    "section": "1.2 Introduction",
    "text": "1.2 Introduction\nStudies vary by:\n\nUnit of analysis: individual (above designs) versus population (ecological).\nWhether researcher assigns participants to the treatment or not.\nWhether participants are observed prospectively or not\nWhether all data comes from a single time point.\nWhether the primary grouping of participants is by exposure or by disease/outcome.\nWhether they test hypothesis: Descriptive (does not test hypotheses) versus analytic (tests hypotheses).\n\nA study of large entities (countries or counties) is ecological. Intermediate units of analysis may be either type of study. Examples: schools. Could do an ecological study of schools (e.g., compare test scores versus teacher-student ratio) or an experiment on schools (e.g., hire more teachers at schools in the treatment group, do nothing for control group, and observe test scores as the outcome.)\nDefinition: Here I use three terms to be synonymous: treatment, exposure status, and main predictor. `Treatment’ is shorter, and I use it in quotes to indicate that it can be either assigned randomly or not.\nIn non-random studies, statistical methods can still allow causal inference.\n\nInstrumental variables: control for a factor that predicts both `treatment’ and outcome.\nPropensity matching methods: propensity score weighting/matching, nearest-neighbor matching. Balance treatment and control groups so that only differences remaining between the two groups (treated and control) is their treatment status in an attempt to replicate the assignment mechanism to treatment versus control.\nQuasi-experiments are also sometimes called natural experiments. e.g., New York’s calorie menu labeling requirement, compared with neighboring states."
  },
  {
    "objectID": "intro.html#suggested-answers",
    "href": "intro.html#suggested-answers",
    "title": "1  Introduction: Types of studies",
    "section": "1.3 Suggested answers",
    "text": "1.3 Suggested answers\nYour answers may vary but here are some suggested answers to the quiz.\n\n\n\n\n\n\n\n\nTypes of study\nAdvantages\nLimitations\n\n\n\n\nCase study\nCan describe a rare condition\n\n\n\nCase series\nImplicit comparison with population\nMay highlight wrong feature\n\n\nDescriptive rate-based\nCan observe trends\nCausality unclear\n\n\n\n\nDoes not test hypotheses\n\n\nPre-post, no control\nCan do something\nNo comparison group\n\n\n\nPolitically easier to treat all.\nConclusions may be incorrect.\n\n\nCross sectional\nData easier to find.\nNo temporal ordering.\n\n\n\nInexpensive.\nPotential confounding.\n\n\nProspective cohort\nEstablishes temporal sequence.\nSelf-selection/confounding limits causal inference.\n\n\n\n\nNeed to wait for disease to emerge.\n\n\n\n\nOnly possible for common diseases.\n\n\nRetrospective cohort\nMay establish temporal sequence\nSelf-selection/confounding.\n\n\n\n\nExposure status may not be accurate.\n\n\n\n\nTemporal sequence may not be accurate.\n\n\nCase-control\nCan examine many factors.\nFalse significance (multiple comparisons)\n\n\n\nUseful to generate hypotheses.\nComparison group validity.\n\n\n\nQuick; disease already emerged.\nMeasures often retrospective.\n\n\n\nCan study rare diseases.\n\n\n\nEcological\nUseful for system-level differences.\nNo individual-level conclusions.\n\n\n\n\nUseful first step in research.\n\n\nRandomized experiment\nCausal inference.\nLimited to tested intervention.\n\n\n\nCan falsify initial hypotheses.\nMay test ``wrong’’ intervention.\n\n\n\n\nTime-consuming and expensive.\n\n\nNatural/quasi-experiment\nAlmost as good as RCT.\nRare and hard to identify.\n\n\n\n\nDiscovered rather than designed."
  },
  {
    "objectID": "intro.html#example-case-study-should-i-drink-more-coffee",
    "href": "intro.html#example-case-study-should-i-drink-more-coffee",
    "title": "1  Introduction: Types of studies",
    "section": "1.4 Example case study: Should I drink more coffee?",
    "text": "1.4 Example case study: Should I drink more coffee?\nObservational evidence suggests that coffee predicts lower mortality and morbidity from a variety of diseases. Is the evidence sufficient to suggest that people should drink more coffee? How do we figure that out?\nOne difference you might notice when we think about the personal decisions that individuals make about their health behaviors is that individuals want good outcomes, broadly speaking. Usually when individuals take actions to try to improve their health, they’re not picky about which good health outcomes results from their new health behavior. By contrast, research always has specific outcomes. These outcomes can be very specific.\nWhen the concern is long-term outcomes, individuals don’t even know which outcomes result from which health behaviors because they don’t know the counterfactuals: the outcomes in the case that they had different exposures.\nBecause of the difference between how individuals and reserachers talk about the effects of health behaviors and exposures, there can be a disconnect. Individuals have the question does this health behavior work? In research, that’s too vague of a question.\nIn best practice, these outcomes are pre-specified: that is, before anybody started the research, they write down which hypotheses they plan to test. The reason it’s so important to pre-specify your hypothesis is that we want research to be replicable. Many have made the analogy between research andarchery. In archery, we shoot an arrow at the center of a target that already exists; if we hit the center of the target, that suggests that we have a good chance of likewise hitting near the center of future targets under similar conditions. In other words, hitting a target with an arrow is replicable. Shooting an arrow and then drawing a target around where the arrow landed is not replicable: it doesn’t demonstrate that you would be able to shoot the arrow at the target.\nA 1981 case-control study found an association between coffee and pancreatic cancer. Many other studies have found an association between coffee and reduced morbidity and mortality. So which direction is right? Is coffee likely to lead to better outcomes? Or is coffee likely lead to worse outcomes? Or do we just not know? How much evidence is there and what quality of evidence is there? How certain are we? How much confidence do we have in these results?\nWe can think about the types of studies that might be done. A case control study takes people who have a specific disease and compares them with similar people who don’t have that disease. This type of study compares people with and without the disease to see which exposures are associated with the disease.\nA cohort study or a longitudinal study follows people over time to see which exposures they have and then sees which diseases they develop. If we think about what types of study might collect information about coffee drinking, we can see why it might be so challenging to study the effect of coffee drinking on long-term outcomes.\nThere is a national study called the national health and nutrition examination study or NHANES that asks people about all the different things that they eat and drink. It also does some lab studies and examinations like taking blood samples and urine samples. Then the federal researchers that run the NHANES study link it up with death records. This is one source of data that might have coffee drinking recorded and then later on have death and cause of death recorded. These data already exist, and you could actually go right now and look for these data and conduct the study."
  },
  {
    "objectID": "intro.html#evidence-based-health-behaviors-example-of-yoga",
    "href": "intro.html#evidence-based-health-behaviors-example-of-yoga",
    "title": "1  Introduction: Types of studies",
    "section": "1.5 Evidence-based health behaviors: example of yoga",
    "text": "1.5 Evidence-based health behaviors: example of yoga\nThe long-term effects of coffee drinking have been studied reasonably thoroughly. Other health behaviors may have sparser research.\nIf I take up yoga, and I find that I feel generally happier, I’ll probably feel satisfied with my decision even if I have no measurable differences in any other health metric or disease risk.\nHealth practices like yoga could be qualitatively beneficial even in the absence of quantitative evidence that they improve specific health outcomes. Because of the way that we do research about health, each one of the possible outcomes of yoga might be studied entirely separately. For example, researchers might want to know whether yoga reduces the number of months it takes to conceive a pregnancy, reduces systolic blood pressure, reduces depression as measured by the score on a depression screening survey, or decreases sleep latency, the number of minutes it takes to fall asleep as measured by a specific device. These are all super concrete outcomes. Further, although there is one part of the national institutes of health that studies complementary medicine such as yoga, researchers might apply for funding for these outcomes from entirely different parts of the national institutes of health or similar research funding bodies.\nUsing observational data, we can study health behaviors like yoga, but then we need to evaluate selection into these behaviors. People who do yoga are different from people who don’t."
  },
  {
    "objectID": "intro.html#another-example-kidney-stones-and-roller-coasters",
    "href": "intro.html#another-example-kidney-stones-and-roller-coasters",
    "title": "1  Introduction: Types of studies",
    "section": "1.6 Another example: kidney stones and roller coasters",
    "text": "1.6 Another example: kidney stones and roller coasters\nKidney stones are painful and require expensive intervention to clear if they don’t pass while small. A urologist noticed that many patients who rode roller coasters seemed to pass kidney stones and not need intervention, so he devised a model kidney filled with kidney stones and his own urine and brought it to Disney World to ride a roller coaster. He noticed that the kidney stones passed more often when he was in the back of the roller coaster than in the front. He will use this information to design a randomized controlled trial to test the hypothesis that riding roller coasters helps people to pass kidney stones. Whether or not roller coasters are the next treatment for kidney stones would depend on the results of the RCT.\nJames Hamblin, ``A Health Benefit of Roller Coasters’’, Atlantic Monthly Sep 26, 2016 http://www.theatlantic.com/health/archive/2016/09/for-kidney-health-roller-coaster-therapy/501278/"
  },
  {
    "objectID": "intro.html#another-example-multitasking-and-electronic-distractions",
    "href": "intro.html#another-example-multitasking-and-electronic-distractions",
    "title": "1  Introduction: Types of studies",
    "section": "1.7 Another example: Multitasking and electronic distractions",
    "text": "1.7 Another example: Multitasking and electronic distractions\nThe research cited below comes was cited in slides by Andrew Mills of Otterbein University. Some of the research he cited came from a blog post by journalist Nicholas Carr (How Smartphones Hijack Our Minds, Wall Street Journal) that gave the sources of his WSJ article (http://www.roughtype.com/?p=8195) As students, you face distractions that I and most of your faculty instructors never faced. When I was in high school, one of my chief methods of procrastination was bending a paperclip and running it between the keys to pull up dust from the keyboard (true story!).\nIn this class, we can use laptops and phones for productive purposes: for learning statisical computations in R, for searching the research literature, for looking up the meaning of a term. However, the presence of a screen presents a distraction for everyone, both the users and those around them.(Sana, Weston, Cepeda, 2013, Laptop multitasking hinders classroom learning for both users and nearby peers https://doi.org/10.1016/j.compedu.2012.10.003) Screens reduce learning and retention of information, (Glass and Kang 2018, Dividing attention reduces exam performance. https://doi.org/10.1080/01443410.2018.1489046; Lauren M. Singer, Patricia A. Alexander 2017, Reading Across Mediums: Effects of Reading Digital and Print Texts on Comprehension and Calibration, J Experimental Education. https://doi.org/10.1080/00220973.2016.1143794) quality of notes, test performance, (Payne Carter, Greenberg, Walker, 2016 http://seii.mit.edu/wp-content/uploads/2016/05/SEII-Discussion-Paper-2016.02-Payne-Carter-Greenberg-and-Walker-2.pdf ) and distract others. I summarize the two studies that are most striking to me.\nResearchers at the US military academy performed an experiment in which one section of a class was allowed unlimited use of laptops/tablets (treatment) and the other were only permited tablets that were flat on the desk (control); the average final exam scores in the treatment group were 0.18 standard deviations lower than in the control group. (Payne Carter, Greenberg, Walker, 2016 http://seii.mit.edu/wp-content/uploads/2016/05/SEII-Discussion-Paper-2016.02-Payne-Carter-Greenberg-and-Walker-2.pdf )\nPsychologists performed experiments in which students were instructed to listen to a lecture, and a random subset were assigned to multitask during the lecture: that is, to perform tasks unrelated to the lecture during the lecture. Both students assigned to multitask and students who could see their screen them both performed worse in an exam on the content of the lecture than students assigned not to multitask and who could not see the screen of a multitasker. (Sana, Weston, Cepeda, 2013, Laptop multitasking hinders classroom learning for both users and nearby peers https://doi.org/10.1016/j.compedu.2012.10.003)\nPsychologists teaching two sections of the same course performed a randomized experiment, randomly assigning half of their class sessions to no devices allowed'' ordevices permitted’’ condtions: during the no device class sessions, proctors enforced the rule of not allowing devices. The experiment used a cross-over design, so that for each class session, one section of the class banned devices and the other allowed devices. Students allowed to use devices did not differ in their scores on in-class quizzes on the material presented in class than students who were not allowed to use devices in that class, but students allowed to use devices scored lower on midterm/final exams that were in later class sessions than students not allowed to use devices. Dividing attention bewteen a laptop/tablet/phone and a lecture did not reduce short-term retention of material but reduced long-term retention of material. (Glass and Kang 2018, Dividing attention reduces exam performance. https://doi.org/10.1080/01443410.2018.1489046)\nAn observational study of student use of their laptops in class found that 42% of the time students had open software that was unrelated to the course, and that students underestimated their multitasking behavior in the classroom (email and instant messaging, at the time) compared with the objective measures of multitasking observed by the researchers (Kraushaar, James M.; Novak, David C. Examining the Affects of Student Multitasking with Laptops during the Lecture, Journal of Information Systems Education, v21 n2 p241-251 2010 https://eric.ed.gov/?id=EJ893903)\nEducational psycholgists randomly assigned students to read texts on screens and in print in a cross-over experiment, and found that students performed better on tests of retention for the material that they read in print than on screens. (Lauren M. Singer, Patricia A. Alexander 2017, Reading Across Mediums: Effects of Reading Digital and Print Texts on Comprehension and Calibration, J Experimental Education.https://doi.org/10.1080/00220973.2016.1143794)\nResearchers randomly assigned participants to place their cell phones nearby in view, nearby out of view, or in another room. Participants assigned to have their phone in view had lower scores on various measures of memory and cognitive capacity than participants whose phones were in another room. However, irrespective of their phone’s location, most participants reported that they did not think about their phone at all while performing the tasks, and they did not think their phone’s location affected their performance. (Ward, Duke, Gneezy, Bos, ``Brain Drain: The Mere Presence of One’s Own Smartphone Reduces Available Cognitive Capacity,’’ Journal of the Association for Consumer Research, 2017.)\nThe educational research suggests that students have worse learning outcomes from using electronic devices in class, and that they are completely unaware of negative outcomes. However, these studies were not specific to computer-oriented classes. In this class, students may want to use laptops during some class sessions to follow along with the statistical commands. The research suggests to me that learning outcomes for everyone will be better if students put devices out of sight when they are not needed."
  },
  {
    "objectID": "intro.html#professionalism",
    "href": "intro.html#professionalism",
    "title": "1  Introduction: Types of studies",
    "section": "1.8 Professionalism",
    "text": "1.8 Professionalism\nInitiation into a professional identity with norms.\nPlay fair — cite others; don’t plagiarize.\n\nCopying others’ words with minimal changes.\nFailing to cite others’ ideas.\nFailure to use quotation marks for exact quotes (and exact quotes should almost never be used in scientific papers.)\n\nRespect others’ time.\n\nCommunicate clearly and efficiently. Refer to books on communication and always improve.\nNo such thing as a final draft: revision is always possible.\n\n\n1.8.1 Connecting with professional associations\nConnecting with professional associations as a student allows you to connect with others across the country/world, share research, get job and conference announcements, and experiment with professional identities at a low cost. You can connect through professional organizations through social networking websites such as Twitter and Facebook, by submitting to professional conferences, and by joining. In the past, SPH has generally paid students’ costs to present at conferences.\n\n\n1.8.2 Job resources\nBecome familiar with job listings before job search. Begin job search in August for June graduation: i.e., 10 months ahead. You can prepare job materials even before that, ideally the summer before graduation, especially for doctoral students."
  },
  {
    "objectID": "intro.html#exercises",
    "href": "intro.html#exercises",
    "title": "1  Introduction: Types of studies",
    "section": "1.9 Exercises",
    "text": "1.9 Exercises\n\n1.9.1 Binary classification tree\nMake a binary classification tree to distinguish between the following study types. Hand writing it will be easier than trying to make it on the computer. See example on next page.\n\nRandomized experiment. Also known as randomized controlled trial (RCT).\nQuasi-experiment. Also called a natural experiment, although they are not exactly synonymous.\nRetrospective/prospective cohort study.\nCase-control study.\nCross-sectional study.\nDescriptive rate-based study.\nPre-post study without control group.\nEcological study\n\n\n\n1.9.2 Epidemiology overview\nRead and prepare to discuss George Davey Smith and Shah Ebrahim, Epidemiology — is it time to call it a day? Int. J. Epidemiol. (2001) 30 (1): 1–11. doi: 10.1093/ije/30.1.1. http://ije.oxfordjournals.org/content/30/1/1.full\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "chaptA.html#what-is-r",
    "href": "chaptA.html#what-is-r",
    "title": "2  Introduction to R",
    "section": "2.1 What is R",
    "text": "2.1 What is R\nR is free software, in the sense of both “free speech” and “free beer” (in the words of Richard Stallman). R can implement almost every type of statistics, produces high-quality statistical graphics, and you can use it for free for the rest of your long careers.\nR uses an open format, so that the data that you use and generate in R will always be available to you. R also does not cost money, as opposed to proprietary software packages that require large annual fees that get higher after you are no longer students, which tend to increase because people using a proprietary software will generally avoid having to convert everything over."
  },
  {
    "objectID": "chaptA.html#installing-r-and-rstudio",
    "href": "chaptA.html#installing-r-and-rstudio",
    "title": "2  Introduction to R",
    "section": "2.2 Installing R and Rstudio",
    "text": "2.2 Installing R and Rstudio\nR is available for free here for Mac, Windows, and Linux operating systems. Go to http://R-project.org and choose Downlaod.\nR studio is an interface to R to make everything appear in 1 window, and it lets you click on commands to execute them. You can install it from this website: http://www.rstudio.com/"
  },
  {
    "objectID": "chaptA.html#using-rstudio",
    "href": "chaptA.html#using-rstudio",
    "title": "2  Introduction to R",
    "section": "2.3 Using Rstudio",
    "text": "2.3 Using Rstudio\nOpen R Studio and poke around. If you want help for any command type help or simply a question mark followed by the command name, or type the command name in the upper right corner of the R console.\n\nhelp(command-name)\n\n\n?commandname"
  },
  {
    "objectID": "chaptA.html#conventions-of-programming",
    "href": "chaptA.html#conventions-of-programming",
    "title": "2  Introduction to R",
    "section": "2.4 Conventions of programming",
    "text": "2.4 Conventions of programming\nR uses conventions of computer programming, so it may require new forms of thinking.\nIn this class, we will use a text formatting program Rmarkdown within Rstudio. You will knit these files to create files to submit to our course website. Knitting executes all code chunks within the file.\nIn your Rmarkdown file, explain your code chunks to remind yourself what it does, so that when you come back to it in a few weeks, you will remember what to use it for.\n\nKeep only the code that actually works.\nKnit frequently.\nIf you paste R code into a document, it will be easier to read in Courier or another monospace font.\nText from a word processor or email program or PDF may have hidden characters that R can’t read, so if you paste from these formats, you may need to retype something if you get an error.\nBe careful with quotation marks: typing quotation marks directly into R will always work, but if you are pasting from another source, occasionally straight up-and-down quotation marks that are the same at the beginning and end will be transformed to “smart” quotation marks that are different at the beginning and end of a quotation. R does not know how to read smart quotation marks.\n\nR can have a steep learning curve. Once you know how to use R, you will have an easier time learning to use other statistical packages and computer languages."
  },
  {
    "objectID": "chaptA.html#r-reference",
    "href": "chaptA.html#r-reference",
    "title": "2  Introduction to R",
    "section": "2.5 R Reference",
    "text": "2.5 R Reference\nMany of the R commands you will learn this term\nR Studio has menu items for importing data. It also remembers past plots.\nR Studio will display some of the data that you’ve loaded, but it does not show all variables in either the viewer or the list of variables.\n\n2.5.1 Libraries\nR has a great deal of built-in functionality, but it gets its strength from having user-written packagesthat add functions.\n\n\n2.5.2 Help\nIf you want help for any command type help(command-name) or simply a question mark followed by the command name ?commandname, or type the command name in the upper right corner of the R console.\n\n\n\nCommand\nMeaning\nExample\n\n\n\n\n?command\nGet help for command\n?xyplot\n\n\nhelp(command)\nGet help for command\nhelp(xyplot)\n\n\n??keyword\nFind topics related to keyword\n??plot\n\n\n\n\n\n2.5.3 Using data\nR stores data in structures called data frames. When you load in data in R, your data will automatically be in a data frame. Data frames are similar to matrices, although R recognizes a difference between them.\n\n\n\n\n\n\n\nCommand\nMeaning\n\n\n\n\nDF=read.table(“file”, header=T)}\nRead in data from tab-separated file with header containing variable names and assign it to dataframe called DF.\n\n\nDF=read.csv(“file”, header=T)\nRead in data from comma-separated file with header containing variable names and assign it to dataframe called DF.\n\n\n\n\n\n2.5.4 Using variables\nAll variables must be referenced by their dataframe, such as DF$x.\nAvoid using attach/detach\n\n\n2.5.5 Describing data objects\n\n\n\n\n\n\n\nCommand\nMeaning\n\n\n\n\nnrow(DF)\nNumber of rows in data frame or other two-dimensional object DF\n\n\nncol(DF)\nNumber of columns in data frame or other two-dimensional object DF\n\n\nrownames(DF)\nLists names of rows in data frame or other two-dimensional object DF\n\n\ncolnames(DF)\nLists names of columns in data frame or other two-dimensional object DF\n\n\nsummary(DF)\nSummarize data frame DF\n\n\nnames(DF)\nList all the names of all items in data frame DF\n\n\nstr(DF)\nSummarize each item in data frame DF\n\n\nlength(Var1)\nLength of one-dimensional object Var1\n\n\nis.na(Var1)\nTests whether each item in Var1 is missing (NA)\n\n\n\n\n\n2.5.6 Creating data objects\n\n\n\n\n\n\n\nCommand\nMeaning\n\n\n\n\nX = cbind(v1, v2)\nCreate 2-dimensional object X where vectors v1 and v2 are the columns\n\n\nX = rbind(v1, v2)\nCreate 2-dimensional object X where vectors v1 and v2 are the rows\n\n\nX = c(1, 2, 3)\nCreate vector X, which is the numbers (1, 2, 3)\n\n\nDF1=subset(DF, condition)\nCreate a new object DF1: all items in DF that satisfy a condition.\n\n\n\n\n\n2.5.7 Referring to elements\n\n\n\nCommand\nMeaning\n\n\n\n\nVar1[1]\nfirst element in Var1 (one-dimensional).\n\n\nDF[1,]\nfirst row in DF (two-dimensional).\n\n\nDF[,1]\nfirst column in DF (two-dimensional).\n\n\nDF[3,4]\nfourth element in the third row of DF (two-dimensional).\n\n\n\n\n\n2.5.8 Shortcuts\n\n\n\nCommand\nMeaning\n\n\n\n\nseq(0, 100, 10)\nAll multiples of 10 from 0 to 100\n\n\n1:10\nAll numbers between 1 and 10\n\n\n\n\n\n2.5.9 Calculation\n\n\n\nCommand\nMeaning\n\n\n\n\n+\nPlus\n\n\n-\nMinus\n\n\n*\nMultiply\n\n\n/\nDivision\n\n\n!\nLogical not (opposite)\n\n\nlog()\nNatural log (base e)\n\n\nlog10()\nlog base 10\n\n\nexp(x)\n(e^x)\n\n\nsqrt(x)\n()\n\n\nabs(x)\nAbsolute value of x\n\n\nround(x, digits=2)\nRound x to 2 digits\n\n\n\n\n\n2.5.10 Comparisons\n\n\n\nCommand\nMeaning\n\n\n\n\n==\nTests for equality\n\n\n=\nSets equal\n\n\n<-\nSets equal\n\n\n!=\nTests for inequality\n\n\n<=\nTests for less than or equal\n\n\n<\nTests for less than\n\n\n>=\nTests for greater than or equal\n\n\n>\nTests for greater than\n\n\n\n\n\n2.5.11 Defining new variables\nWhen defining new variables, remember that == tests for equality and = sets a variable equal to the quantity on the right hand side.\n\n\n2.5.12 Summarizing data\nFor many of these functions, you must first load the mosaic library. Mosaic was written by professors at small colleges to make R easier to use for students.\nIf this is your first time using mosaic, you must first install it. When you press “save” on an Rmarkdown file that calls the library, Rstudio will automaically ask if you want to install the library.\n\nlibrary(mosaic)\n\n\n\n\n\n\n\n\nCommand\nMeaning\n\n\n\n\nfavstats()\nDisplays numerical summaries: minimum, maximum, median, quartiles, sample sizes\n\n\nsum()\nSum everything in parentheses\n\n\nmean()\nMean\n\n\nmedian()\nMedian\n\n\nsd()\nStandard deviation\n\n\nvar()\nVariance\n\n\nmedian()\nMedian\n\n\nmin()\nMinimum\n\n\nmax()\nMaximum\n\n\ntally(~x, data=DF)\nFrequency table of x in dataframe DF\n\n\ntally(y~x, data=DF)\nCross-tabulation table of x and y in dataframe DF\n\n\n\n\n\n2.5.13 Plotting using Mosaic\nThe Mosaic package uses the same form for many plotting and analysis commands.\ncommand ( y ~ x | z, data= DF, groups = w, auto.key=T)\ny is the y-axis variable\nx is the x-axis variable\nz is the grouping variable to make separate plots\nw is the grouping variable to plot in different colors in the same plot.\nDF is the data frame that these variables are located in.\nauto.key=T tells the plotting command to automatically draw a key for each item.\n\n\n2.5.14 Univariate distributions\n\n\n\nCommand\nMeaning\n\n\n\n\nhistogram()\nHistogram\n\n\ndensityplot()\nDensity plot (kernel density plot)\n\n\nfreqpolygon()\nFrequency polygon\n\n\nbargraph()\nBargraph\n\n\n\n\n\n2.5.15 Bivariate distributions\n\n\n\nCommand\nMeaning\n\n\n\n\nbwplot()\nBox and whisker plot\n\n\nxyplot()\nScatter plot\n\n\n\n\n\n2.5.16 Data analysis\n\n2.5.16.1 Bivariate analysis\n\n\n\nCommand\nMeaning\n\n\n\n\nt.test()\nT-test\n\n\nwilcox.test()\nWilcoxon test\n\n\nchisq.test()\nChi-squared test\n\n\nprop.test()\nProportion test\n\n\nbinom.test()\nBinomial test\n\n\n\n\n\n2.5.16.2 Multivariate analysis\n\n\n\n\n\n\n\nCommand\nMeaning\n\n\n\n\nmodel1=lm(y~x1 + x2, data=DF)\nPerform linear regression of y on x1 and x2 and put results in model1\n\n\nmodel1=glm(y~x1 + x2, family=binomial)\nPerform logistic regression of y on x1 and x2 and put results in model1\n\n\nmodel1=glm(y~x1 + x2, family=poisson)\nPerform Poisson regression of y on x1 and x2 and put results in model1\n\n\nsummary(model1)\nSummarize results in model1\n\n\n\n\n\n\n2.5.17 Defining variables\nIn R, all variables are lists of numbers. More formally, they are vectors. Here is an example. In this case, I am using R’s shortcut for all the numbers from 1 to 10.\n\nvar1=1:10\nvar1\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nAn equivalent way to write this command is using the c() function, which tells R to make a list out of everything within the parentheses. c stands for concatenate, which means to attach elements together. If you need to enter a few numbers yourself, you can use the c() function.\n\nvar1=c(1,2,3,4,5,6,7,8,9,10)\n\n\nvar1+1\n\n [1]  2  3  4  5  6  7  8  9 10 11\n\nvar2=var1+1\nvar2\n\n [1]  2  3  4  5  6  7  8  9 10 11\n\n\nI just defined a new variable called test which is the numbers from 1 to 10. I then created a new variable called test2 which is defined as test+1. That is, you add 1 to every member of test. If you do something to a variable without setting it equal to anything, R just prints the output.\nYou can also add two variables. For example:\n\nvar1+var2\n\n [1]  3  5  7  9 11 13 15 17 19 21\n\n\nIf you want just a few elements of a variable, you can use brackets to ask for them. The following commands ask for the first element, the first through third elements, and the elements in the list c(2,4,6):\n\nvar2[1]\n\n[1] 2\n\nvar2[1:3]\n\n[1] 2 3 4\n\nvar2[c(2,4,6)]\n\n[1] 3 5 7\n\n\nR also has other data types besides vectors.\n\n\n2.5.18 Matrices\nMatrices are 2-dimensional ways to store variables. For example, a two by two table can be represented as a matrix.\nYou can create a matrix with the matrix command. The following creates a matrix with the elements from 1 to 8. You can tell R how many rows or columns you want using either the option nrow= or ncol=. By default, this function fills in columns in order. If you want the matrix to be entered by row, you have to use the option byrow=T.\n\ntest.matrix=matrix(1:8, nrow=2)\ntest.matrix\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    3    5    7\n[2,]    2    4    6    8\n\ntest.matrix2=matrix(1:8, nrow=2, byrow=T)\ntest.matrix2\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n\n\n\n\n2.5.19 Missing data\nSometimes, data is missing. In this case, I am using a command to set the 3rd element of test to be missing, using a command called is.na(). You don’t have to worry about that command yet, but I’m using it to get somewhere.\n\nis.na(var1)=3\nvar1\n\n [1]  1  2 NA  4  5  6  7  8  9 10\n\nvar2=var1+1\nvar2\n\n [1]  2  3 NA  5  6  7  8  9 10 11\n\n\nNow I just made the third element of the variable missing (NA). I created var2 which is again var1+1, but notice that NA stays the same because adding 1 to missing is still missing.\n\ntest3=1:10\ntest4=1:10\nis.na(test3)=c(2,4,6,8,10)\nis.na(test4)=c(1,3,5,7,9)\ntest3\n\n [1]  1 NA  3 NA  5 NA  7 NA  9 NA\n\ntest4\n\n [1] NA  2 NA  4 NA  6 NA  8 NA 10\n\n\nIn each case where test1 is missing, there is a test2 number to fill in.\nYou can use the ifelse command to combine the variables test1 and test2 so that you again get 1 through 10.\n\ntest5=ifelse(is.na(test3), test4, test3)\ntest5\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "chaptA.html#exercises",
    "href": "chaptA.html#exercises",
    "title": "2  Introduction to R",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\n\n2.6.1 Software preparation\nInstall R and R Studio on your computer of choice (if not already installed). If already installed, update all of these.\nFamiliarize yourself with the menus in Rstudio.\nFind the following features of R studio:\n\nHistory listings\nFile pane\nEditing window where you can create an Rmarkdown file.\nButton to create a code chunk: green +C. Run code in a chunk by pressing the green “play” button in it. Remember to write all of your code in this document and to knit code frequently.\nEnvironment, where all the items in memory are displayed.\nListing of all available packages.\nThe help window."
  },
  {
    "objectID": "chapt1.html#plots-as-necessary-data-summaries",
    "href": "chapt1.html#plots-as-necessary-data-summaries",
    "title": "3  Data displays",
    "section": "3.1 Plots as necessary data summaries",
    "text": "3.1 Plots as necessary data summaries\nThe following data — Anscombe’s quartet — have the same summary statistics (moments.) Plotting reveals the relationship between the factors. (Anscombe, F. J. (1973). Graphs in Statistical Analysis. American Statistician 27 (1): 17–21. Plots from wikipedia.)\n\n\n\nQuantity\nValue\n\n\n\n\nMean of x\n9 (exactly)\n\n\nVariance of x\n11\n\n\nMean of y\n7.50\n\n\nVariance of y\n4.122\n\n\nCor(x, y)\n0.816\n\n\nLinear regression result\ny = 3.00 + 0.500x\n\n\n\nHere are code that generate plots of Anscombe’s quartet. I place them one by one on a grid.\n\nlibrary(mosaic)\np1=xyplot(y1 ~ x1, data=anscombe, type=c(\"p\", \"r\"))\np2=xyplot(y2 ~ x2, data=anscombe, type=c(\"p\", \"r\"))\np3=xyplot(y3 ~ x3, data=anscombe, type=c(\"p\", \"r\"))\np4=xyplot(y4 ~ x4, data=anscombe, type=c(\"p\", \"r\"))\nprint(p1, pos = c(0.0, 0.5, 0.5, 1.0), more = TRUE)\nprint(p2, pos = c(0.5, 0.5, 1.0, 1.0), more = T)\nprint(p3, pos = c(0.0, 0.0, 0.5, 0.5), more = TRUE)\nprint(p4, pos = c(0.5, 0.0, 1.0, 0.5), more = F)\n\n\n\n\nSomeone who gets a dataset may generate numerical summaries and linear regressions without looking at the data. You can see here that only the first dataset is appropriate for linear regression.\nDataset 2 needs a quadratic term to fit the parabolic shape.\nDataset 3 has a linear relationship but one large outlier that has a lot of leverage, pulling the regression line up.\nDataset 4 has no relationship at all between x and y. The line goes between the average value of the y at x4=8 and the datapoint at the far end: the regression line is a line determined by two points."
  },
  {
    "objectID": "chapt1.html#effective-presentation-of-data",
    "href": "chapt1.html#effective-presentation-of-data",
    "title": "3  Data displays",
    "section": "3.2 Effective presentation of data",
    "text": "3.2 Effective presentation of data\n\nUse a plot rather than a table whenever possible.\nWhite backgrounds and sans serif fonts are easier to read. (These are defaults in R.)\nMaximize data to ink ratio: all ink should communicate something. If ink can be removed without losing information, it is “chart junk” and unnecessary.\nExamples of unnecessary ink: unnecessary 3d plots, pie charts, “ducks.” A “duck” is an element of a plot that is only for decoration. Ducks are named after the Big Duck, located in Flanders, NY.\n\nThe primary rule for data display is the less ink, the better. Eliminate as much as possible from a plot or table to avoid obscuring your data with extra ink or redundant information. This rule has a few consequences:\n\nAvoid graphical features that add ink without communicating anything, common in Excel.\nAvoid pie charts and other plotting methods that communicate little information for the amount of ink used.\n\nR has a function pie to make a pie chart, but the help file helpfully notes that pie charts are terrible. “Pie charts are a very bad way of displaying information. The eye is good at judging linear measures and bad at judging relative areas. A bar chart or dot chart is a preferable way of displaying this type of data. Cleveland (1985), page 264:”Data that can be shown by pie charts always can be shown by a dot chart. This means that judgements of position along a common scale can be made instead of the less accurate angle judgements.” This statement is based on the empirical investigations of Cleveland and McGill as well as investigations by perceptual psychologists.”\nYou can make a pie chart to show Pacman, however.\nPacman in base R:\n\npie(c(\"Pacman\" = 78, \"Pacman's mouth\" = 22),\n    init.angle = 45, col = c(\"yellow\", \"white\"), border = F)\n\n\n\n\nPacman in ggplot:\n\ndf <- data.frame(\n  variable = c(\"does not resemble Pacman\", \"resembles Pacman\"),\n  value = c(20, 80)\n)\n\nggplot(df, aes(x = \"\", y = value, fill = variable)) +\n  geom_col(width = 1) +\n  scale_fill_manual(values = c(\"white\", \"yellow\")) +\n  coord_polar(\"y\", start = 2*pi/3) +\n  labs(title = \"Pac man\") + \n  theme_classic()\n\n\n\n\nPyramid pie chart:\n\npie(c(Sky = 78, \"Sunny side of pyramid\" = 17, \"Shady side of pyramid\" = 5),\n    init.angle = 315, col = c(\"deepskyblue\", \"yellow\", \"yellow3\"), border = FALSE)"
  },
  {
    "objectID": "chapt1.html#choosing-suitable-plots-and-analyses-for-the-data",
    "href": "chapt1.html#choosing-suitable-plots-and-analyses-for-the-data",
    "title": "3  Data displays",
    "section": "3.3 Choosing suitable plots and analyses for the data",
    "text": "3.3 Choosing suitable plots and analyses for the data\nWe divide data into categorical (C) and quantitative (Q). The types of analysis depend on the types of data.\nCategorical variables can further be categorized as ordinal or non-ordinal.\n\n\n\nVariable type\nOutcome Quantitative\nOutcome Categorical\n\n\n\n\nPredictor quantitative\n\\(Q \\rightarrow Q\\)\n\\(Q \\rightarrow C\\)\n\n\nPredictor categorical\n\\(C \\rightarrow Q\\)\n\\(C \\rightarrow C\\)\n\n\n\nThe displays and analysis types are not meant to correspond to each other.\nThis table is not meant to be a cookbook. This table demonstrates that some types of analysis definitely do not make sense for some types of data. E.g., scatterplot cannot be used instead of 2x2 table.\n\n\n\n\n\n\n\n\nData\nDisplay\nAnalysis\n\n\n\n\n\\(Q \\rightarrow Q\\)\nscatterplots (xyplot)\nlinear regression (lm)\n\n\n\\(Q \\rightarrow C\\) or \\(C \\rightarrow Q\\)\nBox and whisker plot (bwplot)\n\n\n\n\ndotplot (w or w/o confidence interval)\n\n\n\nCategorical variable is binary\nstratified density plot (densityplot)\nt-test, Wilcoxon\n\n\nCategorical variable is binary\n\nLogistic regression glm( , family=binomial)\n\n\nCategorical variable is not binary\n\ntest for trend (if ordinal): e.g., Cuzick’s\n\n\nCategorical variable is not binary\n\nTukey’s HSD (anova followesd by TukeyHSD)\n\n\nCategorical variable is not binary\n\ntransform to binary and use above methods\n\n\n\\(C \\rightarrow C\\)\nContingency table (tally)\nchi-square test (chisq.test)\n\n\n\n\nKruskal-Wallis test (kruskal.test)\n\n\n\n\npairwise chi-square test"
  },
  {
    "objectID": "chapt1.html#exercise",
    "href": "chapt1.html#exercise",
    "title": "3  Data displays",
    "section": "3.4 Exercise",
    "text": "3.4 Exercise\nHow can you improve the following plots?\n\n\n\nPirates and global warming (Source: Forbes (https://www.forbes.com/sites/erikaandersen/2012/03/23/true-fact-the-lack-of-pirates-is-causing-global-warming); Wikimedia commons.)\n\n\n\n\n\nSource: “Hematocrit was not validated as a surrogate end point for survival among epoetin-treated hemodialysis patients”, Dennis J. Cotter, Kevin Stefanik, Yi Zhang, Mae Thamer, Daniel Scharfstein, James Kaufman, Journal of Clinical Epidemiology 57(10):1086-1095, October 2004.\n\n\nSource: Cotter DJ, et al. (2004) Hematocrit was not validated as a surrogate endpoint for survival amoung epoetin-treated hemodialysis patients. Journal of Clinical Epidemiology 57:1086-1095,\n\n\n\nSource: Roeder K (1994) DNA fingerprinting: A review of the controversy (with discussion). Statistical Science 9:222-278, Figure 4b\n\n\nSource: Roeder K (1994) DNA fingerprinting: A review of the controversy (with discussion). Statistical Science 9:222-278, Figure 4b\n\n\n\nHeight of fed chair and inflation rate.\n\n\n\\\nIncluding an image of the fed chair is a ``duck’’ — if they are really making a point about the height of the chair of the Federal Reserve Board, they don’t need the picture. For an infographic (non-academic purpose), it is reasonable to include some eye-catching elements."
  },
  {
    "objectID": "chapt1.html#visualizing-a-screening-test",
    "href": "chapt1.html#visualizing-a-screening-test",
    "title": "3  Data displays",
    "section": "3.5 Visualizing a screening test",
    "text": "3.5 Visualizing a screening test\nThese hypothetical data show the results of a screening test for a low-prevalence condition.\nHere are three visualizations of the screening test results. Is any more effective?\n\n\n\nScreening test illustration\n\n\n\n\n\nScreening test for rare condition (Yes = red, No = blue), FN= false negative (outline red), TP = true positive (shaded red), FP = false positive (blue), and TN = true negative (outline blue).\n\n\nFor a higher prevalence condition, the data might look like this:\n\n\n\nScreening test for common condition\n\n\nIs there a universally preferred method of displaying these data, or does it depend on context?\n(Source: Tim Brock, How to explain screening test outcomes, Significance, 27 April 2017. Retrieved from: https://www.significancemagazine.com/science/547-a-visual-guide-to-screening-test-results)"
  },
  {
    "objectID": "chapt1.html#data-displays-in-r",
    "href": "chapt1.html#data-displays-in-r",
    "title": "3  Data displays",
    "section": "3.6 Data displays in R",
    "text": "3.6 Data displays in R\nR is a free open-source statistical package that was first released in 1995, based on the S statistical package which was a commercial package developed at Bell Labs. R comprises a central set of commands augmented by libraries that introduce new commands.\nBase R includes a plot command that provides for many types of plotting. as well as additional commands: histogram, barplot, dotchart, boxplot, and curve. These commands can get a bit involved. For example, putting two plots on the same axes requires specifying the scale for both plots, and in between putting the command par(new=T): three commands. Adding a regression line requires doing the regression and then giving the command abline: again, three commands.\nIn recent years, the ggplot has become a popular way to do plots. ggplot can be powerful, but it can be involved.\nWe use the package mosaic, which simplifies commands for statistics students. What would normally take 3 commands in regular R can be done in just 1 command. The plotting commands in Mosaic are listed in the R reference guide at the end of today’s notes. Mosaic is based on the lattice graphics package, something you may see referenced in the help pages.\nPlotting commands in Mosaic use the same format:\n\ncommand ( y \\(\\sim\\) x, data=dataset)\n\nYou can stratify by a third variable using simple variations:\n\ncommand ( y \\(\\sim\\) x, groups=z, data=dataset)\ncommand ( y \\(\\sim\\) x | z, data=dataset)"
  },
  {
    "objectID": "chapt1.html#exploring-a-dataset",
    "href": "chapt1.html#exploring-a-dataset",
    "title": "3  Data displays",
    "section": "3.7 Exploring a dataset",
    "text": "3.7 Exploring a dataset\nMany packages, including Mosaic, comes with built-in datasets that can be used for analysis. You can read about a built-in dataset using the help command (equivalent to a ?), and see the variables available using the names command.\nWe will use the HELPrct study (Health Evaluation and Linkage to Primary Care). ``The HELP study was a clinical trial for adult inpatients recruited from a detoxification unit. Patients with no primary care physician were randomized to receive a multidisciplinary assessment and a brief motivational intervention or usual care, with the goal of linking them to primary medical care.’’\n\nhelp(HELPrct)\nnames(HELPrct)"
  },
  {
    "objectID": "chapt1.html#single-variable-plots",
    "href": "chapt1.html#single-variable-plots",
    "title": "3  Data displays",
    "section": "3.8 Single variable plots",
    "text": "3.8 Single variable plots\nWhen there’s one variable, it is on the right side of the formula.\n\nhistogram(~age, data=HELPrct)\n\n\n\ndensityplot(~age, data=HELPrct)\n\n\n\nfreqpolygon(~age, data=HELPrct)\n\n\n\n\n\nbwplot(~age, data=HELPrct)\n\n\n\nbargraph(~age, data=HELPrct)"
  },
  {
    "objectID": "chapt1.html#two-variable-plots",
    "href": "chapt1.html#two-variable-plots",
    "title": "3  Data displays",
    "section": "3.9 Two variable plots",
    "text": "3.9 Two variable plots\n\nxyplot(i1 ~ age, data=HELPrct, ylab=\"Number of drinks per day\", type=c(\"p\", \"r\"))\n\n\n\nbwplot(age ~ substance, data=HELPrct)\n\n\n\nbwplot(substance ~ age, data=HELPrct)"
  },
  {
    "objectID": "chapt1.html#stratifying-plots-by-a-third-variable",
    "href": "chapt1.html#stratifying-plots-by-a-third-variable",
    "title": "3  Data displays",
    "section": "3.10 Stratifying plots by a third variable",
    "text": "3.10 Stratifying plots by a third variable\nOften it’s useful to stratify plots by a third variable. You can do this using two methods.\n\nxyplot(i1 ~ age, groups=female, data=HELPrct, ylab=\"Number of drinks per day\", \nauto.key=T, type=c(\"r\", \"p\"))\n\n\n\nxyplot(i1 ~ age | female, data=HELPrct, ylab=\"Number of drinks per day\", \nauto.key=T, type=c(\"r\", \"p\"))"
  },
  {
    "objectID": "chapt1.html#making-historical-plots-in-r",
    "href": "chapt1.html#making-historical-plots-in-r",
    "title": "3  Data displays",
    "section": "3.11 Making historical plots in R",
    "text": "3.11 Making historical plots in R"
  },
  {
    "objectID": "chapt1.html#john-snows-cholera-data",
    "href": "chapt1.html#john-snows-cholera-data",
    "title": "3  Data displays",
    "section": "3.12 John Snow’s cholera data",
    "text": "3.12 John Snow’s cholera data\nJohn Snow’s cholera data is in the library HistData.\n\nlibrary(HistData)\n\n\nAttaching package: 'HistData'\n\n\nThe following object is masked from 'package:mosaicData':\n\n    Galton\n\n\nNumber of cholera deaths by population size.\n\nxyplot(cholera_deaths ~ popn, data=Cholera, type=c(\"r\", \"p\"), \n       xlab=\"Population in 1849\", ylab=\"Number of cholera deaths in 1849\", \n       main=\"Cholera deaths in 1849\")\n\n\n\nxyplot(cholera_deaths ~ popn, groups= water, auto.key=T, \n       data=Cholera, type=c(\"r\", \"p\"), xlab=\"Population in 1849\", \n       ylab=\"Number of cholera deaths in 1849\", \n       main=\"Cholera deaths in 1849 by water supplier\")\n\n\n\nxyplot(cholera_deaths ~ popn | water, data=Cholera, type=c(\"p\", \"r\"),\nxlab=\"Population in 1849\", ylab=\"Number of cholera deaths in 1849\" , \nmain=\"Cholera deaths in 1849 by water supplier\")\n\n\n\n\nNumber of cholera deaths by population density.\n\nxyplot(cholera_deaths ~ pop_dens, data=Cholera, type=c(\"r\", \"p\"), \n       xlab=\"Population density in 1849\", \n       ylab=\"Number of cholera deaths in 1849\", \n       main=\"Cholera deaths in 1849\")\n\n\n\nxyplot(cholera_deaths ~ pop_dens, groups= water, data=Cholera, \n       type=c(\"r\", \"p\"), auto.key=T,\n       xlab=\"Population density in 1849\", \n       ylab=\"Number of cholera deaths in 1849\", \n       main=\"Cholera deaths in 1849 by water supplier\")\n\n\n\nxyplot(cholera_deaths ~ pop_dens | water, data=Cholera, type=c(\"p\", \"r\"),\nxlab=\"Population density in 1849 (persons per acre)\", ylab=\"Number of cholera deaths in 1849\" , \nmain=\"Cholera deaths in 1849 by water supplier\")\n\n\n\n\nNumber of cholera deaths by house value\n\nxyplot(cholera_deaths ~ house_valpp | water, data=Cholera, type=c(\"p\", \"r\"),\nxlab=\"Average value of houses in 1849 (pounds)\", ylab=\"Number of cholera deaths in 1849\" , \nmain=\"Cholera deaths in 1849 by water supplier\")\n\n\n\n\n\n3.12.1 Questions for discussion:\n\nInterpret each of these plots. Based on these plots, which factors predict cholera?\nIf you are able to explore the data further, are there other factors that appear important?"
  },
  {
    "objectID": "chapt1.html#florence-nightingales-data",
    "href": "chapt1.html#florence-nightingales-data",
    "title": "3  Data displays",
    "section": "3.13 Florence Nightingale’s data",
    "text": "3.13 Florence Nightingale’s data\nIt’s possible to create the coxcomb plot in R: see the documentation of Histdata.\nFlorence Nightingale’s plot of mortality during the Crimean War is a famous early example of data display. It is a polar area diagram, also known as a coxcomb plot. Note: it is not a pie chart.\n\nBased on looking at both the static and the animated version of the data, explain what the data shows about the primary causes of death during the Crimean War.\nName two advantages that make this data display particularly effective at communicating the data.\nName two disadvantages that make this data display confusing or ineffective.\nWhat is another way to display the same information, and how would it address the problems that you identified? Name both the type of display and exactly what you would plot.\n\nWhy is the following plot better than the coxcomb plot?\n\nxyplot(Disease.rate + Wounds.rate + Other.rate ~ Date, data=Nightingale, \ntype=c(\"p\", \"l\"), auto.key=T, ylab=\"Annual rate of deaths per 1000\", \nxlab = \"Date (year-month)\")"
  },
  {
    "objectID": "chapt1.html#births-by-day-of-year",
    "href": "chapt1.html#births-by-day-of-year",
    "title": "3  Data displays",
    "section": "3.14 Births by day of year",
    "text": "3.14 Births by day of year\nThis plot shows the number of US births by the day of the year in 1978.\n\nxyplot (births ~ day_of_year, data=Births78, type=c(\"p\", \"smooth\"))\n\n\n\n\nNotice that the data are grouped. What proportion of the data are in the lower group, approximately? What are these data points?\nDefine new variable weekend to be 1 if Sat or Sun, 0 if any other day. Now view the data again with the command View(Births78) and then plot the data.\n\nBirths78$weekend=Births78$wday==\"Sun\" | Births78$wday==\"Sat\"\nxyplot(births ~ day_of_year, groups=weekend, data=Births78, auto.key=T,\n       type=c(\"p\", \"smooth\"))"
  },
  {
    "objectID": "chapt1.html#womens-weights-and-heights",
    "href": "chapt1.html#womens-weights-and-heights",
    "title": "3  Data displays",
    "section": "3.15 Women’s weights and heights",
    "text": "3.15 Women’s weights and heights\nMake a simple scatterplot of the average heights and weights of women in the US from an unspecified year. You can execute the below commands by pasting them into the command box.\nLoad data into memory. We use a built-in dataset of women, their heights, and weights. Look at the dataset by typing the name of it.\n\ndata(women)\n\nMake a simple scatterplot.\n\nxyplot(weight ~ height, data=women)\n\n\n\n\nImprove the scatterplot a bit by labeling the axes and giving it a title. Also, change the plotting character from an open circle to a closed circle. Do a linear regression of weight on height, and draw the regression line on the plot.\n\nxyplot(weight ~ height, data=women, xlab=\"Height (inches)\", ylab=\"Average weight (pounds)\", main=\"Average weights by height for US women in an unknown year\", pch=20, type=c(\"p\", \"r\"))\n\n\n\n\nCreate a new variable for body mass index (BMI) for each height/average-weight combination in this dataset\n\nbmi=703*women$weight/women$height^2\n\nPlot average BMI by height\n\nxyplot(bmi ~ height, data=women, type=c(\"r\", \"p\"), xlab=\"Height (inches)\", ylab=\"Average BMI (kg/m^2)\", \nmain=\"Average BMI by height for US women in an unknown year\")\n\n\n\n\n\nCurrently, about 2/3 of American women are overweight (BMI between 25 and 30) or obese (BMI more than 30), a trend that began in the early 1990s. Do you think that these data are recent, or do they predate the “epidemic” of overweight and obesity? Explain your answer.\nThe goal of the BMI is to assess weight independent of height. Based on your scatterplot, do you think that BMI succeeds in doing that? Explain why. If there is a group of women for whom BMI succeeds as a measurement of weight independent of height, specify it."
  },
  {
    "objectID": "chapt1.html#esophageal-cancer-case-control-data",
    "href": "chapt1.html#esophageal-cancer-case-control-data",
    "title": "3  Data displays",
    "section": "3.16 Esophageal cancer case-control data",
    "text": "3.16 Esophageal cancer case-control data\nThese data come from a study of esophageal cancer in Ille-et-Vilaine, France. (Source: Breslow, N. E. and Day, N. E. (1980) Statistical Methods in Cancer Research. 1: The Analysis of Case-Control Studies.http://w2.iarc.fr/en/publications/pdfs-online/stat/sp32/)\n“Cases were 200 males diagnosed with esophageal cancer in one of the regional hospitals between January 1972 and April 1974. Controls were a sample of 775 adult males drawn from electoral lists in each commune. Both types of subject were administered a detailed dietary interview. which contained questions about their consumption of tobacco and of various alcoholic beverages in addition to those about foods.”\nLoad and summarize the data.\n\ndata(esoph)\nsummary(esoph)\n\n   agegp          alcgp         tobgp        ncases         ncontrols     \n 25-34:15   0-39g/day:23   0-9g/day:24   Min.   : 0.000   Min.   : 0.000  \n 35-44:15   40-79    :23   10-19   :24   1st Qu.: 0.000   1st Qu.: 1.000  \n 45-54:16   80-119   :21   20-29   :20   Median : 1.000   Median : 4.000  \n 55-64:16   120+     :21   30+     :20   Mean   : 2.273   Mean   : 8.807  \n 65-74:15                                3rd Qu.: 4.000   3rd Qu.:10.000  \n 75+  :11                                Max.   :17.000   Max.   :60.000  \n\n\nPlot the ratio of cases to controls versus age, alcohol consumption, and tobacco consumption.\n\nbwplot(ncases/ncontrols ~ agegp, data=esoph, xlab=\"Age (years)\", \nylab=\"Ratio of cases to controls\")\n\n\n\nbwplot(ncases/ncontrols ~ alcgp, data=esoph, xlab=\"Alcohol consumption (grams/day)\", \nylab=\"Ratio of cases to controls\")\n\n\n\nbwplot(ncases/ncontrols ~ tobgp, data=esoph, xlab=\"Tobacco consumption (grams/day)\", \nylab=\"Ratio of cases to controls\")\n\n\n\n\nBased on these plots, does alcohol or tobacco seem to be most strongly associated with esophageal cancer? Explain your answer."
  },
  {
    "objectID": "chapt1.html#map-data",
    "href": "chapt1.html#map-data",
    "title": "3  Data displays",
    "section": "3.17 Map data",
    "text": "3.17 Map data\nR can also plot maps using additional packages. This example comes from the book Flowing Data by Nathan Yau. Note that he chooses to use hexadecimal numbers for colors instead of names.\n\nlibrary(maps)\nfertility=read.csv(\"http://book.flowingdata.com/ch08/points/adol-fertility.csv\")\n\nThis map plots adolescent fertility for each country by latitude and longitude. In demographics, fertility refers to the number of births, which is a term in contrast to conversational English. (Fecundability in demographics refers to the ability to become pregnant and give birth, which is what is called fertility in conversational English.) Circles are proportional to fertility rate for adolescents. Why is a square root scaling useful?\n\nhistogram(~ad_fert_rate, data=fertility)\n\n\n\n\n\nmap(\"world\", fill=F, col=\"#cccccc\")\nsymbols(fertility$longitude, fertility$latitude, circles=sqrt(fertility$ad_fert_rate), add=T, inches=0.15, bg=\"#03ceef\", fg=\"#ffffff\")"
  },
  {
    "objectID": "chapt1.html#summarizing-data-in-r",
    "href": "chapt1.html#summarizing-data-in-r",
    "title": "3  Data displays",
    "section": "3.18 Summarizing data in R",
    "text": "3.18 Summarizing data in R"
  },
  {
    "objectID": "chapt1.html#data-are-data-frames",
    "href": "chapt1.html#data-are-data-frames",
    "title": "3  Data displays",
    "section": "3.19 Data are data frames",
    "text": "3.19 Data are data frames\nAs before, we’ll use data from Health Evaluation and Linkage to Primary (HELP) care randomized clinical trial (RCT), which followed n=470 subjects without primary care enrolled in detox in Boston circa 2000, followed for up to 2 years, every six months. Before you analyze data, you should look at the data frame with the {} and {} commands to make sure it looks like you expect: the appropriate number of observations and variables.\n\nlibrary(mosaic)\n\n\n3.19.1 Numerical summaries: one categorical and one quantitative variable\nR has the expected tools for data summaries: mean, median, sd\nMosaic also includes a command to do many data summaries at once: favstats.\n\nhistogram(~age, data=HELPrct)\n\n\n\nfavstats(~age, data=HELPrct)\n\n min Q1 median Q3 max     mean       sd   n missing\n  19 30     35 40  60 35.65342 7.710266 453       0\n\n\nOn average, both mean and median, the participants are about 35 years old.\nWe can also summarize data by groups. The following commands from Mosaic are equivalent.\n\nfavstats(age ~ substance, data=HELPrct)\n\n  substance min Q1 median    Q3 max     mean       sd   n missing\n1   alcohol  20 33   38.0 43.00  58 38.19774 7.652272 177       0\n2   cocaine  23 30   33.5 37.25  60 34.49342 6.692881 152       0\n3    heroin  19 27   33.0 39.00  55 33.44355 7.986068 124       0\n\nfavstats(~age, groups=substance, data=HELPrct)\n\n  substance min Q1 median    Q3 max     mean       sd   n missing\n1   alcohol  20 33   38.0 43.00  58 38.19774 7.652272 177       0\n2   cocaine  23 30   33.5 37.25  60 34.49342 6.692881 152       0\n3    heroin  19 27   33.0 39.00  55 33.44355 7.986068 124       0\n\n\nWe can also find means stratified by two factors simultaneously:\n\nmean(age ~ substance | sex, data=HELPrct)\n\nalcohol.female cocaine.female  heroin.female   alcohol.male   cocaine.male \n      39.16667       34.85366       34.66667       37.95035       34.36036 \n   heroin.male         female           male \n      33.05319       36.25234       35.46821 \n\n\nWhen the categorical variable is binary, we can test for significance with a t.test or Wilcoxon test.\n\nt.test(age ~ sex, data=HELPrct) \n\n\n    Welch Two Sample t-test\n\ndata:  age by sex\nt = 0.92976, df = 179.74, p-value = 0.3537\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -0.8800365  2.4482932\nsample estimates:\nmean in group female   mean in group male \n            36.25234             35.46821 \n\nwilcox.test(age ~ sex, data=HELPrct)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  age by sex\nW = 19510, p-value = 0.3981\nalternative hypothesis: true location shift is not equal to 0\n\n\nWhen the categorical variable is not binary, we can test for significance with a linear regression or a Kruskal-Wallis test.\n\nkruskal.test(age ~ substance, data=HELPrct) \n\n\n    Kruskal-Wallis rank sum test\n\ndata:  age by substance\nKruskal-Wallis chi-squared = 34.04, df = 2, p-value = 4.058e-08\n\nsummary(lm(age ~ substance, data=HELPrct))\n\n\nCall:\nlm(formula = age ~ substance, data = HELPrct)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1977  -5.4435  -0.4934   4.5565  25.5066 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       38.1977     0.5593  68.297  < 2e-16 ***\nsubstancecocaine  -3.7043     0.8228  -4.502 8.59e-06 ***\nsubstanceheroin   -4.7542     0.8714  -5.456 8.06e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.441 on 450 degrees of freedom\nMultiple R-squared:  0.07279,   Adjusted R-squared:  0.06867 \nF-statistic: 17.66 on 2 and 450 DF,  p-value: 4.122e-08\n\n\nWe will discuss the meaning of these tests in subsequent class sessions."
  },
  {
    "objectID": "chapt1.html#tables-in-r-two-categorical-variables",
    "href": "chapt1.html#tables-in-r-two-categorical-variables",
    "title": "3  Data displays",
    "section": "3.20 Tables in R: two categorical variables",
    "text": "3.20 Tables in R: two categorical variables\nWe can make cross-tabulations in R easily, using the Mosaic command tally.\n\ntally(~sex, data=HELPrct) \n\nsex\nfemale   male \n   107    346 \n\ntally(~substance, data=HELPrct)\n\nsubstance\nalcohol cocaine  heroin \n    177     152     124 \n\n\ntally can show counts, proportions, or percents, and it can show margins.\n\ntally(sex ~ substance, data=HELPrct, format=\"count\", margins=T) \n\n        substance\nsex      alcohol cocaine heroin\n  female      36      41     30\n  male       141     111     94\n  Total      177     152    124\n\ntally(sex ~ substance, data=HELPrct, format=\"proportion\", margins=F) \n\n        substance\nsex        alcohol   cocaine    heroin\n  female 0.2033898 0.2697368 0.2419355\n  male   0.7966102 0.7302632 0.7580645\n\ntally(sex ~ substance, data=HELPrct, format=\"percent\") \n\n        substance\nsex       alcohol  cocaine   heroin\n  female 20.33898 26.97368 24.19355\n  male   79.66102 73.02632 75.80645\n\ntally(~sex + substance, data=HELPrct, format=\"percent\")\n\n        substance\nsex        alcohol   cocaine    heroin\n  female  7.947020  9.050773  6.622517\n  male   31.125828 24.503311 20.750552\n\n\n\n3.20.1 Analyzing data in tables\nSeveral tests are possible: chi-square, McNemar. The McNemar test is for non-independent observations (e.g., comparison of the same subject over time.)\nThe chi-square test takes a table as input.\n\nchisq.test(tally(sex ~ substance, data=HELPrct)) \n\n\n    Pearson's Chi-squared test\n\ndata:  tally(sex ~ substance, data = HELPrct)\nX-squared = 2.0264, df = 2, p-value = 0.3631"
  },
  {
    "objectID": "chapt1.html#two-continuous-variables",
    "href": "chapt1.html#two-continuous-variables",
    "title": "3  Data displays",
    "section": "3.21 Two continuous variables",
    "text": "3.21 Two continuous variables\n\n3.21.1 R data object manipulation: apply\nWe’ve learned how to sum all the elements in a vector or matrix, but what if we want to sum only the columns or rows? We can use the apply command to apply a command to rows or columns of a matrix.\n\ntest.matrix=matrix(c(1:8), nrow=2, byrow=T) \ntest.matrix \n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n\napply(test.matrix, 2, sum) \n\n[1]  6  8 10 12\n\napply(test.matrix, 1, sum)\n\n[1] 10 26\n\n\nThe apply command is useful if we want to look for missing data in a dataset and see how many of each values are missing in the dataset.\nWe can go one by one through all of the variables in the dataset to see how many missing values they have using the is.na command. The HELPrct dataset has 27 variables, however, so it would take 27 commands to review that information. Instead, we can use apply to find out how many observations are missing from each variable.\n\ndim(HELPrct) \n\n[1] 453  30\n\nnames(HELPrct) \n\n [1] \"age\"              \"anysubstatus\"     \"anysub\"           \"cesd\"            \n [5] \"d1\"               \"daysanysub\"       \"dayslink\"         \"drugrisk\"        \n [9] \"e2b\"              \"female\"           \"sex\"              \"g1b\"             \n[13] \"homeless\"         \"i1\"               \"i2\"               \"id\"              \n[17] \"indtot\"           \"linkstatus\"       \"link\"             \"mcs\"             \n[21] \"pcs\"              \"pss_fr\"           \"racegrp\"          \"satreat\"         \n[25] \"sexrisk\"          \"substance\"        \"treat\"            \"avg_drinks\"      \n[29] \"max_drinks\"       \"hospitalizations\"\n\nsum(is.na(HELPrct$age)) \n\n[1] 0\n\nsum(is.na(HELPrct$anysub)) \n\n[1] 207\n\napply(apply(HELPrct, 2, is.na), 2, sum) \n\n             age     anysubstatus           anysub             cesd \n               0              207              207                0 \n              d1       daysanysub         dayslink         drugrisk \n               0              209               22                1 \n             e2b           female              sex              g1b \n             239                0                0                0 \n        homeless               i1               i2               id \n               0                0                0                0 \n          indtot       linkstatus             link              mcs \n               0               22               22                0 \n             pcs           pss_fr          racegrp          satreat \n               0                0                0                0 \n         sexrisk        substance            treat       avg_drinks \n               0                0                0                0 \n      max_drinks hospitalizations \n               0                0 \n\n\nWe can notice that the variables with the most missing data (missing 207, 209, and 239 observations) are missing responses from about half of the sample. That fact is important to note because any analysis that includes these variables will have half the sample size compared with an analysis that doesn’t use those variables."
  },
  {
    "objectID": "chapt1.html#exercise-1",
    "href": "chapt1.html#exercise-1",
    "title": "3  Data displays",
    "section": "3.22 Exercise",
    "text": "3.22 Exercise\nIn February 2015, the New England Journal of Medicine published a randomized controlled trial that assigned infants ages 4–11 months to be introduced to peanuts or to avoid peanuts. The study found that infants introduced to peanuts had much lower prevalence of peanut allergy at age 5 years old than infants who avoided peanuts: 3% among peanut eaters versus 17% among avoiders in intention-to-treat analysis. The study included the following plots. (George Du Toit, et al. Randomized Trial of Peanut Consumption in Infants at Risk for Peanut Allergy, NEJM. 2015; 372:803–813.)\n\n\n\nPlot from peanut consumption in infants at risk for peanut allergy\n\n\n\nDescribe how wheal sizes differed between the peanut avoidance and peanut consumption groups, and how they changed over time. Support your answer with reference to specific components of the data displays.\nDescribe how peanut specific IgE differed between the peanut avoidance and peanut consumption groups, and how they changed over time. Support your answer with reference to specific components of the data displays.\nWhy did the authors show both individual and aggregate measures in this data display?\nAssuming that the above data displays are accurate, in your opinion, are these effective displays of the data? Explain your answer.\nThe authors used graphical data displays instead of tables in their paper. The paper included zero tables. Why might they have used data displays instead of tables, in your opinion?\n\n\n3.22.1 Suggested answers\n\nDescribe how wheal sizes differed between the peanut avoidance and peanut consumption groups, and how they changed over time. Support your answer with reference to specific components of the data displays. Any reasonable answer will get credit.\n\nThe wheal sizes were bigger in the peanut avoidance group than in the peanut consumption group, both on average and individually. We can see the average wheal size as the dark black line which is practically zero in the peanut consumption group, but the mean is not zero and increases with time in the peanut avoidance group. We can see the individual wheal sizes among those allergic to peanuts as the red lines on the plot and notice only one person in the peanut consumption group had a peanut allergy and their wheal sizes increased over time, whereas many people in the peanut avoidance group had peanut allergies, and their wheal sizes increased over time. We can also notice that many children eating peanuts had nonzero wheal sizes, but they were not allergic. Wheal sizes were generally larger in the avoidance group, though.\n\nDescribe how peanut specific IgE differed between the peanut avoidance and peanut consumption groups, and how they changed over time. Support your answer with reference to specific components of the data displays.Any reasonable answer will get credit.\nPeanut specific IgE differed between the two groups, as we described for the skin wheal size. The patterns both on average and at mean were similar as we described above.\nWhy did the authors show both individual and aggregate measures in this data display?\n\nShowing both individual and mean measures in a data display lets readers decide for themselves what the data shows. We can see patterns in both the mean and individual data, and the patterns are the same. Any reasonable answer will get credit.\n\nAssuming that the above data displays are accurate, in your opinion, are these effective displays of the data? Explain your answer.\n\nI think these are effective displays of the data. They show a lot of information without overwhelming the reader. Every bit of ink is useful and conveys useful information to the reader. Any reasonable answer will get credit.\n\nThe authors used graphical data displays instead of tables in their paper. The paper included zero tables. Why might they have used data displays instead of tables, in your opinion?\n\nThe authors manage to display more information in these plots then would’ve been reasonable to put into a table. The readers of this article are busy doctors who do not have time to read tables, so the authors took time to figure out how to convey the information in an easy to read format that allows readers to see both individual and average trends over time. Making a table might be easier, but it would probably only show the average, which gives less useful information. A reader seeing this paper might wonder about individual variation from the mean because peanut allergies are so severe and sometimes means to conceal information. For example the reader might wonder whether any individuals in the peanut consumption group developed highly severe allergies, but this data display answers their question about how individuals vary from the group by showing wheal size and IgE levels for every participant, and we see that the one peanut allergic person in the peanut consumption group had relatively low wheal size and IgE levels, compared to those in the peanut avoidance group. Showing every individual in a table would not be feasible."
  },
  {
    "objectID": "chapt2.html#formulating-research-questions",
    "href": "chapt2.html#formulating-research-questions",
    "title": "4  Identifying research questions and data sources",
    "section": "4.1 Formulating research questions",
    "text": "4.1 Formulating research questions\nResearch questions have the following elements, which can be remembered by the acronym PICO.\n\n\n\n\n\n\n\n\nLetter\nMeaning\nExample\n\n\n\n\nP\nPatient or population\nAdolescents\n\n\nI\nIntervention or exposure\nsmoke cigarettes daily\n\n\nC\nComparison group\ndo not smoke cigarettes daily\n\n\nO\nOutcome\nwear a seat belt in a car consistently\n\n\n\nExample question: Are adolescents who smoke cigarettes daily less likely to wear a seat belt in a car consistently than adolescents who do not smoke cigarettes daily?\nComparison groups are sometimes left unstated, but that leads to ambiguities because often more than one comparison group is possible.\nE.g., Are adolescents who smoke cigarettes daily less likely to wear a seat belt in a car than adults who smoke cigarettes daily?"
  },
  {
    "objectID": "chapt2.html#summarizing-research-and-evaluating-research-quality",
    "href": "chapt2.html#summarizing-research-and-evaluating-research-quality",
    "title": "4  Identifying research questions and data sources",
    "section": "4.2 Summarizing research and evaluating research quality",
    "text": "4.2 Summarizing research and evaluating research quality\nLiterature review versus systematic review versus meta-analysis: in all cases, the papers are all about the exact research question.\nA paper may include additional background information. In the case of our example: the number of adolescents who are injured or killed by inconsistent seatbelt use, and a theory linking various risk-seeking behavior such as cigarette smoking and inconsistent seatbelt use. This background information is useful, but it isn’t considered part of the literature review.\n\n4.2.1 Systematic reviews in public health\nIn systematic reviews, researchers say how they found the papers that they are using. This flow diagram uses the PRISMA style source: Reporting Guidelines and the American Journal of Public Health’s Adoption of Preferred Reporting Items for Systematic Reviews and Meta-Analyses, Am J Public Health. 2012 May; 102(5): 780–784. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3483925/\n\n\n\nPRISMA diagram for systematic review\n\n\n\n\n4.2.2 Systematic reviews in epidemiology\nCDC’s Human Genome Epidemiologic Network has guidelines for how to conduct reviews. http://www.cdc.gov/genomics/hugenet/publications/index.htm#Guidelines\nEpidemiology has not established formal procedures for systematic reviews beyond those published in isolated peer-reviewed journal articles. Denison HJ, Dodds RM, Ntani G, et al. How to get started with a systematic review in epidemiology: an introductory guide for early career researchers. Archives of Public Health 2013, 71:21 http://www.archpublichealth.com/content/71/1/21 Systematic reviews in epidemiology: why are we so far behind? Int. J. Epidemiol. 2002; 31 (1): 6–12. http://ije.oxfordjournals.org/content/31/1/6.full\n\n\n4.2.3 Systematic reviews in health services research"
  },
  {
    "objectID": "chapt2.html#identifying-sources",
    "href": "chapt2.html#identifying-sources",
    "title": "4  Identifying research questions and data sources",
    "section": "4.3 Identifying sources",
    "text": "4.3 Identifying sources\n\n4.3.1 Peer-reviewed sources\nSearch database with free text or medical subject heading terms. Pubmed http://pubmed.gov\nThe library system is new, and the library is still working out problems. Contact the library right away if you have problems so they can help you before the assignment is due.\nIf your university does not give you free access to a paper and if the paper is not available for free via Pubmed, please write to the paper’s author to request it. An example email:\nDear Dr. Jones, I’m interested in citing your paper titled, XXX but unfortunately my university library does not subscribe. Could you please send me a copy? Thank you,\nYour name, MPH candidate\n\n\n4.3.2 Grey literature\nNon-peer-reviewed papers from government agencies and reputable think tanks.\n\n\n4.3.3 Hierarchy of evidence\nEvidence can be evaluated both by the study type and the quality of the study.\nLiterature reviews must attempt to resolve conflicts between studies, and also show flaws and openings in existing studies. Many people have tried to create a hierarchy of evidence.\n\n\n\nEvidence pyramid\n\n\nWe’re most concerned with the analytic studies, the top 4 levels of this diagram. The diagram is a good start, but it leaves out several study types (e.g., cross-sectional data, non-blinded RCTs, natural experiments), doesn’t deal with study quality (e.g., how much weight to give a RCT with high drop-out?), and it gives more space to the types of data that it deems less rigorous.\nThere are also rubrics for evaluating studies using prompts. Rubrics prompt reviewers to identify all important issues in the study, as well as to think about factors that were omitted from consideration, such as potential confounders. These rubrics are similar to the guide questions that students use in study evaluations.\nStudy quality is difficult to define comprehensively. To aid reviewers in assessing the quality of research, research organizations have established rubrics for evaluating studies. These rubrics are similar to the guide questions that you have used in your study evaluations in for the past 2 assignments. Ideally, rubrics prompt reviewers to identify all important issues in the study, as well as to think about factors that were omitted from consideration, such as potential confounders.\nEpidemiology has few bodies defining research quality.\nIn the field of health services research, at least 5 prominent bodies have established criteria for producing systematic reviews, including evaluating research quality.\n\nInstitute for Medicine (IOM), Finding What Works in Health Care: Standards for Systematic Reviews http://iom.nationalacademies.org/Reports/2011/Finding-What-Works-in-Health-Care-Standards-for-Systematic-Reviews.aspx\nPatient Centered Outcomes Research Institute (PCORI) methodology report Standards for Causal Inference Methods in Analyses of Data from Observational and Experimental Studies in Patient-Centered Outcomes Research, Final Technical Report, March 15, 2012, available from: http://www.pcori.org/research-results/research-methodology/pcori-methodology-report\nAgency for Healthcare Research and Quality (AHRQ)\nCochrane Collaboration: http://handbook.cochrane.org/\nU.S. Preventive Services Task Force (USPSTF): http://www.uspreventiveservicestaskforce.org/Page/Name/methods-and-processes\n\nOther fields have their own standards, such as education: Institute of Education Sciences (IES, in the federal Department of Education) WWC Procedures and Standards Handbook, http://ies.ed.gov/ncee/wwc/documentsum.aspx?sid=19, American Educational Research Association (AERA, a national research organization) (Schneider et al, Estimating Causal Effects: Using Experimental and Observational Methods, http://www.aera.net/Portals/38/docs/Causal%20Effects.pdf IES produced this diagram for evaluating RCTs:\n\n\n\nIES RCT evaluation criteria\n\n\nAll of these rubrics — including the rubric for evaluating studies that you will use in class — are just tools for evaluating research. Ultimately, reviewers must use their own judgement in evaluating studies and find balance between the ideal and the feasible.\n\n\n4.3.4 US Preventive Services Task Force guidelines\nUS Preventive Services Task Force defines studies as good, fair, or poor: “In general, a good'' study is one that meets all criteria well. Afair’’ study is one that does not meet (or it is not clear that it meets) at least one criterion but has no known fatal flaw.''Poor’’ studies have at least one fatal flaw.” http://www.uspreventiveservicestaskforce.org/uspstf08/methods/procmanualap7.htm\nThey give criteria that characterize a good study, e.g., for RCTs and cohort studies, the USPSTF says (continued quote from above webpage): ” Initial assembly of comparable groups: - For RCTs: adequate randomization, including first concealment and whether potential confounders were distributed equally among groups. - For cohort studies: consideration of potential confounders with either restriction or measurement for adjustment in the analysis; consideration of inception cohorts.\n\nMaintenance of comparable groups (includes attrition, cross-overs, adherence, contamination).\nImportant differential loss to follow-up or overall high loss to follow-up.\nMeasurements: equal, reliable, and valid (includes masking of outcome assessment).\nClear definition of interventions.\nAll important outcomes considered.\nAnalysis: adjustment for potential confounders for cohort studies, or intention to treat analysis for RCTs.”\n\n\n\n4.3.5 PCORI guidelines\nPCORI has 2 preliminary requirements:\n\nclearly articulate a specific causal hypothesis;\nprecisely define relevant exposures and outcomes\n\nand 8 causal inference requirements:\n\nAssess data source adequacy: In selecting variables for confounding adjustment, assess the suitability of the data source in terms of its capture of needed covariates.\nDefine analysis population using information available at study entry: Inclusion in an analysis should be based on information available at the time of study entry and not based on future information.\nDescribe population that gave rise to the effect estimate(s): As many design and analytic strategies impose restrictions on the study population, the actual population that gave rise to the effect estimate(s) should be described.\nDefine effect period of interest: Precisely define the timing of the outcome assessment relative to the initiation and duration of therapy\nSelect appropriate comparators: When evaluating an intervention, the comparator treatment(s) should be chosen to enable accurate evaluation of effectiveness or safety.\nMeasure confounders before start of exposure: In general, variables measured for use in adjusting for confounding should be ascertained prior to the first exposure to the therapy (or therapies) under study.\nAssess propensity score balance: When propensity scores are used, assess the balance achieved across compared groups with respect to potential confounding variables.\nAssess instrumental variable assumptions: If an instrumental variable approach is used, then empirical evidence should be presented describing how the variable chosen as an IV satisfies the three key properties of a valid instrument."
  },
  {
    "objectID": "chapt2.html#data-types",
    "href": "chapt2.html#data-types",
    "title": "4  Identifying research questions and data sources",
    "section": "4.4 Data types",
    "text": "4.4 Data types\nAdministrative data: anything created for official purposes: birth, death certificates, tax forms, transcripts, medical records, crime records, voting records, medical billing.\nSurvey data: self-reported responses from a sample of participants.\nBiomarkers: Medical tests conducted by researchers\nRegistry data\nStandardized tests as part of a survey\nScreening test results (e.g., CES-D) as part of a survey\nSelf-report items (e.g., survey items about attitudes, behaviors, demographics)\n\n4.4.1 Survey datasets\nPeople refer to survey datasets, but surveys often have multiple components.\nThe National Longitudinal Study of Adolescent Health (Add Health)\n\nsurveys of adolescent participants: in school (1994–95), in home waves 1–5+ (1995, 1996, 2001, 2008, unspecified future year).\nsurvey of parents (1995)\nsurvey of school administrators for 125/128 schools\nadministrative data: students’ high school transcripts in 2001\nbiomarker data: measured height, weight in all waves. STI (urine) tests in 2001; measured waist, blood pressure, blood tests in 2008.\n\nSurvey design is a craft as much as a science. People who research how to improve surveys are centered at a small number of universities (e.g., Michigan and Maryland’s Joint Program in Survey Research is the oldest), a small number of research institutes (e.g., RAND and Mathematica Policy Research), and the 13 federal government statistics agencies, but especially at Census and Bureau of Labor Statistics. Unlike some areas of research methods, in many cases, the field has not changed much in the past 30–40 years, so many book editions as early as the 1970s or 1980s are still relevant.\nClassic texts in survey research include Floyd (Jack) Fowler, Survey Research Methods and Improving Survey Questions, (SAGE). Related texts include: Peter Rossi, Evaluation: a systematic approach; Richard Krueger and Mary Ann Casey, Focus Groups; Creswell Research Design; Nunnally and Bernstein, Psychometric Theory.\nSame information can be collected in multiple ways. E.g., crime information. Each type of data yields different estimates due to differential reporting.\n\nNCVS/ICVS: National/international crime victimization surveys: household-based surveys.\nAdministrative crime data.\nOther nationally representative surveys for particular issues: e.g., lifetime forced sex is collected on sexual health surveys, such as Add Health.\n\n\n\n4.4.2 Three+ types of validity:\nInternal validity: causal inference\nexternal validity: generalizability\nmeasurement validity: whether a measure assesses what it claims to assess. E.g., whether an IQ test measures intelligence.\nReliability is distinct.\nSurvey data concepts:\nCensus (entire population) vs. survey (subsample of population).\nSampling frame: list of potential participants\nSampling unit: participants\nTypes of samples\n\nStratified sample: divide the population into strata and sample from each stratum. e.g., divide the country into 4 regions (NE, W, S, MW) and choose samples from each region.\nCluster sample: sample groups of participants in logical groupings such as schools or households, rather than as individuals.\nMulti-level survey designs: Any combination of above sampling methods. E.g, sample schools from each region, sample individuals within each school.\n\nOversample: sampling more from target populations to ensure sufficient sample size.\nSampling method: systematic, random, convenience. Influences how representative the sample is of the population.\nQuestionnaire administration: Self-administered, interview (in person or over phone).\nTypes of self-administered surveys: (audio) computer-administered survey `interview (ACASI), pen and paper (e.g., Scantron).\nResearchers use power calculations to estimate necessary population for desired inferences.\n``Too small to be nationally representative’’ is impossible.\nNationally representative is a construct: representativeness is always in reference to a specific population (e.g., noninstitutionalized population, people with phone numbers.) Some of these populations are close to the same thing as nationally representative, but not identical.\nHigh participation rates and retention rates require a great deal of attention: e.g., paying participants $20 cash up front before they do anything."
  },
  {
    "objectID": "chapt2.html#survey-question-development",
    "href": "chapt2.html#survey-question-development",
    "title": "4  Identifying research questions and data sources",
    "section": "4.5 Survey question development",
    "text": "4.5 Survey question development\nGood survey questions minimize ambiguity.\nSurvey questions go through extensive testing: e.g, cognitive interviews.\nQuestions that have a distribution of answers gives the most useful information: if nearly all respondents give a single answer, that question isn’t as useful as if the answers were more spread out.\nAsk questions one at a time. Avoid double-barreled questions.\n- Double-barreled question: Have you been diagnosed with herpes and/or syphilis in the past year?\n-Better: divide into two questions: (1) Have you been diagnosed with herpes in the past year?; (2) Have you been diagnosed with syphilis in the last year?\nAvoid biased/leading questions.\n\nBiased/Leading: Community organizing is hard. Do leadership trainings help you feel prepared for community organizing?\nBetter: Do you feel prepared for community organizing after attending the leadership training sessions?\n\nAvoid awkward constructions, such as the double negative.\n\nBad: Do you agree or disagree with the following statement? I have never felt excluded by my classmates during recess.\nBetter: Do you agree or disagree with the following statement? I have felt excluded by my classmates during recess.\n\nAvoid jargon.\n\nJargon example: Have you used hormonal contraception in the past year?\nBetter: Indicate which of the following forms of contraception that you have used in the past year by filling in the yes'' bubble next to it.  Otherwise markno’‘. Oral contraception (the pill''),the patch’‘, depo-provera (the shot''), Norplant,the ring’’.\n\nInclude a time-frame in your questions.\n\nLack of time-frame: Do you use oral contraception (``the pill’’)?\nClear time-frame: Have you used oral contraception in the past month?\n\nAnswers to close-ended questions must be exhaustive and mutually exclusive.\n\nBad: Question to adolescents: What is your current age?\nAnswer choices: <12, 13, 14, 15, 16, 17, 18, 19+\nBetter: Question to adolescents: What is your current age? Answer choices: <12, 12, 13, 14, 15, 16, 17, 18, 19+\nBad: What is your marital status? Answer choices: married, never married, divorced.\nBetter: What is your marital status? Answer choices: married, never married, divorced, legally separated, in a civil union, widowed.\n\nDon’t throw away information before you begin collecting data. Don’t group answers until you get your data, unless it makes a huge difference to the survey’s response burden.\n\nBad: Question to adolescents: What is your current age? Answer choices: 12–14, 15–16, 17–18, 19+\nBetter: Question to adolescents: What is your current age? Answer choices: <12, 12, 13, 14, 15, 16, 17, 18, 19+\nBad: Were you threatened by a gun or knife in school?\nBetter: either decouple as per double-barreled example, or ask which of the following weapons you were threatened with in school.\n\nTo minimize social desirability bias, some questions are phrased in somewhat leading way, ``How many times in the past 12 months have you used marijuana?’’\nIncome questions are less likely to be answered, so usually at the end.\nBranching is confusing, so used mostly for interviewer- or computer- administered surveys.\n\n4.5.1 Capture recapture estimates of populations\nReporting systems seem as though they would be complete, but they are not accurate for non-urgent diseases. E.g., it’s estimated that among 100 cases of shigella, 76 will be symptomatic, 28 go to doctor, 9 had stool culture, 7 had positive stool culture (Rosenberg et al 1977).\nMusic manuscripts example\nEpidemiologists use capture-recapture method to determine under-reporting."
  },
  {
    "objectID": "chapt2.html#using-data",
    "href": "chapt2.html#using-data",
    "title": "4  Identifying research questions and data sources",
    "section": "4.6 Using data",
    "text": "4.6 Using data\n\n4.6.1 Youth Risk Behavior Survey\nYouth Risk Behavior Survey YRBS data are available here for the public. https://www.cdc.gov/healthyyouth/data/yrbs/index.htm\nI’ve converted and put it on our courses’s Sharepoint.\nNavigating the codebook\nCodebooks list the variable name, question wording, possible answers, coding, and often the variable frequencies. In the YRBS codebook, the variable name, the question wording, and possible answers appear in the initial part of the codebook. The next part of the codebook lists the frequencies of all variables and number of missing cases.\nEach question is coded with two versions: the raw data with all possible answers and a dichotomous coded variable. The codebook shows which answer choices were coded yes, no, and (sometimes) not applicable with a note about the numerator and denominator. For instance, the dichotomous version of the question about number of sexual partners excludes teens who have never had sex.\nRace/ethnicity allows multiple answers, so use the coded variables rather than the original question."
  },
  {
    "objectID": "chapt2.html#citations",
    "href": "chapt2.html#citations",
    "title": "4  Identifying research questions and data sources",
    "section": "4.7 Citations",
    "text": "4.7 Citations\nFor papers, please use American Medical Association (AMA) citation style. Many libraries have made their citation guides available on the internet.\n\nLast name first followed by initials. No periods after initials, no comma between last name and first name.\nPeriods used to separate most elements.\nTitle of journal article is written in title case. Only the first word of each title is capitalized. Sometimes the first word after a colon is capitalized.\nJournal title is all capitalized and italicized.\nYear;Volume(Number):Page range.\nBooks, chapters in books, websites, and technical reports are cited similarly.\n\nExample:\nRosenbaum JE. Reborn a virgin: adolescents’ retracting of virginity pledges and sexual histories.American Journal of Public Health. 2006; 96(6):1098–1103.\n\n4.7.1 National Health Interview Survey (NHIS)\nNHIS data is available here: https://www.ipums.org/healthsurveys.shtml"
  },
  {
    "objectID": "chapt2.html#exercise",
    "href": "chapt2.html#exercise",
    "title": "4  Identifying research questions and data sources",
    "section": "4.8 Exercise",
    "text": "4.8 Exercise\n\n4.8.1 Project research question\nYou will be doing a semester-long project using the Youth Risk Behavior Survey or another dataset that the instructor has approved. If you are interested in using a dataset other than YRBS, discuss with the instructor as soon as possible. Review the codebook for YRBS or the other dataset and identify an item that particularly interests you that will be an outcome for a study that you will conduct. Identify a second item that may be an important and interesting predictor of your item of interest; the second item should not be a demographic factor. Later you will add demographic factors and test for differences by these factors.\nState the items that you chose from YRBS and the research question that you plan to answer using YRBS. Make sure that your research question includes all necessary components of a research question: Population, Intervention, Comparison group, and Outcome (PICO). Email instructor with your proposed research question and obtain approval before proceeding.\n\n\n4.8.2 Identify elements of published papers\nPrepare summaries of 2 papers, using past issues of the American Journal of Epidemiology or any other public health journal. http://aje.oxfordjournals.org/content/current\n\nPopulation of interest\nSample\nData source and brief description\nWho collected this data? If you wanted to analyze this dataset, could you access it? How?\nOutcome\nMain predictor\nType of study, and how you know:\nSummary of findings:\nResearch question:\n\n\n\n4.8.3 Data scavenger hunt\nFind one or more examples of datasets with each of the following characteristics. If possible, say if the data would be accessible to general researchers. Try to find more than the obvious examples for each.\n\nUses death certificates\nUses birth certificates\nA dataset that samples individuals from multiple US states, or compiles data from multiple US state surveys.\nAs above, but the dataset identifies the states.\nA dataset that samples individuals from multiple countries. %, or compiles data from multiple country surveys.\nIdentify datasets for studying health disparities. %Some large datasets in existence include one that focuses on Asian-Americans, one that focuses on Blacks including an over-sample of foreign-born Blacks.\nCollects sexual minority status from a nationally representative sample of adolescents, such as lesbian/gay/bisexual identity or sexual activity with same-sex partners.\nCollects opinions of a nationally representative sample of Americans about social issues for many decades.\nA dataset that includes all US income tax returns (hint: search for papers that use this data.)\nCollects information on whether individuals own guns.\nIncludes actual voter participation records\nIncludes information on individuals’ diet choices\nLongitudinal data that follows children for long periods.\nLongitudinal data that follows teenagers from just before high school graduation for several years.\nData that includes individuals’ driving risk behavior\nLongitudinal data from a large nationally representive sample of middle-aged US adults.\nData that tests a large sample of participants for STIs (other than Add Health)\nData that include reported cases of vector-borne diseases\nData that includes tobacco tax levels in different countries or states.\nData that includes public attitudes about social issues, such as attitudes towards inter-racial relationships or same-sex marriage.\nData that collects information about respondents’ sexual behavior, such as number of sex partners or extramarital relationships.\nIncludes a wide variety of data from Americans diagnosed with cancer.\nData from all birth certificates for children born in the US in a recent year\nData to study health issues for different populations in NYC\nHealth data from early adolescents in many countries around the world\nData that can be used to answer a question that you are interested in.\n\n\n\n4.8.4 Data set exercise\nFor each of the below papers, identify the research question, making sure that you have identified all elements of the PICO acronym: Population, Intervention or Exposure, Comparison group, and Outcomes of intervention/exposure. Then, find the datasets used by the following papers and figure out how one could access and use the dataset, and whether it would be feasible for an MPH or DrPH student to use this data for research. Which datasets were collected primarily for health purposes, and which were collected primarily for other purposes?\nFor each dataset, answer the following questions: - What type(s) of data is it? If the dataset uses more than one type of data, state that. - Can you find anything out about the history or purpose of the data?\n\nWho may access it?\nHow is it accessed? E.g., costs, application procedure. Would it be feasible for a student to use this data for their ILE?\n\n\n\n4.8.5 Data set exercise\nDevelop a research question and identify dataset(s) to address one of the following grant requirements:\n\nIdentify data from RCTs of early life interventions, link them together, and follow-up using existing data.\nStudy the effects of recent changes in public policy towards marijuana on substance use. - Analyze existing data about alcohol use (i.e., identify a dataset that collects information about alcohol use and identify research question.)\n\n\n\n4.8.6 Literature review\nWrite an annotated bibliography for the research question involving the 2 constructs that you chose. You must use at least 5 papers from the peer-reviewed medical literature with analytic designs, not qualitative or descriptive. They must be about both constructs, not just one: e.g., if you are studying TV watching and obesity, studies of diet and obesity are off-topic.\nPopulate a table with the following headers to ensure that your papers are all on topic and relevant to the population of US adolescents:\n\n\n\nReference\nExposure\nOutcome\nStudy design\nPopulation\nResults\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter populating the table, identify at least 5 papers in the peer-reviewed medical literature about the research question involving the 2 constructs that you have chosen. They must be about the exact same topic, not a slightly related topic. Use these papers to write a literature review. A literature review should have the following elements:\n\nBrief background explaining why the topic is important, and why you expect that the two chosen variables may be related (1–3 sentences.) Any citations in this section do not count towards the 5 papers.\nStatement of the research question in the form of a statement.\nSynthesis of the 5 papers. Synthesis of the evidence, including explaining why the research may contradict, and speculate about what your research may be able to add. Explain why there may be differences and what causes them, rather than listing superficial or obvious differences.\nList of references. References should be in AMA format or another valid format, such as APA.\n\nNotes:\n\nPaper summaries should not mention the paper’s title, journal, and usually do not mention the author or year.\nAvoid jargon. If you use a technical term that a non-specialist might not understand, explain it, and explain how it relates to the topic (e.g., if it’s a statistical method, explain why it’s helpful to use that method.)\nIf a paper comes from a different population than your sample (e.g., for YRBS, a country other than the US, a non-Western country, or non-adolescent age group), address whether their findings might differ from what you are likely to find in YRBS and explain whether it makes a difference.\nUse academic writing style. Avoid using colloquial style."
  },
  {
    "objectID": "chapt3.html#parametric-vs-non-parametric-comparisons",
    "href": "chapt3.html#parametric-vs-non-parametric-comparisons",
    "title": "5  Testing hypotheses",
    "section": "5.1 Parametric vs non-parametric comparisons",
    "text": "5.1 Parametric vs non-parametric comparisons\nParametric comparisons only work under certain conditions, such as if variables have certain distributions. Non-parametric comparisons always work.\nExamples: mean versus median. Examples: t-tests versus tests of medians.\nBivariate analysis Review: t-test and Wilcoxon test Recall that T-tests are tests of whether means differ from each other. Parametric confidence intervals are formed around the mean plus or minus the t coefficient for the data degrees of freedom times the standard deviation. For large sample size, the t- coefficient approaches 1.96, which you can just call 2. Recall that the Wilcoxon test is a test of medians. Nonparametric confidence intervals are formed around the median (the 50th percentile, the middle observation of the dataset). An example of a common nonparametric confidence interval is the interquartile range (IQR), the middle 50% of the dataset, between the 25th and 75th quartiles. The IQR is a nonparametric 50% confidence interval, although it’s not actually referred to that way. A non-parametric 95% confidence interval is the range between the 2.5 percentile and the 97.5 percentile: that is, the middle 95% of the data. Using a nonparametric test when a parametric test could be used reduces power slightly, in the case of using the Wilcoxon test instead of the t-test. For other nonparametric tests, the difference may be larger. For multiple categories, the nonparametric equivalent of the Wilcoxon test is the Kruskal- Wallis test.\n\n5.1.1 t-test\nt-test Random independent samples from a normal distribution. Gossett derived this formula in early 1900s from work at Guinness brewery; RA Fisher proved Gossett’s formula correct in 1925.\nIncreased sample size: parameter estimate −→ population average.\nIf population has a standard deviation of σ, se(\\(\\bar{Y}\\)) = σ/√n, which has n-1 degrees of freedom.\nThe t-test follows from this definition, and also has df = n − 1.\nt = (estimate − parameter)/ se(estimate)\nt-test is relatively robust against departures from normality.\nComparing means, medians, and quartiles.\nGraphical summaries: density plots, box and whisker plots, histograms Parametric and non-parametric tests, primarily the t-test and the Wilcoxon-Mann-Whitney rank-sum test.\n\n\n5.1.2 Conditions for t-test\nIf two populations have the same standard deviations σ1 ≈ σ2 and approximately the same shapes.\nIf approximately the same sample sizes n1 ≈ n2, t-test is moderately impacted by long tails and not impacted much by skewness.\nIf sample sizes differ by too much n1 ̸= n2, t-test is moderately impacted by long tails and substantially impacted by skewness, but matters less for large samples.\nIf the skewness of the two populations differs considerably, t-tests can be misleading with small and moderate sample sizes.\nIf observations are not independent of each other — such as if data were collected in clusters of individuals, time, or space— then the t-test is not appropriate because the standard error does not accurately measure the difference in averages.\nSimulation of how often t-tests are correct\n\n\n5.1.3 Rank-sum test for unpaired data\nAlso called the Wilcoxon or Wilcoxon-Mann-Whitney test.\nNon-parametric alternative to the t-test\nOrders the data and adds the ranks in each group.\nEvaluates whether medians differ.\nAdvantages: versatile, only slightly lower power than t-test.\nDisadvantages: No confidence intervals.\n\n\n5.1.4 Non-parametric test for paired data\nWilcoxon signed-rank test.\nSign test: tests hypothesis of no difference by evaluating whether about half of the differences between pairs are positive.\nEvaluate with exact binomial test (n=number of pairs, probability of success = 0.5)\nPermutation test — given two samples, rearrange the data N times, and see which percentage of those permutations are at least as extreme as the observed group differences.\nParametric tests for 2 groups Test and Command z-test chi-squared test chisq.test() t-test t.test() Assumptions/purpose Continuous variable has normal distribution Equivalent to z-test for 2 groups If z is normally distributed, z2 ∼ χ2(1). Random samples from symmetric distribution. Paired (paired=T) or unpaired (paired=F). Paired form uses a comma instead of tilde."
  },
  {
    "objectID": "chapt3.html#effect-size",
    "href": "chapt3.html#effect-size",
    "title": "5  Testing hypotheses",
    "section": "5.2 Effect size",
    "text": "5.2 Effect size\nEffect size P-values have been widely criticized because they are affected by large sample size. A clinically small effect in a large sample size will have a small p-value. Some journals have even banned p-values. “Effect size” is a general term meaning the size of the observed effect, and many measures including odds ratios, relative risks, and risk differences can serve as measures of effect size. In addition to these effect size measures, some specific measures are called effect size measures.\nWe can calculate Cohen’s effect size as the difference in means divided by the average standard deviation. This measure can take on any numerical value. Cohen’s effect size is evaluated by the rule of thumb that Cohen’s effect size (in absolute value) below 0.2 is inconsequential, between 0.2–0.5 is small, 0.5–0.8 is medium, and above 0.8 is large. Cohen’s effect size can be larger than 1. There are a number of other effect size measures like Hedge’s g that are slight variations on Cohen’s measure.\n\n\n\n\n\n\n\n\n\nTest\nR command\nOptions/notes\n\n\n\n\n\nchi-squared test\nchisq.test(tally())\nThe argument is a 2x2 table, so need to tally inside the chi-squared test command\n\n\n\nt-test\nt.test\npaired=T for paired data\n\n\n\nWilcoxon rank-sum test\nwilcox.test\npaired=T for paired data\n\n\n\nRegression\nlm()\n\n\n\n\nSummary statistics\nfavstats\n\n\n\n\nEffect size\nCalculate by hand\nNew library effectsize has functions like cohens_d()"
  },
  {
    "objectID": "chapt3.html#example-height-differences-by-gender",
    "href": "chapt3.html#example-height-differences-by-gender",
    "title": "5  Testing hypotheses",
    "section": "5.3 Example: Height differences by gender",
    "text": "5.3 Example: Height differences by gender\nFrancis Galton created a famous dataset of heights of adults and their parents, and it is in the mosaic package. The data has been cleaned of non-numeric entries for height such as “tall”, “short”, “idiotic”, and “deformed.”1 In this dataset, what is the difference btween males and females? The favstats command we learned already. The t-test comand is new.\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nfavstats(~height, groups=sex, data=Galton)\n\n  sex min   Q1 median   Q3  max     mean       sd   n missing\n1   F  56 62.5   64.0 65.5 70.5 64.11016 2.370320 433       0\n2   M  60 67.5   69.2 71.0 79.0 69.22882 2.631594 465       0\n\nhistogram(~height | sex, data=Galton, auto.key=T, col=\"white\")\n\n\n\nt.test(height ~ sex, data=Galton)\n\n\n    Welch Two Sample t-test\n\ndata:  height by sex\nt = -30.662, df = 895.02, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group F and group M is not equal to 0\n95 percent confidence interval:\n -5.446293 -4.791018\nsample estimates:\nmean in group F mean in group M \n       64.11016        69.22882 \n\nwilcox.test(height ~ sex, data=Galton)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  height by sex\nW = 15256, p-value < 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\nMales are on average 5’9” and females are on average 5’4” — males are between 4.8 and 5.4 inches taller than females, according to a 95% confidence interval."
  },
  {
    "objectID": "chapt3.html#help-rct",
    "href": "chapt3.html#help-rct",
    "title": "5  Testing hypotheses",
    "section": "5.4 HELP RCT",
    "text": "5.4 HELP RCT\nWe can use significance tests in the Health Evaluation and Linkage to Primary Care RCT for both continuous and categorical variables. A common concern in randomized trials is whether randomization resulted in similar numbers of important variables. We can evaluate whether there’s any age difference by treatment status.\n\nhistogram(~age | treat, data=HELPrct, auto.key=T, col=\"white\")\n\n\n\nfavstats(age ~ treat, data=HELPrct)\n\n  treat min Q1 median Q3 max     mean       sd   n missing\n1    no  20 31     35 41  59 36.30263 8.141945 228       0\n2   yes  19 30     35 39  60 34.99556 7.205217 225       0\n\nwilcox.test(age ~ treat, data=HELPrct)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  age by treat\nW = 27592, p-value = 0.1629\nalternative hypothesis: true location shift is not equal to 0\n\n\nBased on the histogram, the age distribution may be slightly right-skewed, so we use a Wilcoxon test. We see that there is no difference on average in the ages of the treatment and control participants, who are both 35 years old at median (control group IQR 31–41, treatment group IQR 30–39)). The primary outcome of the study may have been days to linkage to primary care. We can do a bivariate analysis of that outcome.\n\nhistogram(~dayslink | treat, data=HELPrct, auto.key=T, col=\"white\")\n\n\n\nfavstats(dayslink ~ treat, data=HELPrct)\n\n  treat min  Q1 median  Q3 max     mean       sd   n missing\n1    no   9 331  365.0 365 456 322.7081 103.7741 209      19\n2   yes   2  35  120.5 365 449 192.4324 161.1661 222       3\n\nwilcox.test(dayslink ~ treat, data=HELPrct)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  dayslink by treat\nW = 32910, p-value = 1.379e-14\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe see from the histogram that it’s definitely not a symmetric distribution. At median, the treatment group was linked to primary care within 121 days and the control group was linked to primary care wthin 365 days, which is a statistically significant difference (p < 0.001). Sometimes, results are statistically significant without being important, so we can calculate a Cohen’s effect size from the information in the favstats output: (322.7-192.4)/((103.8+161.2)/2)=0.98 whch is a large Cohen’s effect size. Another primary outcome may have been time to use any substance.\n\nhistogram(~daysanysub | treat, data=HELPrct, auto.key=T, col=\"white\")\n\n\n\nfavstats(daysanysub ~ treat, data=HELPrct)\n\n  treat min   Q1 median     Q3 max     mean       sd   n missing\n1    no   0 3.00   32.0 161.00 260 72.35088 78.74468 114     114\n2   yes   0 7.25   41.5 164.75 268 77.90000 79.88071 130      95\n\nwilcox.test(daysanysub ~ treat, data=HELPrct)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  daysanysub by treat\nW = 6957, p-value = 0.4105\nalternative hypothesis: true location shift is not equal to 0\n\n\nThe distribution of days to any substance use is highly right-skewed due to zero inflation (many had 0 days to use any substance). At median, the treatment group had 41.5 days to use any substance and the control group had 32.0 days to use any sbustance, but the difference is not statistically signfiicant (p=0.4). However, among the treatment group 95 observations were missing and among the control group 114 were missing, which is close to half of each group, and we don’t know why. Another primary outcome may have been whether they used any substance after treatment. We can also do a significance test for that outcome.\n\ntally(anysub ~ treat, data=HELPrct, format=\"percent\")\n\n      treat\nanysub       no      yes\n  no   11.40351 13.33333\n  yes  39.03509 44.88889\n  <NA> 49.56140 41.77778\n\ntally(anysub ~ treat, data=HELPrct, format=\"percent\", useNA=\"no\")\n\n      treat\nanysub       no      yes\n   no  22.60870 22.90076\n   yes 77.39130 77.09924\n\nchisq.test(tally(anysub ~ treat, data=HELPrct, format=\"count\"))\n\n\n    Pearson's Chi-squared test\n\ndata:  tally(anysub ~ treat, data = HELPrct, format = \"count\")\nX-squared = 2.7678, df = 2, p-value = 0.2506\n\n\nAfter excluding missing observations, there’s no difference in the percentage who used any substance after detox between the treatment and control groups (77.1% treatment group vs. 77.4% control group, p=0.3); as before, there was substantial missing data."
  },
  {
    "objectID": "chapt3.html#statistical-significant",
    "href": "chapt3.html#statistical-significant",
    "title": "5  Testing hypotheses",
    "section": "5.5 Statistical significant",
    "text": "5.5 Statistical significant\n\n\n\nStatistically significant others xkcd\n\n\n“… okay, but because you said that, we’re breaking up.” (Source:xkcd)"
  },
  {
    "objectID": "chapt3.html#interpreting-test-results",
    "href": "chapt3.html#interpreting-test-results",
    "title": "5  Testing hypotheses",
    "section": "5.6 Interpreting test results",
    "text": "5.6 Interpreting test results\n\n\n\nFurther research is needed, xkcd\n\n\n“Further research is needed to fully understand how we managed to do such a good job.” Source: xkcd"
  },
  {
    "objectID": "chapt4.html#person",
    "href": "chapt4.html#person",
    "title": "6  Associations",
    "section": "6.1 Person",
    "text": "6.1 Person\nPersonal characteristics: age, gender, race/ethnicity, SES, marital status."
  },
  {
    "objectID": "chapt4.html#place",
    "href": "chapt4.html#place",
    "title": "6  Associations",
    "section": "6.2 Place",
    "text": "6.2 Place\nPlace characteristics: Geographic dispersion: location in neighborhood, country, hospital.\n\n6.2.1 Example of person and place: John Snow\nIn 1855, John Snow made the following cross-tabulation showing the rate of cholera among customers of 2 different London water providers. In 1852, Lambeth changed its intake pipe on the Thames to be upstream to avoid sewage contamination of the water. Southwark and Vauxhall kept the same intake pipe. John Snow evaluated whether there were any systematic differences between houses getting water from one company versus the other.\n“The mixing of the [water] supply is of the most intimate kind. The pipes of each Company go down all the streets, and into nearly all the courts and alleys. A few houses are supplied by one Company and a few by the other, according to the decision of the owner or occupier at the time when the Water Companies were in active competition. In many cases, a single house has a supply different from that on either side. Each company supplies both rich and poor, both large houses and small; there is no difference either in the condition or occupation of the persons receiving the water of the different Companies. … It is obvious that no experiment could have been devised which would more thoroughly test the effect of water supply on the progress of cholera than this…. [The new intake pipe] divided into two groups without their choice, and, in most cases, without their knowledge; one group being supplied with water containing the sewage of London, and, amongst it, whatever might have come from the cholera patients, the other group having water quite free from such impurity.” (John Snow, 1855, On the Mode of Communication of Cholera London: John Churchill, 2nd edition. Reprinted in Snow on Cholera, London: Humphrey Milford; Oxford University Press, 1965)\n\n\n\n\n\n\n\n\n\nCompany\nNumber of houses\nCholera deaths\nDeath rate per 10,000\n\n\n\n\nSouthwark and Vauxhall\n40,046\n1263\n315\n\n\nLambeth\n26,107\n98\n37"
  },
  {
    "objectID": "chapt4.html#time",
    "href": "chapt4.html#time",
    "title": "6  Associations",
    "section": "6.3 Time",
    "text": "6.3 Time\nTime variation: secular trends, cyclical variation (season/month/day of week/time of day), birth cohorts.\nExample: A study in a children’s hospital emergency department in Colorado from 2005–2011 compared the proportion of marijuana ingestions by young children before and after medical marijuana legalization in October 2009. They looked at 1378 patients below age 12 evalu- ated for unintentional ingestions: 790 patients until September 30, 2009, and 588 patients on or after October 1, 2009. Out of 790 patients evaluated for unintentional ingestions before 9/30/09, none were related to marijuana exposure (0%; 95% CI, 0%–0.6%). Out of 588 patients evaluated for unintentional ingestions on or after 10/1/09, 14 were related to marijuana exposure (2.4%; 95% CI, 1.4%–4.0%), a significant increase (P <.001). Out of 14 unintentional marijuana exposures, 8 involved medical marijauana, and 7 were from food products. (Wang GS, Roosevelt G, Heard K., Pediatric Marijuana Exposures in a Medical Marijuana State. JAMA Pediatr. 2013 May 27:1–4.)\nWhat’s the research question? What’s the study design? Is the study design valid for answering their research question?\nA small number of sick people are generally responsible for a large proportion of health care spending. Employers try to reduce their health care costs by reducing the costs of the sickest members of their insurance pools. A medication therapy management (MTM) program invited high-risk members in a large employer group. The MTM treatment group comprised 2250 members who accepted, and the control group comprised 2250 members who decliend the invitation but were matched to the treatment group on unspecified characteristics. The MTM and control groups were compared for the year before versus after the MTM program invitations. The researchers assessed several measures of health care usage and spending, as well as medication possession ratios (MPRs) for 5 chronic conditions. Results: “MTM members significantly reduced their plan-paid health care costs by 10.3% or $977, compared with an increase of 0.7% or $62 in the control group (P=0.048). Inpa- tient visits in the MTM group decreased by 18.6%, while the control group experienced an increase of 24.2% (P < 0.001). While both groups had decreases in ER visits, the groups were not significantly different (P=0.399). Average days supply for the MTM group increased by 72.7 days over baseline; for the control group, it decreased by 111.1 days (P<0.001). MTM members with hypertension and dyslipidemia had pre-post in- creases in MPR of 2.29% and 2.10%, respectively, while the control group had decreases of 2.31% and 2.61% (both P < 0.001). The mean MPRs for members with diabetes, depression, and asthma did not change in either group. Program costs per patient in 2009 were estimated to be $478. The program had a return on investment (ROI) of 2.0 in 2009.” Moore JM, Shartle D, Faudskar L, Matlin OS, Brennan TA. Impact of a patient-centered pharmacy program and intervention in a high-risk group. J Manag Care Pharm. 2013 Apr;19(3):228–36. (a) What’s the research question? (b) What’s the study design? (c) Is the study design valid for answering their research question? (d) Compare this study with the above study."
  },
  {
    "objectID": "chapt4.html#non-identifiability",
    "href": "chapt4.html#non-identifiability",
    "title": "6  Associations",
    "section": "6.4 Non-identifiability",
    "text": "6.4 Non-identifiability\nNon-identifiability is a statistical term relating to the inability to separate the impact of many different inter-related factors. The extreme of non-identifiability: two factors completely deter- mine the third. Example from the book: calendar year, age, and year of birth. Also true for inter-related factors such as race/ethnicity, income, and education."
  },
  {
    "objectID": "chapt4.html#bias",
    "href": "chapt4.html#bias",
    "title": "6  Associations",
    "section": "6.5 Bias",
    "text": "6.5 Bias\nBias arises whenever there are systematic differences between the two groups (e.g., cases vs. controls, exposed vs unexposed, treatment vs. controls) that could explain or conceal differences between groups. - Bias towards the null - Bias away from the null\nWhen proposing potential biases, specify the type of bias (e.g., information, selection), how and in what direction the bias would impact the findings, and, if possible, how the researchers could prevent the bias. The term “bias” without further elaboration is meaningless.\n\n6.5.1 Selection bias\nSelection bias may partially explain research findings, if the two groups (cases vs. controls, exposed vs unexposed, treatment vs. controls) are selected in different ways, or if there is differential attrition.\n\n\n6.5.2 Information bias\nInformation bias includes many types of bias, including observer, responder, instrument, and recall bias.\nIf measurement in the two groups have systematic differences, that could explain the research findings. Observer and responder bias can be addressed through blinding.\n\n\n6.5.3 Potential Confounding\nConfounders are associated with both the outcome and the predictor and not an intermediate variable, so observed effect may instead be entirely attributable to the confounder’s relationship with both factors. Explain how you know that a potential confounder is associated with both outcome and the predictor. Limit your discussion to a relatively small number of factors that are likely to have large impacts.\nLack of a control group or a poor choice of a control group are threats to internal validity, but they are not confounders. Explain why it’s important to have a control group, and how the lack of a (good) control group may explain the results.\n\n\n6.5.4 Adding a third variable to uncover bias\nWe can reveal bias by stratifying data. Estimating associations after stratifying data can reveal important patterns: cohort effects and Simpson’s paradox."
  },
  {
    "objectID": "chapt4.html#cohort-effects",
    "href": "chapt4.html#cohort-effects",
    "title": "6  Associations",
    "section": "6.6 Cohort effects",
    "text": "6.6 Cohort effects\n\n\n\nCohort and age effects, Randall Munroe, XKCD\n\n\nSource: Randall Munroe, XKCD.org https://xkcd.com/2080/\nHysterectomy changes by age cohort\n\n\n\nAge on day of interview\n40-49\n50-59\n60-69\n70-79\n\n\n\n\n35\n11\n5\n6\n6\n\n\n40\n18\n10\n11\n11\n\n\n45\n\n22\n19\n17\n\n\n50\n\n35\n26\n23\n\n\n55\n\n\n33\n26\n\n\n60\n\n\n37\n27\n\n\n65\n\n\n\n31\n\n\n70\n\n\n\n35\n\n\n\n\nplot(c(35,40), c(11, 18), type=\"b\", xlim=c(35,70), ylim=c(0,40), xlab=\"\",\n        ylab=\"\", lty=1, axes=F)\npar(new=T)\nplot(c(35,40, 45, 50), c(5, 10, 22, 35), type=\"b\", xlim=c(35,70), ylim=c(0,40),\n        xlab=\"\",  ylab=\"\", lty=2, axes=F)\npar(new=T)\nplot(c(35,40, 45, 50, 55, 60), c(6, 11, 19, 26, 33, 37), type=\"b\", xlim=c(35,70), ylim=c(0,40),  xlab=\"\", ylab=\"\", lty=3, axes=F)\npar(new=T)\nplot(c(35,40, 45, 50, 55, 60, 65, 70), c(6, 11, 17, 23, 26, 27, 31, 35),\n        type=\"b\", xlim=c(35,70), ylim=c(0,40), xlab=\"Age in years\",\n         ylab=\"Percent with hysterectomy\", lty=4)"
  },
  {
    "objectID": "chapt4.html#simpsons-paradox",
    "href": "chapt4.html#simpsons-paradox",
    "title": "6  Associations",
    "section": "6.7 Simpson’s paradox",
    "text": "6.7 Simpson’s paradox\nSimpson’s paradox refers to the situation where an apparent relationship between two variables reverses after stratifying on a third variable.\n\n6.7.1 Berkeley graduate admissions data\nBerkeley gender bias case is a classic example of Simpson’s paradox. (Bickel, P. J., Hammel, E. A., and O’Connell, J. W. (1975) Sex bias in graduate admissions: Data from Berkeley. Science, 187, 398–403)\nHere are the admission rates from fall 1973 for graduate school at UC Berkeley. Men seem to be more likely to be admitted, so Berkeley was afraid of being sued. They were never sued, however.\n\n\n\n\nApplicants\nAdmitted\n\n\n\n\nMen\n8442\n44%\n\n\nWomen\n4321\n35%\n\n\n\nAfter stratifying by department, here are the admission rates:\n\n\n\n\n\n\n\n\n\n\nDepartment\nMen applicants\nMen admitted\nWomen applicants\nWomen admitted\n\n\n\n\nA\n825\n62%\n108\n82%\n\n\nB\n560\n63%\n25\n68%\n\n\nC\n325\n37%\n593\n34%\n\n\nD\n417\n33%\n375\n35%\n\n\nE\n191\n28%\n393\n24%\n\n\nF\n272\n6%\n341\n7%\n\n\nTotal\n2590\n46%\n1835\n30%\n\n\n\n\n\n\nBickel, P. J., Hammel, E. A., and O’Connell, J. W. (1975) Sex bias in graduate admissions: Data from Berkeley. Science, 187, 398--403\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMen applicants\nMen admitted\n\nWomen applicants\nWomen admitted\n\n\n\n\n\nArts\n4100\n1300\n32%\n8250\n3150\n38%\n\n\nSciences\n8200\n5100\n62%\n2900\n1900\n66%\n\n\nTotal\n12300\n6400\n52%\n11150\n5050\n45%\n\n\n\nThe reason that Simpson’s paradox occurred here is that more women apply to more competitive departments (e.g., the humanities) than men do, so women experience lower overall admissions rates than men due to their preference for these more competitive departments. Disaggregated by department, we see that women do not experience a lower admissions rate. The reason that the science departments are less competitive is that the applicants tend to be self-selected, having had more attrition at the undergraduate level, so the applicant pool is overall probably more suitable for graduate school than the applicant pool for non-science departments which have less attrition among undergraduates.\nI’ve looked for the source of the above plot to reproduce it, but the most detailed data are here (https://discovery.cs.illinois.edu/dataset/berkeley/). It seems Berkeley doesn’t release the full set.\n\nB = read.csv(\"berkeley.csv\")\nxtabs(~Admission + Major + Gender, data=B)\n\n, , Gender = F\n\n          Major\nAdmission     A    B    C    D    E    F Other\n  Accepted   89   17  201  131   94   25   937\n  Rejected   19    8  392  244  299  316  1549\n\n, , Gender = M\n\n          Major\nAdmission     A    B    C    D    E    F Other\n  Accepted  825  353  120  138   53   22  2227\n  Rejected  313  207  205  279  138  351  3211\n\n\nWe can reproduce these numerical results in R using the version from the datasets package. Sum up all the values for males and females separately.\nThis is what the dataset looks like. It’s a cross-tabulation in 3 dimensions: admission status, gender, and department.\n\nUCBAdmissions\n\n, , Dept = A\n\n          Gender\nAdmit      Male Female\n  Admitted  512     89\n  Rejected  313     19\n\n, , Dept = B\n\n          Gender\nAdmit      Male Female\n  Admitted  353     17\n  Rejected  207      8\n\n, , Dept = C\n\n          Gender\nAdmit      Male Female\n  Admitted  120    202\n  Rejected  205    391\n\n, , Dept = D\n\n          Gender\nAdmit      Male Female\n  Admitted  138    131\n  Rejected  279    244\n\n, , Dept = E\n\n          Gender\nAdmit      Male Female\n  Admitted   53     94\n  Rejected  138    299\n\n, , Dept = F\n\n          Gender\nAdmit      Male Female\n  Admitted   22     24\n  Rejected  351    317\n\n\nWe can use the apply function to sum up across the first two dimensions of the cross-tabulation: the rows (admits) and columns (gender), so we have just a 2x2 table with admission numbers (rows) by gender (columns).\n\n(all=apply(UCBAdmissions, c(1, 2), sum))\n\n          Gender\nAdmit      Male Female\n  Admitted 1198    557\n  Rejected 1493   1278\n\n\nUse these data to estimate the acceptance rates by gender, using apply to sum over the columns (gender).\n\nround(100*all[1,]/apply(all, 2, sum), digits=1)\n\n  Male Female \n  44.5   30.4 \n\n\nGet the acceptance rates for each department. Because this is a cross-tabulation in three dimensions, we use 1,, to refer to the first row and 2,, to refer to the second row.\n\n(acceptancerates = round(100*UCBAdmissions[1,,]/(UCBAdmissions[1,,]+UCBAdmissions[2,,]), digits=1))\n\n        Dept\nGender      A    B    C    D    E    F\n  Male   62.1 63.0 36.9 33.1 27.7  5.9\n  Female 82.4 68.0 34.1 34.9 23.9  7.0\n\n\n\nbarplot(acceptancerates, beside=T, col=c(\"red\", \"blue\"), legend=c(\"Male\", \"Female\"), \n        ylab=\"Acceptance rate (%)\", ylim=c(0,100), xlab=\"Department\")\n\n\n\n\nHere’s the bar plot.\n\n\n6.7.2 Discrimination in DDS\nCA Department of Developmental Services allocates funds to over 250,000 developmentally- disabled individuals. There appears to less spending on Hispanics than non-Hispanic whites when aggregate spending is examined, but the difference reverses after stratifying on age cohort.1\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\ndisability_spending=read.csv(\"paradox_data.csv\")\nfavstats(Expenditures ~ Ethnicity, data=disability_spending)\n\n           Ethnicity   min       Q1  median       Q3   max      mean        sd\n1    American Indian  3726 22085.25 41817.5 56170.50 58392 36438.250 25693.912\n2              Asian   374  3382.00  9369.0 34274.00 75098 18392.372 19209.225\n3              Black   240  3870.00  8687.0 41857.00 60808 20884.593 20549.274\n4           Hispanic   222  2331.25  3952.0 10292.50 65581 11065.569 15629.847\n5         Multi Race   669  1689.75  2622.0  3749.50 38619  4456.731  7332.135\n6    Native Hawaiian 37479 39103.00 40727.0 45434.00 50141 42782.333  6576.462\n7              Other  2018  2667.25  3316.5  3965.75  4615  3316.500  1836.356\n8 White not Hispanic   340  3977.00 15718.0 43134.00 68890 24697.549 20604.376\n    n missing\n1   4       0\n2 129       0\n3  59       0\n4 376       0\n5  26       0\n6   3       0\n7   2       0\n8 401       0\n\n\n\nfavstats(Expenditures ~ Age.Cohort, data=disability_spending)\n\n  Age.Cohort   min       Q1  median       Q3   max      mean        sd   n\n1      0 - 5   222  1034.25  1380.5  1739.25  2750  1415.280  612.6143  82\n2       51 + 33110 49515.00 53509.0 57745.50 75098 53521.896 6283.7671 106\n3      13-17   386  3306.50  3952.0  4665.50  6798  3922.613 1012.6525 212\n4      18-21  3153  7588.00  9979.0 11806.50 18435  9888.538 2940.6088 199\n5      22-50 25348 36447.25 40455.5 44720.75 56716 40209.283 6287.3119 226\n6       6-12   620  1601.50  2191.0  2846.50  4163  2226.863  830.9430 175\n  missing\n1       0\n2       0\n3       0\n4       0\n5       0\n6       0\n\n\n\ndisability_spending=transform(disability_spending, hispanic=ifelse(Ethnicity==\"Hispanic\", 1, 0))\ndisability_smaller=subset(subset(disability_spending, Ethnicity==\"White not Hispanic\" | Ethnicity==\"Hispanic\"), is.na(Ethnicity)==0)\nfavstats(Expenditures ~ Age.Cohort + hispanic, data=disability_smaller)\n\n   Age.Cohort.hispanic   min       Q1  median       Q3   max      mean\n1              0 - 5.0   340   875.75  1100.5  1777.25  2750  1366.900\n2               51 +.0 33110 48673.00 52652.5 57556.25 68890 52670.424\n3              13-17.0  1195  3076.00  3977.0  4586.00  6798  3904.358\n4              18-21.0  3157  8299.00 10068.0 11775.00 16133 10133.058\n5              22-50.0 26702 36279.00 40587.0 44002.00 56716 40187.624\n6               6-12.0   620  1344.25  2155.5  2659.75  3572  2052.261\n7              0 - 5.1   222  1025.00  1423.0  1704.75  2549  1393.205\n8               51 +.1 47420 51777.00 54875.0 59926.00 65581 55585.000\n9              13-17.1  1597  3394.50  3945.0  4675.00  5920  3955.282\n10             18-21.1  3225  7521.75 10009.5 11995.00 16677  9959.846\n11             22-50.1 26178 36782.50 40277.0 46504.00 52222 40924.116\n12              6-12.1   776  1675.00  2247.0  2899.50  4163  2312.187\n          sd   n missing\n1   716.2439  20       0\n2  6424.6686  66       0\n3  1071.0216  67       0\n4  2705.7115  69       0\n5  6081.3319 133       0\n6   842.7642  46       0\n7   533.4011  44       0\n8  5389.9663  17       0\n9   938.8189 103       0\n10 3230.9162  78       0\n11 6467.0946  43       0\n12  823.3743  91       0\n\n\n\ntally(Age.Cohort~hispanic, data=disability_smaller)\n\n          hispanic\nAge.Cohort   0   1\n     0 - 5  20  44\n     51 +   66  17\n    13-17   67 103\n    18-21   69  78\n    22-50  133  43\n    6-12    46  91\n\n\n\n\n6.7.3 New Zealand Jury Pools\nIn 1993, the Department of Justice in New Zealand investigated whether Maori tribespeople were underrepresented on juries. Overall, Maori were 9.5% of the eligible population, but 10.1% of jury pools, but decomposed by district of residence, the results looked different. They found the following percentages of Maori Ethnic Group in the jury pools:\n\n\n\nEligible population (%)\nJury pool (%)\nShortfall (%)\n\n\n\n\n9.5\n10.1\n-0.6\n\n\n\nDecomposed by district of residence compared with results from the 1991 Census, they found the following percentages of Maori Ethnic Group in the jury pools.\n\n\n\n\n\n\n\n\n\nDistrict\nEligible population (%)\nJury pool (%)\nShortfall (%)\n\n\n\n\nWhangarei\n17.0\n16.8\n0.2\n\n\nAuckland\n9.2\n9.0\n0.2\n\n\nHamilton\n13.5\n11.5\n2.0\n\n\nRotorua\n27.0\n23.4\n3.6\n\n\nGisborne\n32.2\n29.5\n2.7\n\n\nNapier\n15.5\n12.4\n3.1\n\n\nNew Plymouth\n8.9\n4.1\n4.8\n\n\nPalmerston North\n8.9\n4.3\n4.6\n\n\nWellington\n8.7\n7.5\n1.2\n\n\nNelson\n3.9\n1.7\n2.2\n\n\nChristchurch\n4.5\n3.3\n1.2\n\n\nDunedin\n3.3\n2.4\n0.9\n\n\nInvercargill\n8.4\n4.8\n3.6\n\n\nAll districts\n9.5\n10.1\n-0.6"
  },
  {
    "objectID": "chapt4.html#exercise-coffee-and-cancer-of-the-pancreas",
    "href": "chapt4.html#exercise-coffee-and-cancer-of-the-pancreas",
    "title": "6  Associations",
    "section": "6.8 Exercise: Coffee and cancer of the pancreas",
    "text": "6.8 Exercise: Coffee and cancer of the pancreas\nAnswer the following questions about the attached paper: “Coffee and cancer of the pancreas” in New England Journal of Medicine 1981. 1. What research question is the paper trying to answer? 2. Is there a clear background and rationale for this study? Do the researchers explain why is it important to study this research question? Explain. 3. What is the study’s research design? Is the design adequate to answer the major research questions? Explain. 4. What is the study’s sample and source of data? Are the descriptions of the study settings and subjects adequate? Are there limitations of the study samples that might cause problems with internal validity? Are there limitations of the study samples that might cause problems with external validity? Explain your answers. 5. What is the primary outcome variable (also known as dependent variable)? Can you tell whether the outcome variable is likely to be measured accurately? If you think that the outcome is not measured accurately, how might that affect the study’s results? 6. What is the main predictor variable (also known as independent variable)? Can you tell whether the predictor variable is likely to be measured accurately? If you think that the predictor is not measured accurately, how might that affect the study’s results? 7. What were the results, and what did the study conclude from the results? Assess how well the researchers justified the study’s main conclusions in the abstract and discussion. Explain your answer in view of the study’s research design. 8. Are there any research designs that would allow a more useful or better study? If so, explain briefly this overall design and how it would be more useful or better. 9. What has happened in the literature since this paper was published? Find a recent meta-analysis, if possible. Has the literature supported this paper’s finding?\n\n6.8.1 Suggested answers\n\nWhat research question is the paper trying to answer? What causes pancreatic cancer? Specifically, using PICO acronym: are people (in New England) who drink tea or coffee or who smoke more likely to get pancreatic cancer than people who don’t?\nIs there a clear background and rationale for this study? Do the researchers explain why is it important to study this research question? Explain. Yes, the researchers explain why is it important to study pancreatic cancer. Pancreatic cancer kills 20,000 people per year and treatments were not effective, making primary prevention particularly important. At the time of writing, cigarettes were the only cause identified so far, and only weakly. Alcohol, coffee, and tea were not adequately explored.\nWhat is the study’s research design? Is the design adequate to answer the major research questions? Explain. The study used a case-control design, comparing patients with pancreatic cancer with hospitalized patients with the same doctors, excluding those with diseases associated with smoking and alcohol. A case-control research design cannot address causal question of which factors cause pancreatic cancer, but it is sufficient to determine whether pancreatic cancer is associated with the factors.\nWhat is the study’s sample and source of data? Are the descriptions of the study settings and subjects adequate? Are there limitations of the study samples that might cause problems with internal validity? Are there limitations of the study samples that might cause problems with external validity? Explain your answers. Patients at 11 Boston and Rhode Island hospitals: 369 cases and 644 controls. Cases had pancreatic cancer, excluding some varieties. Controls were patients of the same doctors in the same hospitals, excluding those treated for diseases known to be caused by alcohol and smoking. Yes, description was adequate. They listed most of the diagnoses of the controls, and exclusion criteria, and they noted that there was over-representation of GI illnesses. The samples could cause problems with internal validity. Over-representation of GI ill- nesses in control group could cause selection bias away from the null; coffee drinking may be lower than expected in the control group because many people with GI illnesses may drink less coffee due to their conditions. Exclusion of those treated for diseases known to be caused by alcohol and smoking could cause selection bias away from null because smokers and alcohol drinkers are also more likely to drink coffee, so the control group may have less coffee drinking than average, even among those without GI diseases. The samples could cause problems with external validity. The researchers excluded non- whites and non-residents of the US. The study only generalizes to white patients with certain forms of pancreatic cancer who are likely to go to hospitals where nearly all the patients are white. Excluding non-whites limits external validity, and is unethical and would not be permitted under current research review rules. The study also excluded people too sick to interview, patients who died, and patients who were discharged. Without additional analysis of the background factors — comparing excluded versus included patients — we can’t know whether these factors limit the external validity. For instance, patients who were discharged may have been more healthy than other pancreatic cancer patients, whereas patients who were too sick or died may have been less healthy than other pancreatic cancer patients.\nWhat is the primary outcome? Can you tell whether the outcome is likely to be measured accurately? If you think that the outcome is not measured accurately, how might that affect the study’s results? Pancreatic cancer is the primary outcome, and it was measured as a clinical diagnosis with or without pancreatic cancer. The cases were hospitalized for pancreatic cancer, so their diagnosis is likely to be accurate. The controls were hospitalized for other conditions, and their doctors likely ruled out pancreatic cancer. Thus, the outcome of pancreatic cancer is likely to be measured accurately for both cases and controls.\nWhat are the main predictor(s)? Can you tell whether the predictor(s) are likely to be measured accurately? If you think that one or more predictor(s) are not measured accurately, how might that affect the study’s results? Consumption of coffee, tea, alcohol, and cigarettes are the main predictors. Coffee drink- ing may not have been measured accurately because the researchers in this study did not specify that they wanted to know participants’ pre-illness coffee drinking. As mentioned above, people with GI conditions that were over-represented in the control group may have reduced coffee drinking due to their illnesses, and the researchers did not specify that they were interested in pre-illness coffee drinking. If they had specified pre-illness coffee drinking, there may have been recall bias if people with conditions thought to be associated with coffee drinking (GI conditions) recalled more or less coffee than they actually drank, which would cause bias towards the null if they recalled more coffee drinking, or away from the null if they recalled less coffee drinking.\nWhat were the results, and what did the study conclude from the results? Assess how well the researchers justified the study’s main conclusions in the abstract and discussion. Explain your answer in view of the study’s research design. Patients who reported drinking up to 2 cups of coffee had 1.8 times the odds (80% greater odds) of pancreatic cancer, and patients who reported drinking 3 or more cups of coffee had 2.7 times the odds of pancreatic cancer, adjusted for cigarette smoking. The risk of pancreatic cancer increased monotonically with coffee intake, which is convincing because it suggests a dose-response relationship. Given the available information, the researchers justified the main conclusions, but further investigation has suggested selection bias may explain the findings.\nAre there any research designs that would allow a more useful or better study? If so, explain briefly this overall design and how it would be more useful or better. The case-control research design is reasonable because the researchers were still trying to identify causes of pancreatic cancer. Altering the design to reduce the chances of selection bias, such as by excluding people with diseases thought to be associated with coffee drinking (e.g., GI illnesses), could improve the case-control design. Including people of all races and ethnicities would meet modern ethical standards and improve the study’s external validity.\nWhat has happened in the literature since this paper was published? Find a recent meta-analysis, if possible. Has the literature supported this paper’s finding? There have been at least 37 case-control and 17 cohort studies, and the literature has not supported this paper’s finding of such a large association between coffee and pan- creatic cancer; the meta-analysis by Turati et al suggests not even a small association is supported. The research suggests that this study may have had selection bias and information bias because the study did not measure pre-illness coffee drinking."
  },
  {
    "objectID": "chapt5.html#philosophical-approaches-to-causality",
    "href": "chapt5.html#philosophical-approaches-to-causality",
    "title": "7  Causality vs association",
    "section": "7.1 Philosophical approaches to causality",
    "text": "7.1 Philosophical approaches to causality\n\n7.1.1 David Hume\n“All reasonings concerning matter of fact seem to be founded on the relation of cause and effect. By means of that relation alone we can go beyond the evidence of our memory and senses.” —David Hume, An Enquiry Concerning Human Understanding, 1777.\n“Suppose a person, though endowed with the strongest faculties of reason and reflection, to be brought on a sudden into this world; he would, indeed, immediately observe a continual succession of objects, and one event following another; but he would not be able to discover anything farther. He would not, at first, by any reasoning, be able to reach the idea of cause and effect” (section V, part I).\nSimilar reasoning was found by earlier philosophers, such as 11th century al Ghazali.\nHume believed that we perceive causality on the basis of experience, but causality cannot be proved by reason. He established 8 “rules by which to judge of causes and effects” (Treatise on Human Nature, book 1, part III, section 15):\n\nContiguous in space and time.\nTemporality: cause comes before effect.\nPerfect correlation: “constant union betwixt the cause and effect”\n“The same cause always produces the same effect, and the same effect never arises but from the same cause.”\n“like effects imply like causes.”\nFailure of an expected event to occur “proceeds from some difference in the causes”\nDose-response: “The absence or presence of one part of the cause is here supposed to be always attended with the absence or presence of a proportionable part of the effect.” but “A certain degree of heat gives pleasure; if you diminish that heat, the pleasure diminishes; but it does not follow, that if you augment it beyond a certain degree, the pleasure will likewise augment; for we find that it degenerates into pain.”\nMultiple causes: “like effects necessarily follow from like causes, and in a contiguous time and place, their separation for a moment shows, that these causes are not complete ones.” Hume comments on his rules for perceiving causality: “Here is all the LOGIC I think proper to employ in my reasoning; and perhaps even this was not very necessary, but might have been supplied by the natural principles of our understanding. … All the rules of this nature are very easy in their invention, but extremely difficult in their application.”\n\nKant believed in causality because otherwise it wouldn’t be possible to understand the world."
  },
  {
    "objectID": "chapt5.html#epidemiologic-approaches-to-causality",
    "href": "chapt5.html#epidemiologic-approaches-to-causality",
    "title": "7  Causality vs association",
    "section": "7.2 Epidemiologic approaches to causality",
    "text": "7.2 Epidemiologic approaches to causality\nCausal inference is the goal of epidemiologic studies.\n“Correlation does not imply causation” is a known clichee, but how far can you get with correlation?\n\n7.2.1 Associations\n\nChildren raised with more books in the house delay sex.\nAs ice cream sales rise, the risk of drowning rises.\nAs the number of pirates has decreased, the average global temperature has increased.\nPeople who consume beta carotene supplements have lower rates of cancer. Randomized controlled trials showed beta carotene treatment group had a small increase in lung cancer and mortality relative to the placebo control group.\n\n\n\n7.2.2 Lack of association is meaningful.\n\nIf lack of access to land caused scurvy, we would expect to see an association between recovery from scurvy and being buried in the ground, even in a non-randomized trial.\nIf drowning was unrelated to alcohol, we would expect to see no correlation between rates of drowning and sales of alcohol.\nIf comprehensive sex education increased teen pregnancy and sexually transmitted in- fections, we would expect that places with less comprehensive sex education would have lower teen pregnancy and STIs than the rest of the country.\n\n\n\n7.2.3 Henle-Koch postulates (1890)\nRobert Koch and Friedrich Loeffler\n\nThe agent is present in every case of the disease, and not in healthy subjects.\nThe agent can be isolated and grown in pure culture.\nThe agent will cause the disease if introduced to healthy subjects.\nThe same organism must be reisolated from the experimentally infected host.\n\nUsing Koch’s postulates, Koch’s students identified the organisms responsible for diphtheria, typhoid, gonorrhea, pneumonia, meningitis, leprosy, bubonic plague, tetanus and syphilis. In 1984, Barry Marshall drank Helicobacter pylori to test his theory about gastritis, following Koch’s third postulate.\nLimitations of Henle-Koch postulates\n\nAsymptomatic carriers of a disease agent: Koch discovered asymptomatic carriers of typhoid and cholera. Poliovirus causes paralytic disease in about 1% of those infected.\nSome disease agents can’t be cultured: e.g., prions.\nPublic health expanded to chronic diseases, injury prevention, and other non-infectious causes of morbidity and mortality.\n\n\n\n7.2.4 Hill’s criteria for observational data\nThe Surgeon General’s report on smoking and 1965 paper by Sir Austin Bradford Hill advanced standards that could be used to judge when an association might be causal. Note: This list is not a checklist.\n\nStrength: Stronger associations are more likely to be causal and less likely due to chance or confounding.\nConsistency: Association has been observed by different persons, in different settings (places, circumstances, times), populations, and methods.\nSpecificity: single cause produces a specific effect.\nTemporality: Exposure precedes outcome.\nBiologic Gradient: dose-response relationship.\nPlausibility of a mechanism between exposure and disease.\nCoherence between epidemiologic theory and laboratory evidence.\nExperiment: concurring experimental evidence exists.\nAnalogy to similar situations.\n\n\n\n7.2.5 Koepsell and Weiss’s causal criteria Summary of Hill’s criteria\n\nTemporality\nStrong association\nNo plausible non-causal explanation accounts for entirety of the association, and a plausible explanation for the association being causal.\nMagnitude of association is strongest when predicted to be so. Causality from potential outcomes: the Rubin Causal Model Epidemiologic research attempts to establish what would have happened in the absence of “treatment.”"
  },
  {
    "objectID": "chapt5.html#counterfactuals",
    "href": "chapt5.html#counterfactuals",
    "title": "7  Causality vs association",
    "section": "7.3 Counterfactuals",
    "text": "7.3 Counterfactuals\n\n7.3.1 Counterfactuals in the legal system.\nThe Federal Judicial Center’s Reference Manual on Scientific Evidence (1994, Chapter 3, p. 481) states: “The first step in a damages study is the translation of the legal theory of the harmful event into an analysis of the economic impact of that event. In most cases, the analysis considers the difference between the plaintiff’s economic position if the harmful event had not occurred and the plaintiff’s actual economic position. The damages study restates the plaintiff’s position”but for” the harmful event; this part is often called the but-for analysis. Damages are the difference between the but-for value and the actual value.” (Book available for free download here: https://nap.nationalacademies.org/read/13163/chapter/10)\n\n\n7.3.2 Effect of aspirin on headaches with n=1\nDon Rubin gives the following example of a counter-factual: Say that you have a headache. You will measure your pain 2 hours after taking an aspirin versus not taking an aspirin. You can phrase the causal effect of the aspirin as follows.\nYou can express the headache pain with and without aspirin. The effect of aspirin on headache pain is -50 units of pain, comparing the headache pain without aspirin (75) versus with aspirin (25).\n\n\n\n\n\n\n\n\n\nUnit\nHeadache pain with aspirin\nHeadache pain without aspirin\nCausal effect\n\n\n\n\nYou\n25\n75\n-50\n\n\n\nYou can express the same quantities by how much headache pain changes under aspirin and no aspirin. Without aspirin, the pain reduces by 5 units. With aspirin, it reduces by 55 units. The effect of aspirin on headache pain is -50 units of pain.\n\n\n\n\n\n\n\n\n\n\nUnit\nInitial headache\nReduction in pain with aspirin\nReduction in pain without aspirin\nCausal effect\n\n\n\n\nYou\n80\n-55\n-5\n-50\n\n\n\nIn real life, you never know what would have happened both with and without aspirin: one condition is always missing.\n\n\n7.3.3 The perfect doctor\nThis example is also due to Don Rubin.\nImagine an omniscient doctor who could know the outcome of each patient under two different treatments.\nThe data given below shows all potential outcomes for the number of years lived under two different treatments: standard surgery and a new surgery.\n\n\n\n\n\n\n\n\n\nPatient\nStandard surgery\nNew surgery\nCausal effect (new-standard)\n\n\n\n\nA\n13\n14\n-1\n\n\nB\n6\n0\n6\n\n\nC\n4\n1\n3\n\n\nD\n5\n2\n3\n\n\nE\n6\n3\n3\n\n\nF\n6\n1\n5\n\n\nG\n8\n10\n-2\n\n\nH\n8\n9\n-1\n\n\nTrue average\n7\n5\n2\n\n\n\nWe can see from this omniscient standpoint that the true causal effect is that the standard surgery results in 2 more years of life on average than the new surgery. If we did a randomized experiment, we would expect that on average our results would show this.\nThe perfect doctor would choose the best treatment for the patient, and if there’s no difference, she flips a coin.\nObserved outcomes under perfect doctor’s assignment give the opposite of random assignment. The data therefore look like this:\n\n\n\nPatient\nStandard surgery\nNew surgery\nTreatment\n\n\n\n\nA\n?\n14\nNew\n\n\nB\n6\n?\nStandard\n\n\nC\n4\n?\nStandard\n\n\nD\n5\n?\nStandard\n\n\nE\n6\n?\nStandard\n\n\nF\n6\n?\nStandard\n\n\nG\n?\n10\nNew\n\n\nH\n?\n9\nNew\n\n\nObserved average\n5.4\n11\n\n\n\n\nThe apparent causal effect is that the new surgery results in 5.6 more years of life than the standard surgery.\nRandom assignment on average yields the true averages. Across all possible assignments to standard versus new surgery (56 ways to assign 3 participants to get the new surgery and 5 participants to get the old surgery), we get an average treatment effect of -2 (standard surgery better than new surgery by 2 years)."
  },
  {
    "objectID": "chapt5.html#exercises",
    "href": "chapt5.html#exercises",
    "title": "7  Causality vs association",
    "section": "7.4 Exercises",
    "text": "7.4 Exercises\n\n7.4.1 Whickham data\nThese data come from\nDR Appleton, JM French, MPJ Vanderpump. “Ignoring a covariate: an example of Simpson’s paradox”. (1996) American Statistician, 50(4):340-341.\nThese data are a random sample study in Whickham, UK of smoking among women in 1972-74 and viral status in 1992-94.\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\ntally(outcome ~ smoker, data=Whickham, margin=T)\n\n       smoker\noutcome  No Yes\n  Alive 502 443\n  Dead  230 139\n  Total 732 582\n\n\nCalculate the percentage of baseline current smokers versus baseline never-smokers who were still alive at the second survey (1992–94.) Interpret your results. Can you think of any explanation for these results?\n\ntally(outcome ~ smoker, data=Whickham, format=\"percent\")\n\n       smoker\noutcome       No      Yes\n  Alive 68.57923 76.11684\n  Dead  31.42077 23.88316\n\n\nUse the data to evaluate whether age is a confounder of the relationship between smoking and mortality.\n\n\n7.4.2 Perfect doctor continued\nThis Perfect Doctor problem is based on one from Don Rubin.\nSchizophrenia drugs are a big problem for state Medicaid budgets: need to test new drugs against old to see if the extra cost is worth it. From point of view of omniscient being, we have two drugs to compare. Outcome is quality of life, 0 to 100.\n\n\n\nPatient\nNew drug\nOld drug\nCausal effect (new-old)\n\n\n\n\nA\n100\n80\n20\n\n\nB\n100\n80\n20\n\n\nC\n50\n90\n-40\n\n\nD\n40\n90\n-50\n\n\n\nCalculate the true average treatment effect (ATE) of the drug. Is the new drug better?\nPeople vary and the perfect doctor assigns each person to their optimal treatment. Calculate the treatment effect under the perfect doctor. Is the new drug better?\nThere are 4 choose 2 = 6 combinations of assignments of subjects to treatment or control, listed below: trial 1 through trial 6.\nWrite down all possible treatment effects under each assignment. Make a histogram of the average treatment effect (ATE).\n\n\n\nPatient\n1\n2\n3\n4\n5\n6\n\n\n\n\nA\nNew\nNew\nOld\nOld\nNew\nOld\n\n\nB\nNew\nOld\nNew\nOld\nOld\nNew\n\n\nC\nOld\nNew\nOld\nNew\nOld\nNew\n\n\nD\nOld\nOld\nNew\nNew\nNew\nOld\n\n\nTreatment effect\n\n\n\n\n\n\n\n\n\nLocate your answers to part a and b on the histogram. Comment on the role of randomized treatment assignment in causal inference.\nIn the real world, people drop out: 75% of people in the Sept 2005 NEJM study that this problem is based on dropped out. Who is most likely to drop out of the study? How will the drop out affect treatment effects? How do you compensate for the drop out?"
  },
  {
    "objectID": "chapt6.html#estimating-the-relative-risk-from-a-case-control-study",
    "href": "chapt6.html#estimating-the-relative-risk-from-a-case-control-study",
    "title": "8  Excess risk",
    "section": "8.1 Estimating the relative risk from a case-control study",
    "text": "8.1 Estimating the relative risk from a case-control study\nIf incidence rates cannot be calculated, we can calculate cumulative incidence among the treated and control as \\(CI_1= a/(a+b)\\) and \\(CI_0= c/(c+d)\\)\nWe calculate the relative risk as the ratio of these cumulative incidences $RR = CI_1/CI_0 = = $\nIf an event is rare, a + b ≈ b and c + d ≈ d, so\n$RR = = OR $\nNote that a/c = Odds of exposure among people who develop disease, and b/d = odds of exposure among people who do not develop disease.\nIf an event is not rare, the odds ratio does not approximate the relative risk.\n\n8.1.1 Estimating the attributable risk from a case-control study\nDefine the following quantities:\n\\(p_1\\) = frequency of exposure among cases of disease \\(= a/(a+b)\\)\n\\(p_0\\) = frequency of exposure among controls = \\(b/(b+d)\\)\nIf frequency of exposure is approximately equal in both controls and cases (\\(p_1 ≈ p_0\\)).\nIf incidence in overall population \\(I_t\\) is known (or can be estimated), you can estimate \\(I_0\\). By definition, the incidence in the full population is the sum of incidence among each population times the frequency of exposure:\n\\(I_t =I_1p_1 +I_0p_0 =I_1p_1 +I_0(1−p_1)=RR·I_0p_1 +I_0(1−p_1)=I_0(p_1(RR−1)+1)\\)\n\\(I_0 = \\frac{I_t}{p_1(RR−1)+1}\\)\nThat allows you to estimate AR using the following formula: \\(AR = I_0(RR − 1)= \\frac{I_t}{p_1(RR−1)+1}(RR − 1)= \\frac{I_t}{p_1+\\frac{1}{(RR−1)}}\\)\n\n\n8.1.2 Odds ratios versus risk ratios\nNote that odds ratios are normally larger than risk ratios.\nEIS case: Wendell Ames, Stafford Wheeler, and Alexander Langmuir, “Oswego – An Outbreak of Gastrointestinal Illness Following a Church Supper”, Centers for Disease Control and Prevention Epidemiology Program Office Case Studies in Applied Epidemiology No. 401-303. https://www.cdc.gov/eis/casestudies/xoswego.401-303.student.pdf\nGross M. Oswego County revisited. Public Health Rep. 1976 Mar-Apr;91(2):168-70.\nHere is a 2x2 table of gastoenteritis (ill = yes) versus eating vanilla ice cream.\n\nlibrary(epitools)\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\ndata(oswego)\ntally(ill~vanilla.ice.cream, data=oswego, margins=T)\n\n       vanilla.ice.cream\nill      N  Y\n  N     18 11\n  Y      3 43\n  Total 21 54\n\n\nThe odds ratio is 23.5 = \\(43*18/(3*11)\\). We can also calculate this in R. Note that we have to take the reciprocol because the upper left corner is not exposed and no disease.\n\n1/orrr(tally(ill~vanilla.ice.cream, data=oswego))\n\n[1] 23.45455\n\n\nThe relative risk = (43/54)/(3/21) = 5.6"
  },
  {
    "objectID": "chapt6.html#exercise-smoking-and-lung-cancer",
    "href": "chapt6.html#exercise-smoking-and-lung-cancer",
    "title": "8  Excess risk",
    "section": "8.2 Exercise: smoking and lung cancer",
    "text": "8.2 Exercise: smoking and lung cancer\nThis EIS exercise shows how scientists discovered smoking was linked to lung cancer.\nA causal relationship between cigarette smoking and lung cancer was first suspected in the 1920s on the basis of clinical observations. To test this apparent association, numerous epidemiologic studies were undertaken between 1930 and 1960. Two studies were conducted by Doll and Hill in Great Britain. The first was a case-control study begun in 1947 comparing the smoking habits of lung cancer patients with the smoking habits of other patients. The second was a cohort study begun in 1951 recording causes of death among British physicians in relation to smoking habits. This exercise — developed by the CDC’s Epidemic Intelligence Service (EIS) to train officers — deals first with the case-control study, then with the cohort study.\nData for the case-control study were obtained from hospitalized patients in London and vicinity over a 4-year period (4 April 1948 – February 1952). Initially, 20 hospitals, and later more, were asked to notify the investigators of all patients admitted with a new diagnosis of lung cancer. These patients were then interviewed concerning smoking habits, as were controls selected from patients with other disorders (primarily non-malignant) hospitalized in the same hospitals at the same time. Data for the cohort study were obtained from the population of all physicians listed in the British Medical Register who resided in England and Wales as of October 1951. Information about present and past smoking habits was obtained by questionnaire. Information about lung cancer came from death certificates and other mortality data recorded during ensuing years.\n\nWhat makes the second study a cohort study?\nWhat makes the first study a case-control study?\n\nThe following questions apply to the case-control study. 3. Why were hospitals chosen as the setting for the case-control study?\n\nWhat are the advantages of selecting controls from the same hospitals as cases?\nHow representative of all persons with lung cancer are hospitalized patients with lung cancer? What other sources of cases might have been used?\nHow representative of all persons without lung cancer are hospitalized patients without lung cancer? What other sources of controls might have been used?\nHow may these representativeness issues affect interpretation of the study results?\nOver 1700 cases of lung cancer, all under age 75, were eligible for the case-control study. About 15% were not interviewed because of death, discharge from hospital, severity of illness, or inability to speak English. In addition, some patients were interviewed but later excluded when initial lung cancer diagnosis proved mistaken. The final study group included 1465 cases (1357 males and 108 females).\n\nThe following table shows the relationship between cigarette smoking and lung cancer among male cases and controls.\n\n\n\n\nCases\nControls\nTotal\n\n\n\n\nCigarette smoker\n1350\n1296\n\n\n\nNon-smoker\n7\n61\n\n\n\nTotal\n1357\n1357\n\n\n\n\n\nFrom this table, calculate the proportion of cases and controls who smoked. What do you infer from these proportions?\nCalculate the odds of smoking for cases and controls. Calculate the odds ratio. Interpret these data.\n\n\nThe following table shows the frequency distribution of male cases and controls by average number of cigarettes smoked per day.\n\n\n\n\nDaily # cigarettes\nCases\nControls\nOdds ratio\n\n\n\n\n0 (non-smokers)\n7\n61\nReferent\n\n\n1-14\n565\n706\n\n\n\n15-24\n445\n408\n\n\n\n25+\n340\n182\n\n\n\nAll smokers\n1350\n1296\n\n\n\nTotal\n\n\n\n\n\n\nCalculate the odds ratio by category of daily cigarette consumption, comparing each smoking category to non-smokers. Interpret these results in words.\n\nWhile the study appears to demonstrate a clear association between smoking and lung cancer, cause-and-effect is not the only explanation. What are the other possible explanations for the apparent association?\n\nThe following questions apply to the cohort study.\nAs you may recall, data for the cohort study were obtained from the population of all physicians listed in the British Medical Register who resided in England and Wales as of October 1951. Questionnaires were mailed in October 1951, to 59,600 physicians. The questionnaire asked the physician to classify him/herself into one of three categories: 1) current smoker, 2) ex-smoker, or 3) nonsmoker. Smokers and ex-smokers were asked the amount they smoked, their method of smoking, the age they started to smoke, and, if they had stopped smoking, how long it had been since they last smoked. Nonsmokers were defined as persons who had never consistently smoked. This was defined as smoking as much as one cigarette a day for up to one year. Usable responses to the questionnaire were received from 68% or 40,637 physicians, of whom 34,445 were males and 6,192 were females.\n\nHow might the response rate of 68% have affected the study’s results?\n\nThe remainder of this exercise is concerned exclusively with male physician respondents, 35 years of age or older. The occurrence of lung cancer in physicians responding to the questionnaire was docu- mented over the period of 10 years (November, 1951 through October, 1961) from death certificates filed with the Registrar General of the United Kingdom and from lists of physician deaths provided by the British Medical Association. All certificates indicating that the decedent was a physician were obtained. For each lung cancer case, medical records were reviewed to confirm the diagnosis. Diagnoses of lung cancer were based upon the best evidence available; about 70% were from biopsy, autopsy, or sputum cytology (combined with bronchoscopy or X-ray evidence); 29% from cytology, bronchoscopy, or X-ray alone; and only 1% from just case history, physical examination, or death certificate. Of 4,597 deaths in the cohort over the 10-year period, 157 were reported to have been due to lung cancer; in 4 of the 157 cases this diagnosis could not be documented, leaving a net total of 153 cases of lung cancer.\nThe following table shows numbers of lung cancer deaths by daily number of cigarettes smoked at the time of the 1951 questionnaire (for male physician nonsmokers and current smokers only). Person-years at risk are given for each smoking category. The number of cigarettes smoked was available for 136 of the lung cancer cases.\n\n\n\n\n\n\n\n\n\n\n\nDaily # cigarettes\n# deaths from lung cancer\nPerson-years at risk\nDeath rate per 1000 person-years\nRate ratio\nRate difference per 1000 person-years\n\n\n\n\n0 (non-smokers)\n3\n42,800\n0.07\nreference\nreference\n\n\n1-14\n22\n38,600\n\n\n\n\n\n15-24\n54\n38,900\n\n\n\n\n\n25+\n57\n25,100\n\n\n\n\n\nAll smokers\n133\n102,600\n\n\n\n\n\nTotal\n136\n145,400\n\n\n\n\n\n\n\nWhat does it mean that the person-years at risk were age-standardized? Why was that done?\nCalculate lung cancer death rates, rate ratios, and rate differences for each smoking category. What does each of these measures mean?\nWhy was the rate ratio the correct measure of association to calculate for this study?\nWhat proportion of lung cancer cases among all smokers can be attributed to smoking? What is this proportion called? What assumption must be made about the relationship between smoking and lung cancer to interpret this?\nIf none of the smokers had smoked, how many cases of lung cancer would have been averted?\n\nThe following table shows the relationship between smoking and lung cancer mortality in terms of the effects of stopping smoking.\n\n\n\n\n\n\n\n\n\nSmoking status\n# deaths from lung cancer\nDeath rate per 1000 person-years\nRate ratio\n\n\n\n\nCurrent smokers\n133\n1.3\n18.5\n\n\nEx-smokers, quit <5 years\n5\n0.67\n9.6\n\n\nEx-smokers, quit 5-9 years\n7\n0.49\n7.0\n\n\nEx-smokers, quit 10-19 years\n3\n0.18\n2.6\n\n\nEx-smokers, quit 20+ years\n2\n0.19\n2.7\n\n\nNon-smokers\n3\n0.07\n1.0 (referent)\n\n\n\n\nWhat do these data imply for the practice of public health and preventive medicine?\nThe cohort also provided mortality rates for cardiovascular disease among smokers and non-smokers. The following table presents data on lung cancer mortality and comparable cardiovascular disease mortality.\n\n/1000 p-y = per 1000 person-years\nMR = Mortality rate per 1000 person-years\n\n\n\n\n\n\n\n\n\n\n\n\n\nMR Smokers\nMR Non-smokers\nMR All\nRate ratio\nExcess deaths /1000 p-y\nAttributable risk %\n\n\n\n\nLung cancer\n1.3\n0.07\n0.94\n1.3/0.07 = 18.6\n1.23\n95%\n\n\nCardiovascular disease\n9.51\n7.52\n8.87\n1.3\n2.19\n23%\n\n\n\nWhich disease has a stronger association with smoking? Which measure gives information?\n\nWhat proportion of each disease in the entire population can be attributed to smoking? What is this proportion called? How does this proportion differ from the one that you calculated above?\nDoll and Hill began their case-control study in 1947. They began their cohort study in 1951. Which type of study — case-control or cohort — would you have done first? Why? Why do a second study? Why do the other type of study?\nThe odds ratios and rate ratios from the two studies by numbers of cigarettes smoked are given in the table below.\n\n\n\n\n\n\n\n\n\n\n# cigarettes per day\nRate ratio cohort study\nOdds ratio case-control study\n\n\n\n\n\n0\n1.0 (Referent)\n1.0 (Referent)\n\n\n\n1-14\n8.1\n7.0\n\n\n\n15-24\n19.8\n9.5\n\n\n\n25+\n32.4\n16.3\n\n\n\nAll smokers\n18.5\n9.1\n\n\n\n\nCompare the results of the two studies. Comment on the similarities and differences in the calculated measures of association."
  },
  {
    "objectID": "chapt7.html#three-types-of-validity",
    "href": "chapt7.html#three-types-of-validity",
    "title": "9  Measurement error and screening",
    "section": "9.1 Three types of validity",
    "text": "9.1 Three types of validity\n\n\n\n\n\n\n\n\nStudy design issue\nQuestion to ask\nIdeal answer\n\n\n\n\nExternal validity\nHow was the sample chosen?\nRandom sampling design\n\n\nInternal validity\nHow were participants assigned to treatment vs. control?\nRandom assignment\n\n\nValidity\nDo measures correspond to constructs of interest and predict gold standard?\nYes"
  },
  {
    "objectID": "chapt7.html#data-anomalies",
    "href": "chapt7.html#data-anomalies",
    "title": "9  Measurement error and screening",
    "section": "9.2 Data anomalies",
    "text": "9.2 Data anomalies\nFinding anomalies in data is one way to identify measurement error problems.\nThese issues are obvious in retrospect when pointed out, but many don’t bother to investigate.\nJack Fowler: researchers often refer to survey instruments “as if having been validated was some absolute state, such as beatification.”\n\n9.2.1 Validation through logical contradictions\n“Why are so many men pregnant?”\n\n“In 2009-10, nearly 20,000 adults were coded as having attended paediatric outpatient services, and 3,000 patients under 19 were apparently treated in geriatric clinics.”\n“15,000 and 20,000 men have been admitted to obstetric wards each year since 2003, and almost 10,000 to gynaecology wards. Nearly 20,000 midwife”episodes” — NHS jargon for completed treatments — were with men.” –> much larger than expected number of transmen to give birth.\n“a hospital coded an entire year’s births as stillbirths and had to be excluded from the statistics altogether.” Similarly: positive STI tests among self-reported virgins.\n\n\n\n9.2.2 Overestimates of rare events\nHemenway: “Myth of Millions of Annual Self-Defense Gun Uses: A Case Study of Survey Overestimates of Rare Events”\nValidate with aggregate information: compares number of buglaries with number of alleged self-defense gun uses. Small misclassification errors lead to large impacts for rare events.\n\nUsing actual heights, 1% of children are stunted. Using mother-reported heights, 25% of children are stunted.\n6% of people say that they have met aliens: 1.2 million people!\nPossible to over-estimate, but not under-estimate the number of self-defense gun uses."
  },
  {
    "objectID": "chapt7.html#methods-for-valid-answers",
    "href": "chapt7.html#methods-for-valid-answers",
    "title": "9  Measurement error and screening",
    "section": "9.3 Methods for valid answers",
    "text": "9.3 Methods for valid answers\nMost of these methods apply to survey answers, but some address any type of study.\n\n9.3.1 Compare with aggregate information.\n\nNumber who claim to have donated blood with amount of blood in blood bank.\nLikewise, voting; membership in an organization (Ducks Unlimited, Sierra Club, etc.)\n\nThis is an older plot dating from 2013, but there doesn’t seem to be a more recent version of this comparison.\n\nhttps://www.pewresearch.org/fact-tank/2013/05/08/six-take-aways-from-the-census-bureaus-voting-report/\n– Number of patients seen in all emergency departments every year with number of people who claim to have shot someone, or been shot.\n\n\n9.3.2 Compare with gold standard\n– Parry and Crossley’s 1949 Denver study: library card, voting, rent or own residence, car ownership, have a telephone.\n– Voting self-report versus administrative records (Silver et al POQ 1986)\n– Self-reported circumcision status with expert examination.\n– Self-reported condom use in past 2 weeks versus semen Y-chromosome test: among 141 Baltimore STD clinic patients who reported 100% condom use in the last two weeks, 55% tested positive on the Yc-PCR (Jadack 2006).\n– Self-reported smoking versus cotinine test.\n\n\n9.3.3 Compare with earlier report\n– Drug use last year versus actual report from last year.\n– Test-retest over short interval when answers are not likely to change.\n– Adolescents recant earlier reports of sexual intercourse, cigarette smoking, the use of alcohol and illegal drugs, abortions, and pregnancy, virginity pledges, having a permanent tattoo, driving for respondents under age 15, and pierced ears for men.\n\n\n9.3.4 Ask a question you know the answer to.\n– Include names of fictitious drugs in a list of drugs that respondents have tried.\n\n\n9.3.5 Ask the question under different survey modes\n– Assumption is that larger number is correct.\n\n\n9.3.6 Randomized response method\nRespondent flips a coin and doesn’t show interviewer. – If heads: answer sensitive yes/no question. – If tails: answer a yes/no question with a known % of expected to say yes for that population. – Do the math to estimate the proportion who said yes to the question, given that half got heads.\n\n\n9.3.7 Bogus pipeline\nTake hair sample and claim that will test hair for (subject of question), and then ask the question.\n\n\n9.3.8 Ask respondents at the end of a section if they were honest.\n\n\n9.3.9 Ask respondent casually while walking out of the interview if they were honest.\n\n\n9.3.10 Methods that do not work\nReassure the respondent that answers are confidential: likely to backfire by raising problem."
  },
  {
    "objectID": "chapt7.html#other-issues-in-measurement-error",
    "href": "chapt7.html#other-issues-in-measurement-error",
    "title": "9  Measurement error and screening",
    "section": "9.4 Other issues in measurement error",
    "text": "9.4 Other issues in measurement error\n\n9.4.1 Survey mode effects\nPeople may answer questions differently depending on the survey mode: by ACASI, pen and paper, interview. More female teens report dieting in self-administered survey than interview. It’s possible to test for survey mode effects by asking the same questions in 2 different modes.\n\n\n9.4.2 Editing of responses\nRespondents may know the correct answer but give a different answer for some reason. One reason could be self-presentation bias.\n\n\n9.4.3 Recall accuracy\nRespondents may not know the correct answer, due to changing memories of the past.\n\n\n9.4.4 Survey context\nRespondents may answer questions differently depending on the other questions around them.\n\n\n9.4.5 Non-attitudes\nRespondents report attitudes on surveys about things that they don’t really know about. Researchers revealed non-attitudes in late 1970s by asking respondents about a non-existent law, the “Public Affairs Act of 1975”, on which more than 30% of respondents offered an opinion.\nComedy features use non-attitudes: - Jimmy Kimmel asking people to compare the Affordable Care Act with Obamacare (10/1/13). http://www.youtube.com/watch?v=sx2scvIFGjE - Zlati Meyer, a reporter for Detroit Free Press, asking people on the street about the federal government shutdown. http://www.freep.com/article/20131008/NEWS01/310080140/government-shutdown-zlati-meyer"
  },
  {
    "objectID": "chapt7.html#reliability",
    "href": "chapt7.html#reliability",
    "title": "9  Measurement error and screening",
    "section": "9.5 Reliability",
    "text": "9.5 Reliability\nExamine reliability by giving the same survey two times, separated by a reasonable time period (e.g., 2 weeks): test-retest."
  },
  {
    "objectID": "chapt7.html#screening",
    "href": "chapt7.html#screening",
    "title": "9  Measurement error and screening",
    "section": "9.6 Screening",
    "text": "9.6 Screening\nPrimary prevention: preventing disease\nSecondary prevention: detecting disease early\nTertiary prevention: treatment of cases\n\n9.6.1 US Preventive Services Task Force criteria for screening\n\nDisease is frequent or severe enough to be important.\nDisease can be detected through screening well before symptoms appear.\nEffective treatment at this early stage can improve outcomes of cases or prevent transmission.\nTreatment is more effective if done earlier.\nScreening test can distinguish between diseased and non-diseased.\n\n\n\n9.6.2 Characteristics of screening tests\n\nSensitivity = probability that a person with disease is detected by test\nSpecificity = probability that a person without disease gets a correct negative result\nPositive predictive value = probability that someone with a positive test has the disease. Depends on prevalence of disease.\nNegative predictive value = probability that someone with a negative test doesn’t have the disease. Depends on prevalence of disease.\n\n\n\n9.6.3 Evaluations of effectiveness of screening programs\n\nRCT: randomly assign people to screening\nCohort: observe outcomes in screened vs. non-screened, following both screened and unscreened from time of screening.\nEcological: compare disease rate in populations with and without screening programs\nCase-control: cases are those who developed condition that could have been averted through screening. Controls are those at risk for disease at time of screening.\n\n\n\n9.6.4 Different characteristics of screening tests are important in different contexts.\n\nCourt system: overarching goal is to avoid sending innocent to jail.\nDrunk driving after a party: overarching goal is to prevent drunk driving. If you’re having a party, and you err on the side of someone sleeping over unnecessarily, that’s better than the opposite."
  },
  {
    "objectID": "chapt7.html#test-accuracy",
    "href": "chapt7.html#test-accuracy",
    "title": "9  Measurement error and screening",
    "section": "9.7 Test accuracy",
    "text": "9.7 Test accuracy\nEstimating positive and negative predictive value: the easiest way is to fill out the 2x2 table with sample size, prevalence of disease, and by applying the definitions of sensitivity and specificity. Then PPV and NPV are easy to calculate from the table.\n\n\n\n\nPositive test\nNegative test\n\n\n\n\nDisease\n\n\n\n\nNo disease\n\n\n\n\nTotal\n\n\n\n\n\nHow do you find each parameter from the tables?\nPPV =\nNPV =\n\n9.7.1 Probability notation\nYou can use the probability notation, but these risk errors, as in these xkcds.\n\n\n\nAlt text: P((B|A)|(A|B)) represents the probability that you’ll mix up the order of the terms when using Bayesian notation.\n\n\n\n\n\nAlt text: Don’t forget to add another term for “probability that the Modified Bayes’ Theorem is correct.”\n\n\nEvents A, B. \\(\\bar{A}\\) is the event that A does not occur.\nP(A) = probability of A.\nP(AB) = probability of A and B.\nFor all events A and B, P(A or B) \\(= P(A) + P(B) - P(AB)\\)\nIf A and B are independent, \\(P (AB) = P (A)P(B)\\). Equivalently, \\(P (A|B) = P (A)\\): i.e., knowing that B occurred does not convey information about whether A occurred.\nConditional probability, Bayes’s Theorem: $P(B|A) = P (AB) P (A) $\nLaw of total probability. \\(P(A) = P (A|B)P (B) + P(A|\\bar{B})P(\\bar{B})\\)\nOne more Bayes theorem xkcd:\n\n\n\nAlt text: This is roughly equivalent to ‘number of times I’ve picked up a seashell at the ocean’ / ‘number of times I’ve picked up a seashell’, which in my case is pretty close to 1, and gets much closer if we’re considering only times I didn’t put it to my ear.\n\n\nRelative risk RR \\(≡ P (B|A)/P ( B | \\bar{A} )\\) D+ =has disease, D− = no disease. T+ = positive test. T− = negative test.\nSpecificity \\(C ≡ P (T −|D−)\\): probability that someone without the disease will correctly test negative. Out of all people without the disease, how many tested negative? Opposite: false positive.\nSensitivity \\(S ≡ P(T+|D+)\\): probability that someone with the disease will correct test positive. Out of all people with the disease, how many tested positive? Opposite: false negative.\nPositive predictive value \\(= PPV = P V + = P (D+|T +)\\)\nNegative predictive value \\(= NPV = P V − = P (D−|T −)\\)\nReceiver operating characteristic (ROC) curves: plot of 1-C versus S. used for choosing cut-off point for a diagnostic test.\nArea under the curve (AUC) refers to area under the ROC curve."
  },
  {
    "objectID": "chapt7.html#exercises",
    "href": "chapt7.html#exercises",
    "title": "9  Measurement error and screening",
    "section": "9.8 Exercises",
    "text": "9.8 Exercises\n\n9.8.1 Pilot drug tests\nThis problem comes from Dick Light’s course, Statistics for Leaders\nThere are 100,000 airline pilots in the US. Obviously a bad thing if some of them take drugs. Some of them probably do but not too many. Let’s estimate that 1% of them take drugs. Drug test has specificity 95%, and sensitivity 95%.\n\nFill in the following table according to the information above.\n\n\n\n\n\nTest +\nTest -\nTotal\n\n\n\n\nOn drugs\n\n\n\n\n\nNot on drugs\n\n\n\n\n\nTotal\n\n\n100,000\n\n\n\n\nUsing the table, calculate the positive predictive value of the drug test.\nTo improve PPV, which aspect of the test do we need to improve, sensitivity or specificity?\nIf we couldn’t improve the test, is there anything that we could do to improve the positive predictive value? What assumption regarding the test outcomes would we need to make to improve the PPV?\n\n\n\n9.8.2 Lack of gold standard tests\nThe data below comes from a study to estimate the prevalence of Strongyloides in Cam- bodian refugees to Canada in 1982–83 for which only two imperfect tests are available: a stool test and a blood test. Neither test is a gold standard. Current gold standard is up to 7 serial stool examinations. http://www.cdc.gov/parasites/strongyloides/health professionals/\n\n\n\n\nStool Test +\nStool Test -\nTotal\n\n\n\n\nBlood test +\n38\n87\n125\n\n\nBlood test -\n2\n35\n37\n\n\nTotal\n40\n122\n162\n\n\n\n\nWhat’s the prevalence of the disease according to the stool test?\nWhat’s the prevalence of the disease according to the blood test?\nIs there any way to estimate the actual prevalence?\n\n\n\n9.8.3 Misunderstanding Bayes\nThe State of Florida offered this argument in a brief filed on October 4, 2012 Given the small percentage of the population [about 5%] that is licensed to carry a concealed firearm, the overwhelming majority of firearms, or 95%, are not licensed to be concealed. Thus, an officer’s suspicion that a [concealed] firearm is not licensed would be reasonable because, in any given case, there would be, statistically speaking, a 95% likelihood of illegality. www.loweringthebar.net/2012/10/florida-ag-not-acquainted-with-statistics.html\nWhat mistake did the Florida Attorney General make? Express the mistake in probabilistic terms. You don’t need to use notation.\n\n\n9.8.4 Test-retest\nThe following data comes from a 2-week test-retest evaluation of the Youth Risk Behavior Survey (YRBS). Trained data collectors administered 72 questions from the YRBS to 4628 students at 61 high schools at a 2 week interval. Students’ answers were compared. The question was “Have you ever been pregnant or made another pregnant?”\n\n\n\n\n\n\n\n\n\n\nweek 2, Ever pregnant (%)\nweek 2, Never pregnant (%)\nTotal (%)\n\n\n\n\nBaseline, Ever pregnant (%)\n5\n4\n9\n\n\nBaseline, Never pregnant (%)\n3\n88\n91\n\n\nTotal\n8\n92\n100\n\n\n\n\nIf you believe these data, what proportion of the sample became pregnant or made another pregnant in the 2 week interval?\nIf you believe this data, what proportion of the sample forgot having been pregnant or made another pregnant?\nWhat are the cross-sectional percentages of those who became pregnant or made another pregnant in each survey? (e.g., At baseline, how many have ever been pregnant or made another pregnant, if only have that wave’s data? Likewise wave 2.)\nWhat proportion of respondents retracted their claim that they were ever pregnant or made another pregnant?\nCan you identify a single percentage that summarizes how many people were pregnant?"
  },
  {
    "objectID": "chapt8.html#confounding-definition",
    "href": "chapt8.html#confounding-definition",
    "title": "10  Confounding and linear regression",
    "section": "10.1 Confounding definition",
    "text": "10.1 Confounding definition\nConfounders must be associated with both the exposure and the disease, and generally come before both exposure and disease. Confounders may explain all or part of an observed relationship between exposure and disease.\nA factor that comes after the exposure is often not a confounder. It’s an intermediate variable, and controlling for it will introduce bias.\nA confounder is: 1. associated with disease among non-exposed 2. associated with exposure 3. not intermediate between exposure and outcome\nSimpson’s paradox: type of confounding, where the effect reverses after stratification."
  },
  {
    "objectID": "chapt8.html#effect-modification",
    "href": "chapt8.html#effect-modification",
    "title": "10  Confounding and linear regression",
    "section": "10.2 Effect modification",
    "text": "10.2 Effect modification\nAn effect modifier is a factor that changes the relationship between a predictor and an outcome. For example, if smoking is more dangerous for men than women for some health outcome, then gender is an effect modifier of the relationship between smoking and that health outcome.\nAddressing confounding through stratification\nIf effect estimate changes after stratifying on a potential confounder, then confounding is present.\nA rule of thumb is that if the effect estimate changes by 10%, the crude estimate is confounded, and the adjusted values are more appropriate to present. We already saw one example with the Berkeley admissions data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMen applicants\nMen admitted\n\nWomen applicants\nWomen admitted\n\n\n\n\n\nArts\n4100\n1300\n32%\n8250\n3150\n38%\n\n\nSciences\n8200\n5100\n62%\n2900\n1900\n66%\n\n\nTotal\n12300\n6400\n52%\n11150\n5050\n45%\n\n\n\nNote that the 10% rule of thumb is just a rule of thumb, and it doesn’t imply confunding, nor does it imply whether a term should be in a regression or not.\n\n10.2.1 Confounding example\n\n\n10.2.2 Confounding in a case-control study\n\n\n10.2.3 Confounding in a cohort study\n\n\n10.2.4 Addressing potential confounding through rate adjustment\nRate adjustment is a method of adjustment on a small number of categorical factors. Two groups may have different age distributions. Can weight communities by age composition of a reference group, to make the rates comparable.\n\n\n10.2.5 Addressing confounding through multivariate regression\nOften multiple factors are potential confounders, and some confounders are continuous. Discretization of continuous factors into a small number of categories allows residual confounding. Multivariate regression can reduce confounding by many factors simultaneously. The coefficients can all be described as adjusted for all of the covariates included in the regression.\n\n\n\n\n\n\n\n\nOutcome\nRegression method\nInterpretation\n\n\n\n\nContinuous\nLinear regression\nIncrease of outcome associated with one unit increase in the exposure\n\n\nCount\nPoisson regression\nIncidence rate ratio (longitudinal data) or prevalence ratio (cross-sectional data)\n\n\nBinary\nPoisson regression\nIncidence rate ratio (longitudinal data) or prevalence ratio (cross-sectional data)\n\n\n\nLogistic regression\nodds ratio\n\n\n\nLinear probability model\nPercentage point difference in probability of outcome associated with one unit increase in exposure\n\n\nProportions\nLogistic regression\nodds ratio\n\n\n\nNote: log = ln = natural log.\nFor the above example of potential confounding by age, one could use a logistic regression with outcome the proportion of people with the disease and use age as a predictor. The coefficient on age would tell us if there was a difference in disease by age."
  },
  {
    "objectID": "chapt8.html#identifying-effect-modification-using-multivariate-regression",
    "href": "chapt8.html#identifying-effect-modification-using-multivariate-regression",
    "title": "10  Confounding and linear regression",
    "section": "10.3 Identifying effect modification using multivariate regression",
    "text": "10.3 Identifying effect modification using multivariate regression\nMultivariate regression also allows testing for effect modification. Include an interaction term in the regression that is the product of the factors where there may be effect modification. It’s easier to identify graphically. This data comes from a review of chocolate bars in Consumer Reports: price, rating by Consumer Reports raters, and type of chocolate (milk or 70% cacao dark.)\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nchocolate=read.csv(\"chocolate-ratings-consumer-reports.csv\")\nxyplot(rating ~ price, data=chocolate, auto.key=T,\ntype=c(\"p\", \"r\"))\n\n\n\n\n\nxyplot(rating ~ price, data=chocolate, group=type, auto.key=T,\ntype=c(\"p\", \"r\"), pch=c(9, 10))\n\n\n\n\nWhich of these plots shows effect modification? How can you tell?\nWhat do we see if we try a regression?"
  },
  {
    "objectID": "chapt8.html#assumptions-of-regression",
    "href": "chapt8.html#assumptions-of-regression",
    "title": "10  Confounding and linear regression",
    "section": "10.4 Assumptions of regression",
    "text": "10.4 Assumptions of regression\nRegression makes the following assumptions: 1. Linearity: The plot of response means (outcome) against the explanatory variable (pre- dictor) is a straight line. 2. Constant variance: The spread of the responses around the straight line is the same at all levels of the explanatory variable. Economists call this “homoscedasticity”. The opposite of homoscedasticity is heteroscedasticity. (Economists call statistics “econometrics” so clearly they just make up their own words.) 3. Normality: The subpopulations of responses around the straight line is the same at all levels of the explanatory variable. 4. Independence: The location of any outcome in relation to its mean cannot be predicted from knowledge of where other outcomes are in relation to their means, either fully or partially. Further, the location of any outcome in relation to its mean cannot be predicted from knowledge of the explanatory variable values. When these assumptions are violated, linear regression results may be inaccurate or mis- leading. 1. Violations of Linearity: Linearity could be violated either if the points form a curved line throughout the range of the predictors, or if there are enough outliers to change the direction of the line. Estimated means and predictions may be biased. 2. Non-constant variance: If there is non-constant variance, standard errors, signfiicance tests, and confidence intervals may be inaccurate. 3. Violations of normality: Usually does not threaten the validity of estimates of coefficients and their standard errors because the sampling distribution of estimates is normal re- gardless of the distribution of the population. With small samples that contain outliers, violations of normality can bias estimates of coefficients and standard errors.\n\nLack of independence: Lack of independence doesn’t bias estimates of coefficients, but it harms standard errors. Serial effects — where one observation relies on the observation before it — require models designed especially for this situation.\n\nCreate plots\n\n\n\n\nBest case scenario: standard regression (lm command in R) is perfect because the means are in a straight line and the standard deviation is approximately equal.\nMeans are curved — with a sharp increase at the beginning and reduced slope as X increases — and the standard deviations are about equal. This could occur in a case where there are reduced marginal effects as a predictor increases. Transforming X may make the means linear. Taking the log of X may help. Then do regression.\nMeans are curved in an inverted U shape, and the standard deviations are about equal. This could occur in a case where an outcome peaks at a certain ideal value of a predictor and then decreases again. Including a term with X2 will account for this effect. Then use regression.\nMeans are curved upwards, with slow increases in outcome for low values of the predictor, and increasing more sharply. Also, standard deviations increase with increasing values of the predictor. Transform Y (e.g., take the log of Y, square root of Y, or recriprocal of Y.) Plot again and evaluate whether this fixes the problem, and then use regression.\nThe means increase in a straight line and the standard deviations are about equal, but the distributions around the line are skewed. There is nothing to do about this problem, except to do regresison and report the skewness.\nThe means are a straight line, but the standard deviations are increasing as X increases. Regression gives reasonable estimates for the coefficients, but the standard errors are biased. Use weighted regression, which will be taught later.\n\n\n10.4.1 Weaknesses of multivariate regression\nRegression should never be the first step in data analysis. Data analysis should always begin with univariate and bivariate analysis, preferably plots. Recall Anscombe’s plots: 4 different plots with exactly the same numerical summaries, including regression line. Multivariate regression relies on assumptions that are often not true. Multivariate regression requires that relationships between predictor and outcome be close to linear or log-linear. If a relationship between predictor and outcome is exponential, there will still be residual confounding after multivariate regression."
  },
  {
    "objectID": "chapt8.html#analyzing-potential-confounding-and-effect-modification-in-r",
    "href": "chapt8.html#analyzing-potential-confounding-and-effect-modification-in-r",
    "title": "10  Confounding and linear regression",
    "section": "10.5 Analyzing potential confounding and effect modification in R",
    "text": "10.5 Analyzing potential confounding and effect modification in R\nThis example will demonstrate how to predict height from simple inputs, and demonstrates effect modification. Confounding isn’t particularly an issue because the inputs are obvious: parents’ heights and children’s sex.\n\n10.5.1 Heritability of height\nA famous regression dataset is from Francis Galton — heights of adults and their parents — which is in the mosaic package. This analysis involves simple prediction of an outcome (depen- dent variable) from predictor variables (independent variables.) The data has been cleaned of non-numeric entries for height such as “tall”, “short”, “idiotic”, and “deformed.”\nSource: “Transmuting” women into men: Galton’s family data on human stature. (2004) The American Statistician, 58(3):237–243.\nWe can start out by looking at the distribution of (adult) children’s heights. Generally, we want outcomes of regressions to be normally distributed, or at least symmetrical. Do they look normally distributed? Symmetrical?\n\nhistogram(~height, data=Galton)\n\n\n\nhistogram(~height | sex, data=Galton, auto.key=T)\n\n\n\n\nWe can also get a sense for which heights are typical for each group: males, females, mothers, and fathers. Do the children seem to be taller than their parents, on average?\n\nfavstats(~height, groups=sex, data=Galton)\n\n  sex min   Q1 median   Q3  max     mean       sd   n missing\n1   F  56 62.5   64.0 65.5 70.5 64.11016 2.370320 433       0\n2   M  60 67.5   69.2 71.0 79.0 69.22882 2.631594 465       0\n\nfavstats(~father, data=Galton)\n\n min Q1 median Q3  max     mean       sd   n missing\n  62 68     69 71 78.5 69.23285 2.470256 898       0\n\nfavstats(~mother, data=Galton)\n\n min Q1 median   Q3  max     mean       sd   n missing\n  58 63     64 65.5 70.5 64.08441 2.307025 898       0\n\n\nHow are children’s heights related to parents’ heights? Is the relationship different for male and female children?\nLook first at plots.\n\nxyplot(height ~ father, groups=sex, type=c(\"p\", \"r\"), auto.key=T, data=Galton)\n\n\n\nxyplot(height ~ mother, groups=sex, type=c(\"p\", \"r\"), auto.key=T, data=Galton)\n\n\n\n\nWe have the concept of regression towards the mean: the children of exceptionally tall or exceptionally short parents will tend to be closer to average height. Do we see regression to the mean in this dataset? How could you tell from these plots? We can do regression analysis using this data.\n\nmodel1=lm(height ~ father + mother + sex, data=Galton)\nsummary(model1)\n\n\nCall:\nlm(formula = height ~ father + mother + sex, data = Galton)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.523 -1.440  0.117  1.473  9.114 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15.34476    2.74696   5.586 3.08e-08 ***\nfather       0.40598    0.02921  13.900  < 2e-16 ***\nmother       0.32150    0.03128  10.277  < 2e-16 ***\nsexM         5.22595    0.14401  36.289  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.154 on 894 degrees of freedom\nMultiple R-squared:  0.6397,    Adjusted R-squared:  0.6385 \nF-statistic:   529 on 3 and 894 DF,  p-value: < 2.2e-16\n\n\nWhat does each component mean? Intercept Father Mother Sex R-squared F-statistic Degrees of freedom Residual standard error Is the intercept meaningful? If not, how can we transform the variables so that the intercept becomes meaningful?\nDoes the relationship between parents’ heights differ for males and females? How can you tell?\n\nmodel1b=lm(height ~ father + mother + sex + father*sex, data=Galton)\nsummary(model1b)\n\n\nCall:\nlm(formula = height ~ father + mother + sex + father * sex, data = Galton)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.5248 -1.4463  0.1139  1.4718  9.1080 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15.76019    3.33887   4.720 2.73e-06 ***\nfather       0.40023    0.03927  10.192  < 2e-16 ***\nmother       0.32123    0.03132  10.256  < 2e-16 ***\nsexM         4.33631    4.06250   1.067    0.286    \nfather:sexM  0.01285    0.05864   0.219    0.827    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.155 on 893 degrees of freedom\nMultiple R-squared:  0.6397,    Adjusted R-squared:  0.6381 \nF-statistic: 396.4 on 4 and 893 DF,  p-value: < 2.2e-16\n\n\nWe can also explore further and consider two separate models: one for males, and one for females. Do males inherit their height from their fathers, or from both parents? Likewise, for females?\n\nmodel1.m=lm(height ~ father, data=subset(Galton, sex==\"M\"))\nsummary(model1.m)\n\n\nCall:\nlm(formula = height ~ father, data = subset(Galton, sex == \"M\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.3774 -1.4968  0.0181  1.6375  9.3987 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 38.25891    3.38663   11.30   <2e-16 ***\nfather       0.44775    0.04894    9.15   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.424 on 463 degrees of freedom\nMultiple R-squared:  0.1531,    Adjusted R-squared:  0.1513 \nF-statistic: 83.72 on 1 and 463 DF,  p-value: < 2.2e-16\n\nmodel2.m=lm(height ~ father + mother, data=subset(Galton, sex==\"M\"))\nsummary(model2.m)\n\n\nCall:\nlm(formula = height ~ father + mother, data = subset(Galton, \n    sex == \"M\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.5305 -1.5683  0.2141  1.5183  9.0968 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 19.39988    4.13310   4.694 3.54e-06 ***\nfather       0.41175    0.04668   8.820  < 2e-16 ***\nmother       0.33355    0.04600   7.252 1.74e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.3 on 462 degrees of freedom\nMultiple R-squared:  0.2397,    Adjusted R-squared:  0.2364 \nF-statistic: 72.82 on 2 and 462 DF,  p-value: < 2.2e-16\n\nmodel1.f=lm(height ~ mother, data=subset(Galton, sex==\"F\"))\nsummary(model1.f)\n\n\nCall:\nlm(formula = height ~ mother, data = subset(Galton, sex == \"F\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.8814 -1.5446  0.0983  1.4452  6.7717 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 43.15546    3.05709  14.117  < 2e-16 ***\nmother       0.32655    0.04761   6.859 2.42e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.253 on 431 degrees of freedom\nMultiple R-squared:  0.09841,   Adjusted R-squared:  0.09631 \nF-statistic: 47.04 on 1 and 431 DF,  p-value: 2.421e-11\n\nmodel2.f=lm(height ~ mother + father, data=subset(Galton, sex==\"F\"))\nsummary(model2.f)\n\n\nCall:\nlm(formula = height ~ mother + father, data = subset(Galton, \n    sex == \"F\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3064 -1.3497  0.0261  1.4154  5.6684 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 16.61023    3.61648   4.593 5.75e-06 ***\nmother       0.30746    0.04211   7.301 1.39e-12 ***\nfather       0.40072    0.03629  11.041  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.991 on 430 degrees of freedom\nMultiple R-squared:  0.2975,    Adjusted R-squared:  0.2943 \nF-statistic: 91.07 on 2 and 430 DF,  p-value: < 2.2e-16\n\n\nDoes the number of kids matter? Does the number of kids matter differently for males or for females?\n\nmodel2a=lm(height ~ father + mother + sex + nkids, data=Galton)\nsummary(model2a)\n\n\nCall:\nlm(formula = height ~ father + mother + sex + nkids, data = Galton)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.4748 -1.4500  0.0889  1.4716  9.1656 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 16.18771    2.79387   5.794 9.52e-09 ***\nfather       0.39831    0.02957  13.472  < 2e-16 ***\nmother       0.32096    0.03126  10.269  < 2e-16 ***\nsexM         5.20995    0.14422  36.125  < 2e-16 ***\nnkids       -0.04382    0.02718  -1.612    0.107    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.152 on 893 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6391 \nF-statistic: 398.1 on 4 and 893 DF,  p-value: < 2.2e-16\n\n\n\nmodel2=lm(height ~ father + mother + sex + nkids*sex, data=Galton)\nsummary(model2)\n\n\nCall:\nlm(formula = height ~ father + mother + sex + nkids * sex, data = Galton)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.440 -1.441  0.083  1.452  9.198 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15.718028   2.815112   5.583 3.13e-08 ***\nfather       0.401301   0.029640  13.539  < 2e-16 ***\nmother       0.321472   0.031245  10.289  < 2e-16 ***\nsexM         5.648164   0.360889  15.651  < 2e-16 ***\nnkids       -0.007547   0.038574  -0.196    0.845    \nsexM:nkids  -0.071233   0.053780  -1.325    0.186    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.151 on 892 degrees of freedom\nMultiple R-squared:  0.6414,    Adjusted R-squared:  0.6394 \nF-statistic: 319.1 on 5 and 892 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "chapt9.html#causal-graphs",
    "href": "chapt9.html#causal-graphs",
    "title": "11  Confounding and causal graphs",
    "section": "11.1 Causal graphs",
    "text": "11.1 Causal graphs\n\n11.1.1 Graph terminology\nIn discrete math, a graph is a set of vertices and edges. Edges may be either directed or undirected. Undirected edges can be used to depict connections between nodes without regard to order, such as in a social network where all connections are mutual.\n\nlibrary(DiagrammeR)\n\nHere’s an undirected graph.\n\ngrViz(\"\n    digraph {\n    \n      # Nodes\n      node [shape = plaintext]\n     \n      # Edges\n      edge [color = black,\n            arrowhead = none]\n      rankdir = LR\n      A->B\n      B->C\n      C->A\n      \n      # Graph\n      graph [overlap = true, fontsize = 6]\n    }\")\n\n\n\n\n\nA cycle is a graph where the edges go in a circle, as here:\n\ngrViz(\"\n    digraph {\n    \n      # Nodes\n      node [shape = plaintext]\n     \n      # Edges\n      edge [color = black,\n            arrowhead = vee]\n      rankdir = LR\n      A->B\n      B->C\n      C->A\n      \n      # Graph\n      graph [overlap = true, fontsize = 6]\n    }\")"
  },
  {
    "objectID": "chapt9.html#directed-acyclic-graphs",
    "href": "chapt9.html#directed-acyclic-graphs",
    "title": "11  Confounding and causal graphs",
    "section": "11.2 Directed acyclic graphs",
    "text": "11.2 Directed acyclic graphs\nEpidemiology uses Directed Acyclic Graphs (DAGs). Analysis that preserves the order of events does not use graphs with cycles.\n\n11.2.1 Backdoor paths\nThe simplest backdoor path is confounding. Here’s a DAG showing confounding:\n\ngrViz(\"\n    digraph causal {\n    \n      # Nodes\n      node [shape = plaintext]\n      E [label = 'Exposure']\n      C [label = 'Confounder']\n        D [label = 'Outcome']\n      \n      # Edges\n      edge [color = black,\n            arrowhead = normal]\n      rankdir = LR\n      E->D\n      C->E\n      C->D\n      \n      # Graph\n      graph [overlap = true, fontsize = 6]\n    }\")\n\n\n\n\n\n\n\n11.2.2 Collider\nHere’s a graph showing a collider \\(A → B ← C\\), where both A and B may cause C.\n\ngrViz(\"\n    digraph {\n    \n      # Nodes\n      node [shape = plaintext]\n     \n      # Edges\n      edge [color = black,\n            arrowhead = vee]\n      rankdir = LR\n      A->B\n      C->B\n      \n      # Graph\n      graph [overlap = true, fontsize = 6]\n    }\")\n\n\n\n\n\n\n\n11.2.3 Mediator\n\ngrViz(\"\n    digraph causal {\n    \n      # Nodes\n      node [shape = plaintext]\n      E [label = 'Exposure']\n      M [label = 'Mediator']\n        D [label = 'Outcome']\n      \n      # Edges\n      edge [color = black,\n            arrowhead = normal]\n      rankdir = LR\n      E->M\n      M->D\n      E->D\n\n      # Graph\n      graph [overlap = true, fontsize = 6]\n    }\")"
  },
  {
    "objectID": "chapt9.html#instrumental-variables-analysis",
    "href": "chapt9.html#instrumental-variables-analysis",
    "title": "11  Confounding and causal graphs",
    "section": "11.3 Instrumental variables analysis",
    "text": "11.3 Instrumental variables analysis\n\n11.3.1 Instrumental variables definition\nInstrumental variables are factors that are associated with the treatment but not the outcome.\n\ngrViz(\"\n    digraph causal {\n    \n      # Nodes\n      node [shape = plaintext]\n      E [label = 'Exposure']\n      I [label = 'Instrument']\n        D [label = 'Outcome']\n      \n      # Edges\n      edge [color = black,\n            arrowhead = normal]\n      rankdir = LR\n      E->D\n      I->E\n\n      # Graph\n      graph [overlap = true, fontsize = 6]\n    }\")\n\n\n\n\n\n\n\n11.3.2 Instrumental variables example: Vietnam draft lottery\nQuasi experiments for policy evaluation Instrumental variables Ads for military service claim that it gives people skills and opportunities that they can transfer to the civilian sector, and increase their earnings. If we compared people who entered the military voluntarily, they might be self-selected: only people who feel like they have poor job prospects , or people who are more motivated, might enter the military. The Vietnam draft chose birthdays at random, so it’s similar to a randomized experiment, but it’s not a randomlzed experiment. Most of those who fought in Vietnam had volunteered. Men whose lottery numbers were chosen were more likely to enlist, but might not enlist due to occupation or educational defer- ment, poor health, or low test scores: white men of the appropriate ages selected in the lottery were 18 percentage points more likely to enlist, and non-white men were 8.5 percentage points more likely to enlist. Using a technique called instrumental variables — using birthday as an instrument for military enrollment — Josh Angrist found that military service caused 15% lower lifetime earnings. (Josh Angrist, “Lifetime Earnings and the Vietnam Era Draft Lottery: Evidence From Social Security Administrative Records”, American Economic Review, 1990) Many other studies have looked at Vietnam service and other outcomes: e.g., suicide/accident mortality.\nAds for military service claim that it gives people skills and opportunities that they can transfer to the civilian sector, and increase their earnings. If we compared people who entered the military voluntarily, they might be self-selected: only people who feel like they have poor job prospects , or people who are more motivated, might enter the military. The Vietnam draft chose birthdays at random, so it’s similar to a randomized experiment.\nNot actually a randomized experiment, though: the majority of those who fought in Vietnam had volunteered. Men whose lottery numbers were chosen were more likely to enlist, but might not enlist due to occupation or educational deferment, poor health, or low test scores: white men of the appropriate ages selected in the lottery were 18 percentage points more likely to enlist, and non-white men were 8.5 percentage points more likely to enlist.\nUsing a technique called instrumental variables — using birthday as an instrument for military enrollment — Josh Angrist found that military service caused 15% lower lifetime earnings. (Josh Angrist, “Lifetime Earnings and the Vietnam Era Draft Lottery: Evidence From Social Security Administrative Records”, American Economic Review, 1990). Angrist did another study of military enlistment and mortality.\nIf you were to draw a causal graph, it would look like this:\n\ngrViz(\"\n    digraph causal {\n    \n      # Nodes\n      node [shape = plaintext]\n      E [label = 'Military enlistment']\n      I [label = 'Birth date']\n        D [label = 'Mortality']\n      \n      # Edges\n      edge [color = black,\n            arrowhead = normal]\n      rankdir = LR\n      E->D\n      I->E\n\n      # Graph\n      graph [overlap = true, fontsize = 6]\n    }\")\n\n\n\n\n\nWhy is birthday an instrument for the effect of military service on mortality?\n\n\n11.3.3 Example: Distance to hospital and health outcomes\nDistance to hospitals or health care facilities with certain characteristics is a common instrument in many cases:\nDistance to nearest hospital with cardiac catheterization used as an instrument to study the effect of intensive treatment on acute myocardial infarction compared with less invasive treatment. (McClellan M, McNeil BJ, Newhouse JP. Does more intensive treatment of acute myocardial infarction in the elderly reduce mortality? Analysis using instrumental variables. JAMA. 1994 Sep 21;272(11):859-66.)\n\ngrViz(\"\n    digraph causal {\n    \n      # Nodes\n      node [shape = plaintext]\n      E [label = 'Cardiac catheterization']\n      I [label = 'Distance to nearest hospital with catheterizaation']\n        D [label = 'Mortality']\n      \n      # Edges\n      edge [color = black,\n            arrowhead = normal]\n      rankdir = LR\n      E->D\n      I->E\n\n      # Graph\n      graph [overlap = true, fontsize = 6]\n    }\")\n\n\n\n\n\nWhy is distance to the nearest hospital with cardiac catheterization an instrument for the effect of cardiac catheterization on mortality after AMI?\nAnother example: Distance to continuing care retirement communities used as an instrument to study whether these retirement communities provide higher quality. (John R. Bowblis, Heather S. McHone, An instrumental variables approach to post-acute care nursing home quality: Is there a dime’s worth of evidence that continuing care retirement communities provide higher quality? Journal of Health Economics Volume 32, Issue 5, September 2013, Pages 980–996)\nAnother example: Distance to Cedars-Sinai Hospital in LA to estimate hospital quality of pneumonia care in S California. (Estimating the quality of care in hospitals using instrumental variables. Journal of Health Economics, Volume 18, Issue 6, December 1999, Pages 747-767 Gautam Gowrisankaran, Robert J. Town)\n\n\n11.3.4 Causal graphs resources\nFor more about causal graphs, see the following resources presented in no particular order: • http://dagitty.net/\n• https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html\n• Morgan and Winship, Counterfactuals and Causal Inference, 2nd edition, Cambridge University Press.\n• Modern Epidemiology, 4th edition.\n• Coursera course: https://www.coursera.org/lecture/crash-course-in-causality/causal-graphs"
  },
  {
    "objectID": "chapt9.html#propensity-score-matching-methods",
    "href": "chapt9.html#propensity-score-matching-methods",
    "title": "11  Confounding and causal graphs",
    "section": "11.4 Propensity score matching methods",
    "text": "11.4 Propensity score matching methods\nPropensity score matching methods simulate a randomized experiment within observational data by balancing two or more groups on all important observed factors other than the factor of interest. Propensity score matching methods can also be used to fix a randomized experiment with severe flaws, such as if many participants did not adhere to their assigned treatment or dropped out. Propensity score matching methods are a family of over a dozen methods, including:\n\nPropensity score stratification: make quintiles by propensity score, and compute treatment effect within each quintile.\nNearest-neighbor propensity score matching\nNearest neighbor matching on several variables, often within propensity score calipers, using exact matching and distance matching with the Mahanobis (correlation-adjusted) distance measure\nExact matching: often not possible but it is possible with large datasets like all US birth certificates.\nCoarsened exact matching (CEM)\n\nStatistical research finds that there is no single superior matched sampling method, and there is also no way to know in advance which method to use. The best matching method is the one that balances the treatment and control groups, and allows you to compare them without concern about confounding on the specified variables.\nFurther reading: Gelman and Hill, Data Analysis using regression and multilevel/hierarchical models Rubin “Estimating causal effects from large data sets using propensity scores” Annals of Internal Medicine 1997; 127(8):757–63 Morgan and Winship, Counterfactuals and causal inference: Methods and principles for social research MatchIt software can implement the above methods.\n\n11.4.1 Example: Cardiologists and generalists: who provides better care?\n“Causal Effect of Ambulatory Specialty Care on Mortality Following Myocardial Infarction: A Comparison of Propensity Score and Instrumental Variable Analyses.” Specialists charge more than generalists. Are the extra costs worth it?\nThis paper evaluated whether the type of cardiology care impacted survival from heart attacks. They compared the groups under care of cardiologists versus generalists, and created a comparison group of those treated by generalists such that the two groups were similar.\n\n\nCan you identify potential confounders in the full sample (first three columns of this table)? That is, what are some differences between the patient groups treated by cardiologists versus generalists that might impact survival?\nDid the matching procedure address some of your concerns?\nThey predicted who was most likely to be treated by a cardiologist and divided the groups into quintiles. The lowest propensity score were predicted to have the lowest probability of being treated by a cardiologist: based on the above table, what characteristics are most true of the lowest propensity score quintile?\nThen they estimated the mortality rate in each quintile. Which group in each quintile had lower mortality rates? Which patients does treatment by cardiologists appear to make the biggest difference? Overall, do patients seeing cardiologists have lower mortality rates than patients seeing generalists, after matching?\n\n\n\n11.4.2 Example: Hospice and surviving relative\nNicholas A. Christakis, Theodore J. Iwashyna. The health impact of health care on families: a matched cohort study of hospice use by decedents and mortality outcomes in surviving, widowed spouses. Social Science & Medicine 57 (2003) 465–475.\nStudy of 195,553 elderly couples, of whom 30,838 used hospice. Data is extracted from Medicare claims data, and they named their dataset Care after the Onset of Serious Illness (COSI). COSI has 1.2 million patients diagnosed in 1993 with 13 leading causes of death.\nUsed propensity score matching to identify 30,838 similar elderly couples who did not use hospice. Diagram misuses terms cases and controls.\n\nMatching variables were determinants of hospice use from the literature. They used a separate propensity score model for men and women but the same covariates.\n\nDecedents’ attributes: age, race, Medicaid, average income in zip code, diagnosis, comor- bidity score, duration\nhospital attributes: technology available and teaching hospital status\n\nThe researchers checked the match of the adequacy of the model using a “recommended method of testing for differences in covariates” between the groups (hospice vs. non-hospice bereaved spouses, stratifying by quintiles of estimated propensity score. They did not display the balance of the groups, and they did not explain this method, other than citing a paper (Rosenbaum and Rubin 1984.) They give a table comparing the characteristics before and after matching.\nThey used exact matching on gender and nearest-neighbor estimated propensity score (within 0.005 on scale of 0–1). The procedure identifed matches for 99.92% of surviving wives and 99.04% of surviving husbands.\n\nAfter matching, the researchers evaluated the outcomes for the bereaved spouses of people who used hospice versus matched bereaved spouses of people who did not use hospice.\n\n\n\n\n\n\n\n\n\n\nHospice (n=30,838)\nNo hospice (n=30,838)\nOdds ratio\n\n\n\n\nWife died within 18 months\n4.9\n5.4\n0.92 (0.84, 0.99)\n\n\nHusband died within 18 months\n13.2\n13.7\n0.95 (0.84, 1.06)\n\n\n\n\n\n11.4.3 Example: Evaluation of cardiac catheterization\n“Analysis of Observational Studies in the Presence of Treatment Selection Bias: Effects of Inva- sive Cardiac Management on AMI Survival Using Propensity Score and Instrumental Variable Methods”\nThis study evaluates whether receipt of invasive cardiac care (cardiac catheterization) predicts mortality over 1 and 4 years. As before, they looked at differences between those receiving cardiac catheterization and less invasive care in their full sample.\n\nCan you identify potential confounders in the full sample (first three columns of this table)? That is, what are some differences between the patient groups who received cardiac catheterization within 30 days versus not that might impact survival? Did the matching procedure address some of your concerns?\nThis table shows the distribution of certain variables by propensity score decile.\n\nHow can you summarize the characteristics of those most likely versus least likely to receive cardiac catheterization?\n\nDoes the method of data analysis impact whether cardiac catheterization appears to reduce mortality?"
  },
  {
    "objectID": "chapt9.html#exercise",
    "href": "chapt9.html#exercise",
    "title": "11  Confounding and causal graphs",
    "section": "11.5 Exercise",
    "text": "11.5 Exercise\nThis exercise is based on the paper “Vegetarian Dietary Patterns and Mortality in Adventist Health Study 2.” JAMA Internal Medicine, June 3, 2013, available here (free to public): http://archinte.jamanetwork.com/article.aspx?articleid=1710093\n\nWhat type of study is this?\nWhat is the research question?\nWhat is the primary predictor of interest in this study? Define it briefly. If categorical or dichotomous, list the categories of the variable.\nWhich are the primary outcome(s) in this study?\nLooking at Table 2, identify some potential confounders of the relationship between the predictor and the outcome(s)? Explain in detail how that variable could cause a spurious connection between vegetarianism and lower mortality.\nWhich data analysis methods do the researchers use to adjust for confounding?\nDo you observe any effect modifiers in this study? List the potential effect modifiers and the relationships that they modify. How did you identify them?"
  },
  {
    "objectID": "chapt10.html#ecological-fallacy",
    "href": "chapt10.html#ecological-fallacy",
    "title": "12  Ecological studies",
    "section": "12.1 Ecological fallacy",
    "text": "12.1 Ecological fallacy\nInferences about individual behavior cannot be made from aggregate statistics. When people try to make such inferences anyhow, they have committed the ecological fallacy.\nExample: Mark Bittman published an oped in the NYT (“It’s the Sugar, Folks” Feb 27, 2013) with the ecological fallacy, and also inappropriate attribution of causality. http://opinionator.blogs.nytimes.com/2013/02/27/its-the-sugar-folks They had to issue the correction: “Correction: March 6, 2013 Mark Bittman’s column on Thursday incorrectly described findings from a recent epidemiological study of the relationship of sugar consumption to diabetes. The study found that increased sugar in a population’s food supply was linked to higher rates of diabetes — independent of obesity rates — but stopped short of stating that sugar caused diabetes. It did not find that”obesity doesn’t cause diabetes: sugar does.” Obesity is, in fact, a major risk factor for Type 2 diabetes, as the study noted.”\n\n12.1.1 Cross-level bias\nCross-level bias is one reason to avoid committing the ecological fallacy.\nThe following plots are an example of cross-level bias, which shows why that extra structure is useful for data analysis, both conceptually and statistically.\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nDF = data.frame(exposure = c(rnorm(30, 0.3, 0.05), rnorm(30, 0.6, 0.05), rnorm(30, 0.9, 0.05)), \n           outcome = c(rnorm(30, 0.3, 0.1), rnorm(30, 0.6, 0.1), rnorm(30, 0.9, 0.1)))\nxyplot(outcome ~ exposure, data=DF)\n\n\n\n\n\nexposure = c(rnorm(30, 0.3, 0.05), rnorm(30, 0.6, 0.05), rnorm(30, 0.9, 0.05), rnorm(30, 1.2, 0.05))\nDF2 = data.frame(exposure,\n           outcome = c(rnorm(30, 0.4, 0.05)-exposure[1:30], rnorm(30, 1.2, 0.05)-exposure[31:60], rnorm(30, 1.9, 0.05)-exposure[61:90], rnorm(30, 2.4, 0.05)-exposure[91:120]))\nxyplot(outcome ~ exposure, data=DF2)\n\n\n\n\nRich states are more likely to vote Democratic, but within each state, the chances that an individual votes Republican increases with their income.\n\n\n\nSource: Andrew Gelman, Boris Shor, Joseph Bafumi, David Park, “Rich state, poor state, red state, blue state: What’s the matter with Connecticut?” Popularized in the book Red State, Blue State, Rich State, Poor State: Why Americans Vote the Way They Do. Subsequent analysis in Avi Feller, Andrew Gelman, Boris Shor, “Red State/Blue State Divisions in the 2012 Presidential Election.” The Forum 2012; 10(4): 127–131. DOI 10.1515/forum-2013-0014. The text discusses indications that there is a cross-level bias, but often these relationships are found empirically and explanations come after the fact.\n\n\n12.1.2 Flaws of ecological studies\nEcological fallacy.\nGeographical units may not be the most logical division: e.g., metro areas, especially east of the Mississippi, may go across states: DC and NY metro areas both include 3 states. Some exposures are spatial. Spatial data analysis might be more useful than considering ecological units."
  },
  {
    "objectID": "chapt10.html#application-to-ecological-datasets",
    "href": "chapt10.html#application-to-ecological-datasets",
    "title": "12  Ecological studies",
    "section": "12.2 Application to ecological datasets",
    "text": "12.2 Application to ecological datasets\nThe Gapminder dataset has data from (up to) 195 countries that can be used to conduct an analysis using a ecological research design. The codebook is available on the course website and lists each variable and the number of countries that each variable is available for. Notice that some variables are only available for a small number of countries, so they are not good candidates for variables to use, unless you are okay having only 20 datapoints.\nLoad the mosaic library and the Gapminder dataset. Notice that the variable names in R are all small letters, but the codebook has capital letters in the variable names.\nYou can use the provided file or download yourself here: https://www.gapminder.org/data/\n\nlibrary(mosaic)\nG=read.csv(\"GapMinder.csv\", header=T)\n\nSay that we want to study whether per-capita GDP predicts all-cause child mortality (per 1000 births) before age 5.\n\nhistogram(~childdeathall2008, data=G)\n\n\n\n\n\nxyplot(childdeathall2008 ~ gdp2008, data=G)\n\n\n\n\nWe notice that childhood death is right-skewed, so we take the log before continuing so that we have a relationship that looks linear.\n\nG$log.childdeath=log(G$childdeathall2008)\nG$log.gdp=log(G$gdp2008)\nxyplot(log.childdeath ~ gdp2008, data=G, type=c(\"p\", \"r\"))\n\n\n\n\n\nxyplot(log.childdeath ~ log.gdp, data=G, type=c(\"p\", \"r\"))\n\n\n\n\nIt looks like we can justify doing a linear regression between these variables.\n\nmodel1=lm(log.childdeath ~ log.gdp, data=G)\nsummary(model1)\n\n\nCall:\nlm(formula = log.childdeath ~ log.gdp, data = G)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.86287 -0.42523 -0.04222  0.40722  3.05096 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  8.45197    0.27989   30.20   <2e-16 ***\nlog.gdp     -0.76157    0.03549  -21.46   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7007 on 158 degrees of freedom\n  (35 observations deleted due to missingness)\nMultiple R-squared:  0.7446,    Adjusted R-squared:  0.7429 \nF-statistic: 460.5 on 1 and 158 DF,  p-value: < 2.2e-16\n\ncbind(exp(coef(model1)), exp(confint(model1)))\n\n                               2.5 %       97.5 %\n(Intercept) 4684.2920504 2695.003473 8141.9531482\nlog.gdp        0.4669339    0.435326    0.5008368\n\n\n\n\n\n\n\n\n\nParameter\nInterpretation\n\n\n\n\nIntercept\nLog child death rate if log(GDP)=0\n\n\np-value for intercept\nIs intercept different from 0?\n\n\nlog.gdp coefficient\nChange in log child death rate if log(GDP) increases by one unit\n\n\np-value for log.gdp coef\nIs coefficient on log.gdp different from 0?\n\n\nR-squared\nPercentage of variation in log child death rate explained by log(GDP)\n\n\nF-statistic and p-value\nIs the overall model significant?\n\n\nI.e., does log(GDP) explain log child death rate?\n\n\n\n\nBecause we took the log of both the predictor and outcome variables, the interpretation of these coefficients are different than for regressions where we do not transform the variables.\nA $1 increase in per capita log(GDP) predicts 0.76 unit reduction in log child deaths: that is, if GDP increases by 1%, then child deaths decrease by 0.76%.\nNow we can think about other variables — are there any variables that may confound the relationship between per-capita GDP and childhood mortality, or is this model sufficient?"
  },
  {
    "objectID": "chapt10.html#exercise",
    "href": "chapt10.html#exercise",
    "title": "12  Ecological studies",
    "section": "12.3 Exercise",
    "text": "12.3 Exercise\nWork with a small group of classmates to analyze the Gapminder data. Download the Gapminder codebook from the course website on Dropbox. Load the data (and the mosaic package) using the above commands. Use the codebook to formuate a research question that you could answer with the Gapminder dataset is neither totally trivial/obvious nor totally arbitrary. The outcome variable should be a continuous variable rather than binary or categorical so that you can use linear regression tools.\n\nIdentify the research question, the outcome and predictor variables, and potential confounders.\nDo some basic plots with the outcome and predictor variables to explore the data.\nPerform a regression with one or more predictors.\nPrepare a 10 minute informal presentation to discuss your research question, your initial findings, and potential confounders. Make sure to address whether you were surprised by your findings or whether you just found what you expected."
  },
  {
    "objectID": "chapt11.html#summary-of-statistical-methods",
    "href": "chapt11.html#summary-of-statistical-methods",
    "title": "13  Example data analysis in YRBS",
    "section": "13.1 Summary of statistical methods",
    "text": "13.1 Summary of statistical methods\nRecall the table from chapter 1 for summarizing data from categorical (C) and quantitative (Q) variables. The types of analysis depend on the types of data.\nWe divide data into categorical (C) and quantitative (Q). The types of analysis depend on the types of data.\nCategorical variables can further be categorized as ordinal or non-ordinal.\n\n\n\nVariable type\nOutcome Quantitative\nOutcome Categorical\n\n\n\n\nPredictor quantitative\n\\(Q \\rightarrow Q\\)\n\\(Q \\rightarrow C\\)\n\n\nPredictor categorical\n\\(C \\rightarrow Q\\)\n\\(C \\rightarrow C\\)\n\n\n\nThe displays and analysis types are not meant to correspond to each other.\nThis table is not meant to be a cookbook. This table demonstrates that some types of analysis definitely do not make sense for some types of data. E.g., scatterplot cannot be used instead of 2x2 table.\n\n\n\n\n\n\n\n\nData\nDisplay\nAnalysis\n\n\n\n\n\\(Q \\rightarrow Q\\)\nscatterplots (xyplot)\nlinear regression (lm)\n\n\n\\(Q \\rightarrow C\\) or \\(C \\rightarrow Q\\)\nBox and whisker plot (bwplot)\n\n\n\n\ndotplot (w or w/o confidence interval)\n\n\n\nCategorical variable is binary\nstratified density plot (densityplot)\nt-test, Wilcoxon\n\n\nCategorical variable is binary\n\nLogistic regression glm( , family=binomial)\n\n\nCategorical variable is not binary\n\ntest for trend (if ordinal): e.g., Cuzick’s\n\n\nCategorical variable is not binary\n\nTukey’s HSD (anova followesd by TukeyHSD)\n\n\nCategorical variable is not binary\n\ntransform to binary and use above methods\n\n\n\\(C \\rightarrow C\\)\nContingency table (tally)\nchi-square test (chisq.test)\n\n\n\n\nKruskal-Wallis test (kruskal.test)\n\n\n\n\npairwise chi-square test"
  },
  {
    "objectID": "chapt11.html#logistic-regression",
    "href": "chapt11.html#logistic-regression",
    "title": "13  Example data analysis in YRBS",
    "section": "13.2 Logistic regression",
    "text": "13.2 Logistic regression\nThe regression type that you use is determined by your outcome variable, not by your predictors. Many outcome variables are binary/dichotomous: that is, they take only the values 0 or 1 (or FALSE and TRUE). You can model binary outcome variables with four different methods: logistic regression, Poisson regression, ordinary linear regression, and probit regression. Logistic regression is most commonly used in public health.\nThe coefficients in a logistic regression are log odds ratios; many statistical programs will transform them automatically for you. The predicted values from a logistic regression are the estimated probabilities of the event occurring.\n\n13.2.1 Variable selection and coding for data analysis\nThere are many guidelines for identifying covariates for data analysis. Here are some ideas: • Important demographic features: socioeconomic status, race/ethnicity, gender, age. These may be important to control for, even if non-significant. • Variables predicted to be potential confounders by relevant theories: e.g., health behavior theories often include a construct relevant to self-efficacy to carry out a health behavior. • Variables used as control variables in other papers can suggest both which theories are important and empirically which variables are important.\n\n\n13.2.2 Examples of logistic regression in YRBS\nWe start out by defining necessary variables. I rename everything so that I can read the output more easily. I also change factors to a scale that makes sense. For all varaibles, consult the codebook. Each variable is listed at least twice: first, to show the wording of the question and the answer choices followed by a dichotomized version (if applicable); second, to show the distribution of the variable (how many respondents gave each answer) and the coding (e.g., 1 = yes and 2 = no). For creating new variable:\n\n# Setting new variable to be true if old variable is 1 and 0 otherwise\nyrbs$newvariable=yrbs$oldvariable==1\n# check it did what you expected tally(newvariable ~ oldvariable, data=yrbs)\n\nLoad necessary libraries and data. We are using a new library here called arm because it displays regression analysis results compactly. Check data has expected number of variables (columns) and observations (rows).\nWe use the Stata format because it reliably keeps the labels.\n\nlibrary(readstata13)\nlibrary(mosaic)\nlibrary(arm)\nyrbs=read.dta13(\"yrbs2019.dta\")\ndim(yrbs)\n\n[1] 13677   235\n\n\nAge is originally on a scale from 1 to 7, but I express it as the actual age in years.\n\ntally(~Q1, data=yrbs)\n\nQ1\n12 years old or younger            13 years old            14 years old \n                     60                      27                    1699 \n           15 years old            16 years old            17 years old \n                   3473                    3628                    3102 \n  18 years old or older                    <NA> \n                   1616                      72 \n\nyrbs$age = as.numeric(yrbs$Q1)+11\ntally(Q1~age, data=yrbs)\n\n                         age\nQ1                          12   13   14   15   16   17   18 <NA>\n  12 years old or younger   60    0    0    0    0    0    0    0\n  13 years old               0   27    0    0    0    0    0    0\n  14 years old               0    0 1699    0    0    0    0    0\n  15 years old               0    0    0 3473    0    0    0    0\n  16 years old               0    0    0    0 3628    0    0    0\n  17 years old               0    0    0    0    0 3102    0    0\n  18 years old or older      0    0    0    0    0    0 1616    0\n  <NA>                       0    0    0    0    0    0    0   72\n\n\n\nyrbs$female= yrbs$Q2==\"Female\"\ntally(Q2~female, data=yrbs)\n\n        female\nQ2       TRUE FALSE <NA>\n  Female 6885     0    0\n  Male      0  6641    0\n  <NA>      0     0  151\n\n\n\n# Define race/ethnicity categories\nyrbs$black=yrbs$raceeth==\"black or african american\"\ntally(black ~ raceeth, data=yrbs)\n\n       raceeth\nblack   Am Indian/Alaska Native Asian Black or African American\n  TRUE                        0     0                         0\n  FALSE                     145   618                      2040\n  <NA>                        0     0                         0\n       raceeth\nblack   Native Hawaiian/Other PI White Hispanic / Latino Multiple - Hispanic\n  TRUE                         0     0                 0                   0\n  FALSE                       69  6668              1009                2029\n  <NA>                         0     0                 0                   0\n       raceeth\nblack   Multiple - Non-Hispanic <NA>\n  TRUE                        0    0\n  FALSE                     661    0\n  <NA>                        0  438\n\nyrbs$hispanic=(yrbs$raceeth==\"hispanic / latino\" | yrbs$raceeth==\"multiple - hispanic\")\ntally(hispanic ~ raceeth, data=yrbs)\n\n        raceeth\nhispanic Am Indian/Alaska Native Asian Black or African American\n   TRUE                        0     0                         0\n   FALSE                     145   618                      2040\n   <NA>                        0     0                         0\n        raceeth\nhispanic Native Hawaiian/Other PI White Hispanic / Latino Multiple - Hispanic\n   TRUE                         0     0                 0                   0\n   FALSE                       69  6668              1009                2029\n   <NA>                         0     0                 0                   0\n        raceeth\nhispanic Multiple - Non-Hispanic <NA>\n   TRUE                        0    0\n   FALSE                     661    0\n   <NA>                        0  438\n\nyrbs$white=yrbs$raceeth==\"white\"\nyrbs$asian=yrbs$raceeth==\"asian\"\nyrbs$multi.nonhispanic=yrbs$raceeth==\"multiple - non-hispanic\"\n\nGrade in school. Set grade to missing if grade is 13.\n\nyrbs$grade=as.numeric(yrbs$Q3)+8\nis.na(yrbs$grade)=yrbs$grade==13\ntally(~grade, data=yrbs)\n\ngrade\n   9   10   11   12 <NA> \n3637 3717 3322 2850  151 \n\n\n\nyrbs$age.for.grade=yrbs$age-yrbs$grade\ntally(~age.for.grade, data=yrbs)\n\nage.for.grade\n   0    1    2    3    4    5    6    7    8    9 <NA> \n   7   14   16   34   93 6269 6572  472   30    4  166 \n\nyrbs$appropriate.age.for.grade=yrbs$age.for.grade<=6\ntally(appropriate.age.for.grade ~age.for.grade, data=yrbs)\n\n                         age.for.grade\nappropriate.age.for.grade    0    1    2    3    4    5    6    7    8    9\n                    TRUE     7   14   16   34   93 6269 6572    0    0    0\n                    FALSE    0    0    0    0    0    0    0  472   30    4\n                    <NA>     0    0    0    0    0    0    0    0    0    0\n                         age.for.grade\nappropriate.age.for.grade <NA>\n                    TRUE     0\n                    FALSE    0\n                    <NA>   166\n\n\nWearing a seatbelt never/rarely\n\nyrbs$rarely.seatbelt=yrbs$QN8==1\ntally(rarely.seatbelt ~ Q8 , data=yrbs)\n\n               Q8\nrarely.seatbelt Never Rarely Sometimes Most of the time Always <NA>\n          TRUE    294    495         0                0      0    0\n          FALSE     0      0      1064             2999   6297    0\n          <NA>      0      0         0                0      0 2528\n\n\n\nyrbs$msm = (yrbs$Q65==\"Males\" & yrbs$female==0)\nyrbs$wsw = (yrbs$Q65==\"Females\" & yrbs$female==1)\nyrbs$same.sex.only= ( yrbs$msm | yrbs$wsw )\nyrbs$same.sex= ( yrbs$same.sex.only | yrbs$Q65==\"Females and males\")\ntally(same.sex ~ Q65, data=yrbs)\n\n        Q65\nsame.sex Never had sexual contact Females Males Females and males <NA>\n   TRUE                         0     193    99               543    0\n   FALSE                     4988    2642  2214                 0    0\n   <NA>                         0      30    17                 0 2951\n\n\n\nyrbs$glb=yrbs$Q66==\"Gay or lesbian\" | yrbs$Q66==\"Bisexual\"\ntally(glb ~ Q66, data=yrbs)\n\n       Q66\nglb     Heterosexual (straight) Gay or lesbian Bisexual Not sure  <NA>\n  TRUE                        0            380     1151        0     0\n  FALSE                   10853              0        0      591     0\n  <NA>                        0              0        0        0   702\n\n\nWe also think that sexual orientation could be related. Define variables for which sex respondents have had sex with (MSM = males who have sex with males, WSW = women who have sex with women), and their sexual orientation. Note that MSM/WSW variables are associated with the predictor of number of sexual partners, so it’s problematic to use them as covariates.\n\nyrbs$glbq=yrbs$Q66==\"Gay or lesbian\" | yrbs$Q66==\"Bisexual\" | yrbs$Q66==\"Not sure\"\ntally(glbq ~ Q66, data=yrbs)\n\n       Q66\nglbq    Heterosexual (straight) Gay or lesbian Bisexual Not sure  <NA>\n  TRUE                        0            380     1151      591     0\n  FALSE                   10853              0        0        0     0\n  <NA>                        0              0        0        0   702\n\n\n\nyrbs$any.sports.team=yrbs$QN82==1\ntally(any.sports.team ~ Q82, data=yrbs)\n\n               Q82\nany.sports.team 0 teams 1 team 2 teams 3 or more teams <NA>\n          TRUE        0   2584    1737            1224    0\n          FALSE    4242      0       0               0    0\n          <NA>        0      0       0               0 3890"
  },
  {
    "objectID": "chapt11.html#strength-training-and-sexual-partners",
    "href": "chapt11.html#strength-training-and-sexual-partners",
    "title": "13  Example data analysis in YRBS",
    "section": "13.3 Strength training and sexual partners",
    "text": "13.3 Strength training and sexual partners\nStrength training and number of sexual partners Our main predictor and outcome variables are number of sexual partners and days of strength training.\n\n13.3.1 Define variables\n\nyrbs$num.partners=as.numeric(yrbs$Q60) - 1\ntally(num.partners ~ Q60, data=yrbs)\n\n            Q60\nnum.partners Never had sex 1 person 2 people 3 people 4 people 5 people\n        0             7435        0        0        0        0        0\n        1                0     2043        0        0        0        0\n        2                0        0      926        0        0        0\n        3                0        0        0      563        0        0\n        4                0        0        0        0      294        0\n        5                0        0        0        0        0      197\n        6                0        0        0        0        0        0\n        <NA>             0        0        0        0        0        0\n            Q60\nnum.partners 6 or more people <NA>\n        0                   0    0\n        1                   0    0\n        2                   0    0\n        3                   0    0\n        4                   0    0\n        5                   0    0\n        6                 501    0\n        <NA>                0 1718\n\n\n\nyrbs$days.strength.training=as.numeric(yrbs$Q95) - 1\ntally(Q95~days.strength.training, data=yrbs)\n\n        days.strength.training\nQ95         0    1    2    3    4    5    6    7 <NA>\n  0 days 2568    0    0    0    0    0    0    0    0\n  1 day     0  812    0    0    0    0    0    0    0\n  2 days    0    0  973    0    0    0    0    0    0\n  3 days    0    0    0 1067    0    0    0    0    0\n  4 days    0    0    0    0  763    0    0    0    0\n  5 days    0    0    0    0    0  877    0    0    0\n  6 days    0    0    0    0    0    0  361    0    0\n  7 days    0    0    0    0    0    0    0 1053    0\n  <NA>      0    0    0    0    0    0    0    0 5203\n\nyrbs$any.strength.training=yrbs$days.strength.training >= 1\ntally(Q95~any.strength.training, data=yrbs)\n\n        any.strength.training\nQ95      TRUE FALSE <NA>\n  0 days    0  2568    0\n  1 day   812     0    0\n  2 days  973     0    0\n  3 days 1067     0    0\n  4 days  763     0    0\n  5 days  877     0    0\n  6 days  361     0    0\n  7 days 1053     0    0\n  <NA>      0     0 5203\n\n\n\n\n13.3.2 Crude odds ratio\nEvaluate whether strength training is associated with number of sexual partners. The first model estimates the crude odds ratio and its p-value. The second model estimates the adjusted odds ratio, adjusting for age, gender, and sports team participation.\n\nmodel0=glm(any.strength.training ~ num.partners, family=\"binomial\", data=yrbs)\ncbind(exp(coef(model0)), exp(confint(model0)))\n\nWaiting for profiling to be done...\n\n\n                         2.5 %   97.5 %\n(Intercept)  2.325748 2.197629 2.462291\nnum.partners 1.023808 0.991453 1.057742\n\n\n\n\n13.3.3 Adjusted odds ratio\n\nmodel1=glm(any.strength.training ~ num.partners + age + female + any.sports.team + any.sports.team*female + glb + glb*female , family=\"binomial\", data=yrbs)\ndisplay(model1, detail=T)\n\nglm(formula = any.strength.training ~ num.partners + age + female + \n    any.sports.team + any.sports.team * female + glb + glb * \n    female, family = \"binomial\", data = yrbs)\n                               coef.est coef.se z value Pr(>|z|)\n(Intercept)                     1.93     0.37    5.19    0.00   \nnum.partners                    0.03     0.02    1.72    0.08   \nage                            -0.09     0.02   -3.92    0.00   \nfemaleTRUE                     -0.40     0.08   -5.19    0.00   \nany.sports.teamTRUE             1.38     0.08   16.40    0.00   \nglbTRUE                        -0.62     0.16   -3.77    0.00   \nfemaleTRUE:any.sports.teamTRUE -0.38     0.11   -3.44    0.00   \nfemaleTRUE:glbTRUE              0.34     0.19    1.80    0.07   \n---\n  n = 7433, k = 8\n  residual deviance = 8312.0, null deviance = 9031.6 (difference = 719.6)\n\ncbind(exp(coef(model1)),exp(confint(model1)))\n\nWaiting for profiling to be done...\n\n\n                                             2.5 %     97.5 %\n(Intercept)                    6.9165709 3.3364304 14.3661158\nnum.partners                   1.0324601 0.9958725  1.0709013\nage                            0.9139132 0.8736332  0.9559790\nfemaleTRUE                     0.6683446 0.5738147  0.7780850\nany.sports.teamTRUE            3.9775010 3.3752060  4.6951738\nglbTRUE                        0.5400348 0.3925578  0.7459683\nfemaleTRUE:any.sports.teamTRUE 0.6859657 0.5531117  0.8501359\nfemaleTRUE:glbTRUE             1.4015063 0.9693141  2.0204604\n\n\nThe crude odds ratio and 95% confidence interval for the association between number of sexual partners and engaging in any strength training is 1.03 (1.01, 1.06), and the adjusted odds ratio is 1.04 (1.01, 1.07), adjusting for age, sex, sexual orientation, and sports team participation. We can regard the coefficients on these control variables as nuisance parameters. We can evaluate for effect modification by gender for both our main effect.\n\nmodel2=glm(any.strength.training ~ num.partners + age + female + any.sports.team + any.sports.team*female + glb + glb*female + num.partners*female, family=\"binomial\", data=yrbs)\ndisplay(model2, detail=T)\n\nglm(formula = any.strength.training ~ num.partners + age + female + \n    any.sports.team + any.sports.team * female + glb + glb * \n    female + num.partners * female, family = \"binomial\", data = yrbs)\n                               coef.est coef.se z value Pr(>|z|)\n(Intercept)                     1.82     0.37    4.85    0.00   \nnum.partners                    0.09     0.03    3.46    0.00   \nage                            -0.09     0.02   -3.73    0.00   \nfemaleTRUE                     -0.31     0.08   -3.67    0.00   \nany.sports.teamTRUE             1.37     0.08   16.29    0.00   \nglbTRUE                        -0.63     0.16   -3.85    0.00   \nfemaleTRUE:any.sports.teamTRUE -0.37     0.11   -3.40    0.00   \nfemaleTRUE:glbTRUE              0.37     0.19    1.99    0.05   \nnum.partners:femaleTRUE        -0.12     0.04   -3.29    0.00   \n---\n  n = 7433, k = 9\n  residual deviance = 8301.0, null deviance = 9031.6 (difference = 730.6)\n\ncbind(exp(coef(model2)),exp(confint(model2)))\n\nWaiting for profiling to be done...\n\n\n                                             2.5 %     97.5 %\n(Intercept)                    6.1572718 2.9583529 12.8375392\nnum.partners                   1.0971433 1.0417864  1.1573405\nage                            0.9175708 0.8770303  0.9599216\nfemaleTRUE                     0.7369965 0.6261359  0.8671537\nany.sports.teamTRUE            3.9458993 3.3478580  4.6585373\nglbTRUE                        0.5322496 0.3865827  0.7357501\nfemaleTRUE:any.sports.teamTRUE 0.6890158 0.5555495  0.8539527\nfemaleTRUE:glbTRUE             1.4537884 1.0042945  2.0984839\nnum.partners:femaleTRUE        0.8873172 0.8260548  0.9524688\n\n\nThere is much effect modification, so we may prefer to create separate models for males and females.\n\nmodel2f=glm(any.strength.training ~ num.partners + age\n+ any.sports.team + glb , family=\"binomial\", data=yrbs, subset=female==1)\ndisplay(model2f, detail=T)\n\nglm(formula = any.strength.training ~ num.partners + age + any.sports.team + \n    glb, family = \"binomial\", data = yrbs, subset = female == \n    1)\n                    coef.est coef.se z value Pr(>|z|)\n(Intercept)          1.52     0.49    3.12    0.00   \nnum.partners        -0.03     0.03   -1.02    0.31   \nage                 -0.09     0.03   -2.84    0.00   \nany.sports.teamTRUE  1.00     0.07   14.18    0.00   \nglbTRUE             -0.26     0.09   -2.80    0.01   \n---\n  n = 3839, k = 5\n  residual deviance = 4743.0, null deviance = 4998.2 (difference = 255.2)\n\ncbind(exp(coef(model2f)),exp(confint(model2f)))\n\nWaiting for profiling to be done...\n\n\n                                  2.5 %     97.5 %\n(Intercept)         4.5913847 1.7612809 11.9864705\nnum.partners        0.9737004 0.9254261  1.0248685\nage                 0.9168951 0.8635863  0.9734297\nany.sports.teamTRUE 2.7183719 2.3681710  3.1225726\nglbTRUE             0.7737496 0.6467414  0.9265395\n\nmodel2m=glm(any.strength.training ~ num.partners + age + any.sports.team + glb , family=\"binomial\", data=yrbs, subset=female==0)\ndisplay(model2m, detail=T)\n\nglm(formula = any.strength.training ~ num.partners + age + any.sports.team + \n    glb, family = \"binomial\", data = yrbs, subset = female == \n    0)\n                    coef.est coef.se z value Pr(>|z|)\n(Intercept)          1.80     0.57    3.18    0.00   \nnum.partners         0.09     0.03    3.40    0.00   \nage                 -0.09     0.04   -2.42    0.02   \nany.sports.teamTRUE  1.37     0.08   16.28    0.00   \nglbTRUE             -0.63     0.16   -3.85    0.00   \n---\n  n = 3594, k = 5\n  residual deviance = 3558.1, null deviance = 3896.5 (difference = 338.4)\n\ncbind(exp(coef(model2m)), exp(confint(model2m)))\n\nWaiting for profiling to be done...\n\n\n                                  2.5 %     97.5 %\n(Intercept)         6.0619916 2.0041506 18.4343083\nnum.partners        1.0969474 1.0407212  1.1581297\nage                 0.9184637 0.8573032  0.9837506\nany.sports.teamTRUE 3.9464675 3.3477291  4.6600102\nglbTRUE             0.5322545 0.3865890  0.7357508\n\nmodel1=glm(num.partners ~ days.strength.training + female + age + any.sports.team + glb, data=yrbs, family=poisson)\nsummary(model1)\n\n\nCall:\nglm(formula = num.partners ~ days.strength.training + female + \n    age + any.sports.team + glb, family = poisson, data = yrbs)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.5304  -1.2333  -0.9343   0.3355   5.7570  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)            -6.739015   0.180510 -37.333  < 2e-16 ***\ndays.strength.training  0.045405   0.005272   8.613  < 2e-16 ***\nfemaleTRUE             -0.201368   0.025778  -7.812 5.65e-15 ***\nage                     0.399385   0.010645  37.517  < 2e-16 ***\nany.sports.teamTRUE     0.075070   0.026434   2.840  0.00451 ** \nglbTRUE                 0.366196   0.036621  10.000  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 15862  on 7432  degrees of freedom\nResidual deviance: 14109  on 7427  degrees of freedom\n  (6244 observations deleted due to missingness)\nAIC: 21439\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n13.3.4 Example: asthma and smoking\nAsthma and smoking in the past month This analysis is based on a past student’s project, evaluating the association between asthma and smoking. The student wanted to evaluate whether males and females have different asso- ciations. They also thought that being older than the typical student in their grade may be a potential confounding factor. Here’s the start of an analysis.\nHas a doctor or nurse ever told you that you have asthma?\n\nyrbs$asthma=yrbs$Q87==\"Yes\"\ntally(asthma ~ Q87, data=yrbs)\n\n       Q87\nasthma   Yes   No Not sure <NA>\n  TRUE  2919    0        0    0\n  FALSE    0 9354      627    0\n  <NA>     0    0        0  777\n\nyrbs$pastmonth_smoking=yrbs$QN32==1\ntally(pastmonth_smoking ~ Q32, data=yrbs)\n\n                 Q32\npastmonth_smoking 0 days 1 or 2 days 3 to 5 days 6 to 9 days 10 to 19 days\n            TRUE       0         327         114          55            71\n            FALSE  11591           0           0           0             0\n            <NA>       0           0           0           0             0\n                 Q32\npastmonth_smoking 20 to 29 days All 30 days  <NA>\n            TRUE             28         131     0\n            FALSE             0           0     0\n            <NA>              0           0  1360\n\ntally(asthma ~ pastmonth_smoking, data=yrbs, useNA=\"no\", margins=T, format=\"percent\")\n\n       pastmonth_smoking\nasthma       TRUE     FALSE\n  TRUE   23.28358  22.23031\n  FALSE  76.71642  77.76969\n  Total 100.00000 100.00000\n\nchisq.test(tally(asthma ~ pastmonth_smoking, data=yrbs))\n\n\n    Pearson's Chi-squared test\n\ndata:  tally(asthma ~ pastmonth_smoking, data = yrbs)\nX-squared = 49.704, df = 4, p-value = 4.164e-10\n\n\n\nmodel1=glm(pastmonth_smoking ~ asthma, data=yrbs, family=binomial)\ndisplay(model1, detail=T)\n\nglm(formula = pastmonth_smoking ~ asthma, family = binomial, \n    data = yrbs)\n            coef.est coef.se z value Pr(>|z|)\n(Intercept)  -2.81     0.05  -61.91    0.00  \nasthmaTRUE    0.06     0.09    0.64    0.52  \n---\n  n = 11664, k = 2\n  residual deviance = 5128.7, null deviance = 5129.1 (difference = 0.4)\n\ncbind(exp(coef(model1)),exp(confint(model1)))\n\nWaiting for profiling to be done...\n\n\n                            2.5 %    97.5 %\n(Intercept) 0.06011696 0.05493165 0.0656376\nasthmaTRUE  1.06176008 0.88020795 1.2739006\n\nmodel2=glm(pastmonth_smoking ~ asthma  + female +age + appropriate.age.for.grade, data=yrbs, family=binomial)\ndisplay(model2, detail=T)\n\nglm(formula = pastmonth_smoking ~ asthma + female + age + appropriate.age.for.grade, \n    family = binomial, data = yrbs)\n                              coef.est coef.se z value Pr(>|z|)\n(Intercept)                    -6.48     0.62  -10.48    0.00  \nasthmaTRUE                      0.05     0.10    0.51    0.61  \nfemaleTRUE                     -0.36     0.08   -4.38    0.00  \nage                             0.26     0.03    7.56    0.00  \nappropriate.age.for.gradeTRUE  -0.43     0.18   -2.43    0.02  \n---\n  n = 11508, k = 5\n  residual deviance = 4852.6, null deviance = 4947.7 (difference = 95.1)\n\ncbind(exp(coef(model2)),exp(confint(model2)))\n\nWaiting for profiling to be done...\n\n\n                                                 2.5 %      97.5 %\n(Intercept)                   0.001526682 0.0004512483 0.005104352\nasthmaTRUE                    1.050394219 0.8656139433 1.267371207\nfemaleTRUE                    0.696714307 0.5922142934 0.818723249\nage                           1.298936427 1.2140637435 1.390404241\nappropriate.age.for.gradeTRUE 0.652620488 0.4678269198 0.933971235\n\n\n\nHow do you interpret the bivariate results? Which direction would you report?\nHow would you report and interpret the crude odds ratio?\nHow would you report and interpret the adjusted odds ratio?\nWhat information would you put into a table of the logistic regression results?\n\n\n\n13.3.5 Example: suicidal ideation and grades in school\n\nyrbs$suicidal.ideation=yrbs$Q26==\"Yes\"\ntally(suicidal.ideation ~ Q26, data=yrbs)\n\n                 Q26\nsuicidal.ideation   Yes    No  <NA>\n            TRUE   2633     0     0\n            FALSE     0 10804     0\n            <NA>      0     0   240\n\n\n\nyrbs$grades=yrbs$Q89\ntally(grades ~ Q89, data=yrbs)\n\n                      Q89\ngrades                 Mostly A's Mostly B's Mostly C's Mostly D's Mostly F's\n  Mostly A's                 5130          0          0          0          0\n  Mostly B's                    0       4655          0          0          0\n  Mostly C's                    0          0       2068          0          0\n  Mostly D's                    0          0          0        435          0\n  Mostly F's                    0          0          0          0        174\n  None of these grades          0          0          0          0          0\n  Not sure                      0          0          0          0          0\n  <NA>                          0          0          0          0          0\n                      Q89\ngrades                 None of these grades Not sure <NA>\n  Mostly A's                              0        0    0\n  Mostly B's                              0        0    0\n  Mostly C's                              0        0    0\n  Mostly D's                              0        0    0\n  Mostly F's                              0        0    0\n  None of these grades                  102        0    0\n  Not sure                                0      447    0\n  <NA>                                    0        0  666\n\n\nis.na(yrbs\\(grades) = yrbs\\)Q89==“None of these grades”\n\ntally(suicidal.ideation ~ grades, data=yrbs, format=\"percent\")\n\n                 grades\nsuicidal.ideation Mostly A's Mostly B's Mostly C's Mostly D's Mostly F's\n            TRUE   15.828460  20.107411  22.147002  30.344828  39.655172\n            FALSE  83.099415  78.625134  75.628627  65.057471  54.022989\n            <NA>    1.072125   1.267454   2.224371   4.597701   6.321839\n                 grades\nsuicidal.ideation None of these grades  Not sure      <NA>\n            TRUE             17.647059 23.042506 15.765766\n            FALSE            80.392157 72.483221 80.180180\n            <NA>              1.960784  4.474273  4.054054\n\nplot(tally(suicidal.ideation ~ grades, data=yrbs, format=\"percent\")[1,],\n        type=\"b\", ylab=\"Percent with suicidal ideation\", ylim=c(0,100),\n        axes=F, xlab=\"Grades in school\")\naxis(2)\naxis(1, at=1:8, labels=c(\"As\", \"Bs\", \"Cs\", \"Ds\", \"Fs\", \"None\", \"Unsure\", \"Missing\"))\n\n\n\n\n\nmodel1=glm(suicidal.ideation ~ grades, data=yrbs, family=binomial)\ndisplay(model1, detail=T)\n\nglm(formula = suicidal.ideation ~ grades, family = binomial, \n    data = yrbs)\n                           coef.est coef.se z value Pr(>|z|)\n(Intercept)                 -1.66     0.04  -43.31    0.00  \ngradesMostly B's             0.29     0.05    5.56    0.00  \ngradesMostly C's             0.43     0.07    6.57    0.00  \ngradesMostly D's             0.90     0.11    7.99    0.00  \ngradesMostly F's             1.35     0.16    8.27    0.00  \ngradesNone of these grades   0.14     0.26    0.54    0.59  \ngradesNot sure               0.51     0.12    4.29    0.00  \n---\n  n = 12798, k = 7\n  residual deviance = 12579.5, null deviance = 12720.2 (difference = 140.7)\n\ncbind(exp(coef(model1)),exp(confint(model1)))\n\nWaiting for profiling to be done...\n\n\n                                         2.5 %    97.5 %\n(Intercept)                0.1904762 0.1765901 0.2051917\ngradesMostly B's           1.3426230 1.2102757 1.4897116\ngradesMostly C's           1.5374041 1.3515868 1.7472525\ngradesMostly D's           2.4487633 1.9608995 3.0444650\ngradesMostly F's           3.8537234 2.7912908 5.2960478\ngradesNone of these grades 1.1524390 0.6674814 1.8838241\ngradesNot sure             1.6689815 1.3154428 2.1017143\n\n\n\nmodel2=glm(suicidal.ideation ~ grades + female + age+ appropriate.age.for.grade, data=yrbs, family=binomial)\ndisplay(model2, detail=T)\n\nglm(formula = suicidal.ideation ~ grades + female + age + appropriate.age.for.grade, \n    family = binomial, data = yrbs)\n                              coef.est coef.se z value Pr(>|z|)\n(Intercept)                   -1.84     0.35   -5.31    0.00   \ngradesMostly B's               0.37     0.05    6.77    0.00   \ngradesMostly C's               0.59     0.07    8.72    0.00   \ngradesMostly D's               1.12     0.12    9.60    0.00   \ngradesMostly F's               1.55     0.17    8.97    0.00   \ngradesNone of these grades     0.22     0.27    0.80    0.42   \ngradesNot sure                 0.61     0.12    4.91    0.00   \nfemaleTRUE                     0.82     0.05   17.07    0.00   \nage                           -0.02     0.02   -1.12    0.26   \nappropriate.age.for.gradeTRUE -0.02     0.12   -0.18    0.86   \n---\n  n = 12620, k = 10\n  residual deviance = 12037.4, null deviance = 12479.0 (difference = 441.5)\n\ncbind(exp(coef(model2)),exp(confint(model2)))\n\nWaiting for profiling to be done...\n\n\n                                             2.5 %    97.5 %\n(Intercept)                   0.1581005 0.07991345 0.3121621\ngradesMostly B's              1.4441552 1.29852010 1.6064646\ngradesMostly C's              1.8063832 1.58092905 2.0624705\ngradesMostly D's              3.0648026 2.43263882 3.8452151\ngradesMostly F's              4.7252419 3.35433489 6.6221255\ngradesNone of these grades    1.2456981 0.70576743 2.0777164\ngradesNot sure                1.8403320 1.43659949 2.3397027\nfemaleTRUE                    2.2726675 2.06895397 2.4981077\nage                           0.9789436 0.94324871 1.0159705\nappropriate.age.for.gradeTRUE 0.9779215 0.76959328 1.2544318\n\n\n\nHow do you report the bivariate results?\nHow would you report and interpret the crude odds ratio(s)?\nHow would you report and interpret the adjusted odds ratio(s)?\nWhat information would you put into a table of the logistic regression results?\n\nFor a visual data display (not necessary for the project), you can display the multivariate results visually as adjusted odds ratios with or without confidence intervals. Andrew Gelman calls the data display “the secret weapon.”\n\nplot(exp(coef(model2))[2:5], ylab=\"OR\", type=\"b\", axes=F, xlab=\"Grades\",\n        ylim=c(1, 6))\nabline(h=1, lty=2)\naxis(2)\naxis(1, at=1:4, labels=c(\"Mostly Bs\", \"Mostly Cs\", \"Mostly Ds\", \"Mostly Fs\"))\n\n\n\n\nTo show the confidence intervals, we need another library, and we put the confidence intervals into a new variable to save on computational time. It may be helpful context to tell the viewer how many participants are in each category. The symbol n tells R to insert a new line.\n\nlibrary(gplots)\nci=exp(confint(model2))\nplotCI(exp(coef(model2))[2:5], li=ci[2:5,1], ui=ci[2:5,2], ylab=\"OR\", type=\"b\",\n        axes=F, xlab=\"Grades\", ylim=c(1, 7), pch=20, gap=0)\nabline(h=1, lty=2)\naxis(2)\naxis(1, at=1:4, labels=c(\"Mostly Bs\\n(n=5660)\", \"Mostly Cs\\n(n=3031)\",\n\"Mostly Ds\\n(n=563)\", \"Mostly Fs\\n(n=245)\"), tick=F)\n\n\n\n\nHow do you interpret these findings? Is it more likely that poor grades cause suicidal ideation, that suicidal ideation causes poor grades, or that a third variable is responsible?"
  },
  {
    "objectID": "chapt12.html#survey-types",
    "href": "chapt12.html#survey-types",
    "title": "14  Survey data analysis",
    "section": "14.1 Survey types",
    "text": "14.1 Survey types\nSimple random survey: every unit in the population has an equal chance of being selected. When we analyze data without accounting for survey design, we treat data as if it were from a simple random sample.\nCluster random sample: units are selected within clusters (primary sampling units), such as schools. Because people within a cluster are more similar to each other than to people outside the cluster, failing to account for the primary sampling unit will result in standard deviations that are too small.\nStratified sample: the population is stratified before the sample is seleccted (strata), such as region of country (west, northeast, midwest, south).\nSimple random samples might be used in a case where the population of interest is small and there’s a well-defined dataframe. However, few surveys use simple random samples. Most surveys use all of the above techniques, so surveys come with 3 survey parameters (and sometimes 4). All major survey packages can use survey data."
  },
  {
    "objectID": "chapt12.html#weighting",
    "href": "chapt12.html#weighting",
    "title": "14  Survey data analysis",
    "section": "14.2 Weighting",
    "text": "14.2 Weighting\nUnequal probability of selection, such as for an oversample that chooses units from populations of interest are selected with greater probability in order to ensure sufficient power to understand these populations. (probability weights).\nPost-stratification weights: not everyone participates in the survey, and weights are estimated to account for the probability that people from each population of interest will participate. Also called non-response weights.\nStrata\nPrimary sampling unit (PSU)\nSurvey weights E.g., probability weights, poststratification weights.\nFinite population correction (FPC) Only used when the sample is large relative to the population\nPSUs and strata are linked to location, so to protect subjects’ privacy, sometimes replicate weights are used instead of PSU and strata. In this case, the PSU and strata are not available.\nTo analyze data from surveys, you start out by telling the statistical package which variables identify the strata, PSU, and weights. Then, you analyze the data with commands that are designed to use the survey parameters. Not all commands have been adapted for use with survey data, or they may use arcane syntax. For instance, often it’s easier to do a single-variable survey-weighted regression rather than a t-test; these yield the same answer.\nIn longitudinal dataset with several waves of data, multiple survey weights are available, and each estimate must use the appropriate survey weight.\nIn sum, analyzing survey data with the survey parameters makes estimates representative of the population and ensures that associations are not falsely significant.\nDatasets generally come with a document that tells how to analyze the data using survey weights and the other survey features. The document generally gives the exact commands for setting the survey parameters. We use the R survey package to analyze data from the Youth Risk Behavior Survey 20`9 We use the document produced by YRBS called “Software for Analysis of YRBS Data”.\nWe use the Stata format because it reliably keeps the labels.\n\nlibrary(readstata13)\nlibrary(mosaic)\nlibrary(arm)\nlibrary(survey)\nyrbs=read.dta13(\"yrbs2019.dta\")\ndim(yrbs)\n\n[1] 13677   235\n\n\nHere’s the example from the YRBS document. The I protects whatever is inside, so this example yields confidence intervals for frequency of each variable. The reason it’s necessary is because the YRBS data is coded 1 = yes and 2 = no. If it were coded 0 vs 1, you could just take the mean.\nSet the survey design\n\nyrbsdes <- svydesign(id=~psu, weight=~weight, strata=~stratum,data=yrbs, nest=T)\n\nStoring returned value in a variable\n\n(eversex <- svyciprop(~I(QN58==1), yrbsdes, na.rm=TRUE))\n\n                    2.5% 97.5%\nI(QN58 == 1) 0.384 0.354  0.42\n\n(heroin <- svyciprop(~I(QN52==1), yrbsdes, na.rm=TRUE))\n\n                      2.5% 97.5%\nI(QN52 == 1) 0.0177 0.0125  0.02\n\n\nNow let’s analyze the data from the Epi 5201 fall 2018 final exam. Evaluate the association between water consumption and BMI. I defined a binary variable for water drinking: the variable water3 is coded as 1 for those who drank at least 3 glasses of water per day and 0 for those who drank less than 3 glasses of water per day.\nIn the R survey package, when new variables are added, you need to explicitly add the variable to the survey design object. You can do this with the update or transform function. You do not need to use both, only one of these.\nThis procedure is a bit cumbersome, but it’s a consequence of R’s capability to have more than one dataframe in memory at a time. A package such as Stata that can only have one dataset in memory at a time.\n\nsummary(svyglm(bmipct ~ Q93, yrbsdes, family=\"gaussian\"))\n\n\nCall:\nsvyglm(formula = bmipct ~ Q93, design = yrbsdes, family = \"gaussian\")\n\nSurvey design:\nsvydesign(id = ~psu, weight = ~weight, strata = ~stratum, data = yrbs, \n    nest = T)\n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 64.6984     2.0817  31.080   <2e-16 ***\nQ931 to 3 times             -1.9263     2.7900  -0.690   0.4958    \nQ934 to 6 times             -0.3804     2.6769  -0.142   0.8880    \nQ931 time per day           -4.8332     2.8076  -1.721   0.0966 .  \nQ932 times per day          -4.4633     2.4652  -1.811   0.0814 .  \nQ933 times per day          -1.1793     2.3750  -0.497   0.6235    \nQ934 or more times per day   0.8222     2.3210   0.354   0.7259    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 929.5689)\n\nNumber of Fisher Scoring iterations: 2\n\nyrbsdes=update(yrbsdes, water3=qnwater3==1)\nyrbsdes=transform(yrbsdes, water3=qnwater3==1)\nsummary(svyglm(bmipct ~ 0+water3, yrbsdes, family=\"gaussian\"))\n\n\nCall:\nsvyglm(formula = bmipct ~ 0 + water3, design = yrbsdes, family = \"gaussian\")\n\nSurvey design:\nupdate(`_data`, ...)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \nwater3FALSE  61.9491     0.8839   70.09   <2e-16 ***\nwater3TRUE   64.8666     1.0337   62.75   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 931.9661)\n\nNumber of Fisher Scoring iterations: 2\n\n\nAlternatively, you can add the new variable to your dataframe and then define the survey design object again. I defined the following variables: age was defined as the number of years over age 11 (12 years old is 1, 13 years old is 2, etc.); male gender was 1 for males and 0 for females. Juice, soda, milk, and sports drink were ordered categorical variables with the same categories as water: none, 1-3 times per week, 4-6 times per week, 1 time per day, 2 times per day, 3 times per day, and 4+ times per day. I defined a variable for obese status and evaluated whether obesity was associated with water consumption. Obesity was coded as 1 for adolescents with a BMI percentile over 95, which is considered obese, and 0 for adolescents with BMI percentile under 95.\nIf you are defining lots of variables, it’s more efficient to define them and then define the survey design object again. Note that we need to repeat the water3 variable definition because we didn’t do that one inside the yrbs dataset yet, only directly in the survey object.\n\nyrbs$water3=yrbs$qnwater3==1\n    yrbs$age = as.numeric(yrbs$Q1)\n    yrbs$male = yrbs$Q2==\"Male\"\n    yrbs$sportsdrink=as.numeric(yrbs$Q92)\n    yrbs$soda = as.numeric(yrbs$Q75)\n    yrbs$milk = as.numeric(yrbs$Q76)\n    yrbs$juice=as.numeric(yrbs$Q69)\n    yrbs$obese=yrbs$qnobese==1\n    \n    yrbsdes = svydesign(id=~psu, weight=~weight, strata=~stratum,data=yrbs, nest=TRUE)\n\nI conducted an analysis to predict BMI percentile from whether the respondent reported drinking water at least 3 times per day, adjusting for age; gender; and sports drink, soda, and milk consumption. Interpret the coefficient on water in a sentence: both the coefficient and its significance. Does this result suggest that drinking water at least 3 times per day could lead to weight gain? Explain your answer.\n\nmodel1 = svyglm (bmipct ~ water3 + age + male + sportsdrink\n+ soda+ milk + juice, yrbsdes)\nsummary(model1, detail=T)\n\n\nCall:\nsvyglm(formula = bmipct ~ water3 + age + male + sportsdrink + \n    soda + milk + juice, design = yrbsdes)\n\nSurvey design:\nsvydesign(id = ~psu, weight = ~weight, strata = ~stratum, data = yrbs, \n    nest = TRUE)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  65.4373     2.6686  24.521  < 2e-16 ***\nwater3TRUE    3.0491     0.8991   3.391  0.00241 ** \nage          -1.0789     0.3323  -3.247  0.00343 ** \nmaleTRUE      0.4771     1.1225   0.425  0.67463    \nsportsdrink   0.4693     0.3295   1.425  0.16717    \nsoda          0.2725     0.3271   0.833  0.41291    \nmilk          0.3044     0.2874   1.059  0.30019    \njuice        -0.1647     0.3298  -0.499  0.62203    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 1022.418)\n\nNumber of Fisher Scoring iterations: 2\n\n\nLet’s calculate the associations in both directions and the statistical significance of the associations. Interpret the relevant percentages in both 2x2 tables to evaluate the associations between obesity and water consumption. We specify the total to be 100 because otherwise the weights make it add up. The sum of the 4 cells is 100%, so the entries are cell percentages. It takes some experimentation to figure out how to get what you want.\n\nsvytable(~obese + water3, design=yrbsdes, Ntotal=100)\n\n       water3\nobese       FALSE      TRUE\n  FALSE 37.676869 46.696134\n  TRUE   6.769012  8.857985\n\nsummary(svytable(~ water3 + obese, design=yrbsdes))\n\n       obese\nwater3  FALSE TRUE\n  FALSE  3797  682\n  TRUE   4707  893\n\n    Pearson's X^2: Rao & Scott adjustment\n\ndata:  svychisq(~water3 + obese, design = yrbsdes, statistic = \"F\")\nF = 0.25264, ndf = 1, ddf = 37, p-value = 0.6182\n\nsvyby(~obese, ~water3, design=yrbsdes, svymean, na.rm=T)\n\n      water3 obeseFALSE obeseTRUE se.obeseFALSE se.obeseTRUE\nFALSE  FALSE  0.8477021 0.1522979    0.01150558   0.01150558\nTRUE    TRUE  0.8405522 0.1594478    0.01287206   0.01287206\n\n\n57% of adolescents with obesity drink water at least 3 times per day compared with 50% of adolescents without obesity, which is statistically significant with p < 0.001. Among those who drink water at least 3 times per day, 16% are obese, versus 13% of those who drink water less than 3 times per day, which is statistically significant with p < 0.001. Based on the above analysis, I evaluated whether adolescents with obesity are more likely to drink water at least 3 times per day, controlling for the same variables. What does this model suggest about the relationship between obesity and drinking water at least 3 times a day?\n\nmodel2 =svyglm (water3 ~ obese  + age + male + sportsdrink\n+ soda+ milk + juice, design=yrbsdes, family=binomial)\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nsummary(model2)\n\n\nCall:\nsvyglm(formula = water3 ~ obese + age + male + sportsdrink + \n    soda + milk + juice, design = yrbsdes, family = binomial)\n\nSurvey design:\nsvydesign(id = ~psu, weight = ~weight, strata = ~stratum, data = yrbs, \n    nest = TRUE)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.16636    0.20591   0.808  0.42706    \nobeseTRUE    0.08034    0.10833   0.742  0.46549    \nage          0.02742    0.02935   0.934  0.35938    \nmaleTRUE    -0.07214    0.07554  -0.955  0.34909    \nsportsdrink  0.06991    0.02378   2.940  0.00716 ** \nsoda        -0.25789    0.02189 -11.783 1.82e-11 ***\nmilk         0.08763    0.02478   3.537  0.00168 ** \njuice        0.07316    0.02191   3.339  0.00274 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1.230958)\n\nNumber of Fisher Scoring iterations: 4\n\ncbind(exp(coef(model2)), exp(confint(model2)))\n\n                          2.5 %    97.5 %\n(Intercept) 1.1809985 0.7721260 1.8063858\nobeseTRUE   1.0836588 0.8665506 1.3551620\nage         1.0278036 0.9673959 1.0919834\nmaleTRUE    0.9303978 0.7960836 1.0873733\nsportsdrink 1.0724135 1.0210448 1.1263665\nsoda        0.7726791 0.7385517 0.8083834\nmilk        1.0915851 1.0371656 1.1488601\njuice       1.0759018 1.0283301 1.1256742\n\n\nAdolescents with obesity have 40% greater odds of drinking water at least 3 times per day than adolescents without obesity, controlling for age, gender, and other fluid consumption (OR=1.40, 95% CI (1.19, 1.64))."
  },
  {
    "objectID": "chapt12.html#in-class-exercises",
    "href": "chapt12.html#in-class-exercises",
    "title": "14  Survey data analysis",
    "section": "14.3 In class exercises",
    "text": "14.3 In class exercises\n\nUse the Youth Risk Behavior Study (YRBS) and codebook on the course website to do the following analyses:\n\n\n\nRead in the data.\nDefine the survey design. (See page 49 of the codebook.) Note that you may have to do this again if you define more variables within the YRBS dataframe.\nLook at the variable for whether a student carried a gun to school at least once in the past 30 days. If the variable is not suitable for analysis, add a variable to the YRBS dataframe for whether a student carried a gun to school at least once in the past 30 days and look at the summary to make sure that you defined it properly. (table or tally command)\nDo the same thing for whether a student missed school at least once in the past 30 days because they felt unsafe.\nIf you defined new variables, define the survey design (again — you need it to include any new variables.)\nSummarize the gun variable as mean and standard deviation, without accounting for survey characteristics. Summarize the gun variable as mean and standard deviation, accounting for survey characteristics. Describe the differences between the survey- adjusted and unadjusted.\nPredict whether someone who missed school due to feeling unsafe is more likely to carry a gun with and without accounting for survey characteristics. Interpret each finding. Describe the differences between the survey-adjusted and unadjusted.\nUsing the codebook, add potential confounders to your model. Is the association still significant?\n\n\n14.3.1 Suggested answers\nCarry gun at least once in past 30 days\n\nyrbs$gun30d=yrbs$QN12==1\ntally(gun30d~Q12, data=yrbs)\n\n       Q12\ngun30d  0 days 1 day 2 or 3 days 4 or 5 days 6 or more days <NA>\n  TRUE       0   310         356         148            589    0\n  FALSE   9141     0           0           0              0    0\n  <NA>       0     0           0           0              0 3133\n\n\nMissed school at least once in 30 days because felt unsafe Not go to school because felt unsafe\n\nyrbs$unsafe.missed.school30d=yrbs$QN15==1\ntally(unsafe.missed.school30d~Q15, data=yrbs)\n\n                       Q15\nunsafe.missed.school30d 0 days 1 day 2 or 3 days 4 or 5 days 6 or more days\n                  TRUE       0   615         402         102            151\n                  FALSE  12331     0           0           0              0\n                  <NA>       0     0           0           0              0\n                       Q15\nunsafe.missed.school30d  <NA>\n                  TRUE      0\n                  FALSE     0\n                  <NA>     76\n\n\n\nyrbs.design =svydesign(id=~psu, strata=~stratum, weights=~weight, data=yrbs)\n\n\nsvymean(~gun30d, yrbs.design, na.rm=T)\n\n               mean     SE\ngun30dFALSE 0.86841 0.0065\ngun30dTRUE  0.13159 0.0065\n\nmean(yrbs$gun30d, na.rm=T)\n\n[1] 0.1330615\n\nsd(yrbs$gun30d, na.rm=T)/sqrt(length(yrbs$gun30d))\n\n[1] 0.002904327\n\nsummary(svyglm(gun30d~unsafe.missed.school30d, yrbs.design, family=binomial(link=\"logit\")))\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n\nCall:\nsvyglm(formula = gun30d ~ unsafe.missed.school30d, design = yrbs.design, \n    family = binomial(link = \"logit\"))\n\nSurvey design:\nsvydesign(id = ~psu, strata = ~stratum, weights = ~weight, data = yrbs)\n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 -1.95515    0.05942 -32.906  < 2e-16 ***\nunsafe.missed.school30dTRUE  0.66206    0.14748   4.489 8.71e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1.119776)\n\nNumber of Fisher Scoring iterations: 4\n\nsummary(glm(gun30d~unsafe.missed.school30d, data=yrbs, family=binomial(link=\"logit\")))\n\n\nCall:\nglm(formula = gun30d ~ unsafe.missed.school30d, family = binomial(link = \"logit\"), \n    data = yrbs)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.7421  -0.5107  -0.5107  -0.5107   2.0502  \n\nCoefficients:\n                            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                 -1.97133    0.03119 -63.201   <2e-16 ***\nunsafe.missed.school30dTRUE  0.82260    0.08231   9.994   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 8245.0  on 10521  degrees of freedom\nResidual deviance: 8155.7  on 10520  degrees of freedom\n  (3155 observations deleted due to missingness)\nAIC: 8159.7\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "chapt13.html#rakai-study",
    "href": "chapt13.html#rakai-study",
    "title": "15  Randomized experiments and quasi-experiments",
    "section": "15.1 Rakai study",
    "text": "15.1 Rakai study\nTo evaluate whether circumcision decreases HIV incidence, researchers in Rakai Uganda randomly assigned 5000 HIV-negative men ages 15–49 to be circumcised within 2 weeks of enrollment or to wait 24 months for circumcision. Gray RH, et al. Male circumcision for HIV prevention in men in Rakai, Uganda: a randomised trial. Lancet, Feb 24, 2007. Men with contraindications for circumcision were treated for the contraindications and enrolled after treatment if the con- tradindications resolved. Men with anatomical abnormalities were excluded from trial and referred to urologist for treatment, whch may have included circumcision. Both treatment and control participants received identical compensation: $5 at each screening/enrollment, surgery, and post-surgery visit, and $3 at each of 3 follow-up visits (total compensation $21.)\nParticipants were randomized using blocks of 20 envelopes that were given to their com- munity, and participants chose one of the 20 envelopes to yield their treatment assignment. Once an envelope was chosen, it was replaced by another envelope from the next block. This randomization method ensured that all communities were balanced in treatment and control assignment status. Here are the demographics of treatment and control groups at baseline. Did randomization succeed in balancing the treatment and control groups?\n\n\n\n\n\n\n\n\n\n\n\nTreatment (n=2474)\nControl (n=2522)\n\n\n\n\nAge (years)\n15-19\n679 (27%)\n719 (29%)\n\n\n\n20-24\n686 (28%)\n686 (27%)\n\n\n\n25-29\n440 (18%)\n473 (19%)\n\n\n\n30-49\n669 (27%)\n643 (25%)\n\n\nMarital status\nNever\n1161 (47%)\n1222 (48%)\n\n\n\nCurrently\n1167 (47%)\n1173 (47%)\n\n\n\nPreviously\n146 (6%)\n127 (5%)\n\n\nReligion\nCatholic\n1649 (67%)\n1730 (69%)\n\n\n\nProtestant\n667 (27%)\n629 (25%)\n\n\n\nSaved/Pentecostal\n141 (6%)\n146 (6%)\n\n\n\nMuslim\n17 (0.7%)\n17 (0.7%)\n\n\nEducation\nNone\n141 (6%)\n147 (6%)\n\n\n\nPrimary\n1631 (66%)\n1669 (66%)\n\n\n\nSecondary\n603 (24%)\n589 (23%)\n\n\n\nPost-secondary\n99 (4%)\n116 (5%)\n\n\nPast year sexual partners\n0\n468 (19%)\n494 (20%)\n\n\n\n1\n1152 (47%)\n1168 (46%)\n\n\n\n2\n545 (22%)\n586 (23%)\n\n\n\n3+\n309 (12%)\n274 (11%)\n\n\nPast year non-marital partners\nNo\n1220 (49%)\n1238 (49%)\n\n\n\nYes\n1254 (51%)\n1284 (51%)\n\n\nPast year condom use\nNone\n978 (40%)\n941 (37%)\n\n\n\nInconsistent\n689 (28%)\n732 (29%)\n\n\n\nConsistent\n339 (14%)\n355 (14%)\n\n\nAlcohol use with sex\npast 6m\n938 (38%)\n966 (38%)\n\n\nSex for money/gifts\nany\n38 (2%)\n36 (1%)\n\n\nPrior voluntary counselling/testing\nany\n648 (26%)\n574 (23%)\n\n\nSelf-reported STI symptoms\nGenital ulcer disease\n179 (7%)\n176 (7%)\n\n\n\nUrethral discharge\n85 (3%)\n94 (4%)\n\n\n\nDysuria\n138 (6%)\n162 (6%)\n\n\n\nParticipants were tested for HIV at 6 month intervals during the trial. All HIV-positive screenees and participants were treated for HIV using Pepfar funds (Pres. George W Bush’s Presidential Emergency Fund for AIDS Relief). Here are the results:\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nControl\nIRR (95% CI)\np-value\n\n\n\n\n0–6 mos\nNo. participants\n2263\n2319\n\n\n\n\nIncident HIV infections\n14\n19\n\n\n\n\nPerson-years\n1172\n1207\n\n\n\n\nIncidence per 100 p-y\n1.19\n1.58\n0.76 (0.35, 1.60)\n\n\n6–12 mos\nNo. participants\n2235\n2229\n\n\n\n\nIncident HIV infections\n5\n14\n\n\n\n\nPerson-years\n1191\n1176\n\n\n\n\nIncidence per 100 p-y\n0.42\n1.19\n0.35 (0.10, 1.04)\n\n\n12–24 mos\nNo. participants\n964\n980\n\n\n\n\nIncident HIV infections\n3\n12\n\n\n\n\nPerson-years\n990\n1009\n\n\n\n\nIncidence per 100 p-y\n0.30\n1.19\n0.25 (0.05, 0.94)\n\n\nTotal 0–24 mos\nNo. participants\n2387\n2430\n\n\n\n\nIncident HIV infections\n22\n45\n\n\n\n\nPerson-years\n3352\n3392\n\n\n\n\nIncidence per 100 p-y\n0.66\n1.33\n0.49 (0.28, 0.84)\n\n\n\nThe researchers also estimated incidence rate ratios within each of the baseline factors. The IRR was signficicant at the 0.05 level with those with no or primary education, 2+ sexual partners, non-marital sex partners, inconsistent condom use (but not no condom use), those who did not use alcohol with sex, both those who engaged and did not engage in transactional sex, those w/o uretrhral discharge, and those w/o dysuria."
  },
  {
    "objectID": "chapt13.html#social-experiments",
    "href": "chapt13.html#social-experiments",
    "title": "15  Randomized experiments and quasi-experiments",
    "section": "15.2 Social experiments",
    "text": "15.2 Social experiments\n\n15.2.1 First social experiment: New Jersey Income Maintenance Experiment\nTested guaranteed minimum income (negative income tax) in 1967: 1375 families in 4 NJ cities (Paterson, Jersey City, Trenton, and Passaic) with the addition of Scranton, PA to increase the representation of white families.\n\n\n15.2.2 RAND Health Insurance Experiment\nRAND Health Insurance Experiment (RAND HIE, 1974–82): 7700 participants in 6 sites in the US assigned to 0% (free), 25%, 50%, and 95% coinsurance, and non-profit HMO with no coinsurance. Out of pocket expenditure capped as percentage of income (5, 10, 15%) or equivalent of $3800 today, whichever was lower. Cost-sharing and HMO predicted lower chance of initiating treatment than with no coinsurance. (Joseph P. Newhouse and the Insurance Experiment Group. Free for All? Lessons from the RAND Health Experiment. Cambridge, Mass.: Harvard University Press, 1993. Also http://www.rand.org/pubs/research briefs/RB9174/index1.html)\n\n\n15.2.3 Seguro Popular de Salud: the Mexican universal health care system\nThe Mexican government implemented their 2005 universal health care system such that it could be tested with randomized experiment: 7100 health clusters (health facility cachement areas) in 13 states were identified, and researchers identified 74 matched pairs of clusters that included 119,000 households.\nKing, Gary, Gakidou, Emmanuela, Imai, Kosuke, et al. 2009. Public Policy for the Poor? A Randomised Assessment of the Mexican Universal Health Insurance Programme. The Lancet 373: 1447-1454. Copy at http://j.mp/lgZF4R, King, Gary, et al. 2007. A “Politically Robust” Experimental Design for Public Policy Evaluation, with Application to the Mexican Universal Health Insurance Program. Journal of Policy Analysis and Management 26: 479-506. Copy at http://j.mp/lXnta2\n\n\n15.2.4 Oregon Health Study\nOregon closed its Medicaid rolls in 2004 due to lack of funding, but it was later able to extend Medicaid, so held a lottery in 2008.\n\n\n\nStage\nNumber\n\n\n\n\nSigned up for lottery\n89,824\n\n\nChosen in lottery\n30,000\n\n\nSubmitted applications\n18,300\n\n\nAccepted and enrolled in Medicaid\n8704\n\n\n\nQuestion: What should the treatment group be? The 30,000 people given applications, the people who submitted the application, or the 8704 who actually enrolled in Medicaid? K Baicker et al, The Oregon Experiment — Effects of Medicaid on Clinical Outcomes. N Engl J Med 2013; 368:1713–1722.\n\n\n15.2.5 Moving to Opportunity\nLow-poverty area vouchers and assistance (n=1788) Housing vouchers alone (n=1312) Control group (n=1398)\nFindings: - Children who moved to low-poverty neighborhoods had better mental and physical health than either control group. (Soc Sci Med. 2011 Sep;73(5):737-43.).\n\n10 years later, obesity and diabetes were less common among the parents who moved to the low-poverty neighborhoods. (N Engl J Med. 2011 Oct 20;365(16):1509-19.)\n10–15 years later, subjective well-being was higher among families who moved to the low-poverty neighborhoods (Science. 2012 Sep 21;337(6101):1505-10.)\nChildren who moved to low-poverty neighborhoods had less exposure to danger, especially girls (Soc Sci Res. 2012 Jul;41(4):788-801.)\nSeveral studies found better outcomes for girls and worse outcomes for boys. One study found both boys and girls who moved to low-poverty neighborhoods had lower grades and school engagement after 5 years (Dev Psychol. 2005 Nov;41(6):933-52). J Ludwig et al, Neighborhoods, Obesity, and Diabetes — A Randomized Social Experiment, N Engl J Med. 2011 Oct 20;365(16):1509–19.\n\n\n\n15.2.6 Post-diction and coincidences\nRCTs need to establish their hypotheses before they are tested, or else they engage in “post- diction” and could be finding significant findings due to multiple comparisons. Postdiction is the scientific equivalent of coincidences. Many coincidences that seem im- probable are not that improbable. My first two boyfriends had birthdays within 2 days of each other, in different years, which sounds unlikely, but the probability of that event (two people having birthdays within 2 days of each other) is 5/365, or about 1.4%. It’s unlikely but not that unlikely. See Radio Lab and This American Life for coincidence stories. My favorite: a person asks his friend to email him a picture, and she sends a picture of herself as a 4 year old child at a tourist attraction; he notices his grandmother in the background of the photo. Another: an engaged couple discovers that her mother had been engaged to his deceased father in Korea. https://www.thisamericanlife.org/radio-archives/episode/489/transcript\n\n\n15.2.7 False significance due to multiple comparisons\nIllustrated by this comic: https://xkcd.com/882/\n\n\n15.2.8 Publication bias\nRCTs are the best way to learn about cause and effect, but does studying the published liter- ature of RCTs teach you whether a RCT works? E. J. Masicampoa & Daniel R. Lalande, A peculiar prevalence of p values just below .05, The Quarterly Journal of Experimental Psychology, Volume 65, Issue 11, 2012. (Histogram from http://normaldeviate.wordpress.com)\nThe International Committee of Medical Journal Editors and FDA required all clinical trials to be registered beforehand, to ensure that even negative results would be known. To reduce publication bias, clinical trial registries were developed to require all clinical trials to register prior to their starts, and to report all results within a year. Prayle, Hurley, Smyth, Compliance with mandatory reporting of clinical trial results on ClinicalTrials.gov: cross sectional study, BMJ 2012; 344\n(Source: BMJ 2012;344:d7373) A more recent study found trial registration increased with time, but was still below 50%. Anderson ML, Chiswell K, Peterson ED, Tasneem A, Topping J, Califf RM. Compliance with results reporting at ClinicalTrials.gov.N Engl J Med. 2015 Mar 12;372(11):1031-9. doi: 10.1056/NEJMsa1409364.\n\n\n15.2.9 A study designed to be misleading: Chocolate for dieting RCT\nA paper with the following abstract was published in the International Archives of Medicine and featured in the popular press (see the attached xerox from Shape magazine, June 2015: “Why you must eat Chocolate Daily.”) The full study is available here: http://www.scribd.com/doc/266969860/Chocolate-causes-weight-loss\nThe study was a real study, but it was designed to be intentionally biased away from the null. http://io9.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800 What clues can you find that the study is biased away from the null?"
  },
  {
    "objectID": "chapt13.html#quasi-experimental-designs",
    "href": "chapt13.html#quasi-experimental-designs",
    "title": "15  Randomized experiments and quasi-experiments",
    "section": "15.3 Quasi experimental designs",
    "text": "15.3 Quasi experimental designs\n\n15.3.1 Instrumental variables\n\n\n15.3.2 Regression discontinuity\nRegression discontinuity studies can evaluate programs where eligibility is determined by a cut-off value: people below the cut-off value do not qualify, and people above the cut-off value qualify. They compare people who are just below the cut-off value with those just above because cut-off points can be arbitrary. The following image3 shows four different outcomes of a regression discontinuity study where the outcome is continuous: (a) linear relationship with no treatment effect; (b) linear regression with treatment effect; (c) curvilinear relationship with no treatment effect; (d) linear relationship with treatment effect between 3 conditions. Ariel Linden, John L. Adams, Nancy Roberts. Evaluating disease management programme effectiveness: an introduction to the regression discontinuity design. Journal of Evaluation in Clinical Practice. 2006;12(2):124– 131.\nSimilar analyses could be done with regression discontinuity design with dichotomous outcome. Regression discontinuity designs avoid the following threats to internal validity that are often present in observational studies: selection bias, maturation, and regression to the mean. Explain why these threats to internal validity would apply in many observational studies. Would they apply in a regression discontinuity design?\nRegression to the mean: see this illustration of health care costs for two consecutive years for continuously insured patients: coronary artery disease (CAD), congestive heart failure (CHF), and chronic obstructive pulmonary disease (COPD). Costs are quintiles numbered I (lowest cost) to V (highest cost).\n\n15.3.2.1 Example: Disease management programs\nDisease management programs target individuals with health problems that can be dangerous and costly if uncontrolled, and give them additional counseling: e.g., pregnant women at risk for birth complications, people with diabetes and hypertension. Frequently, disease management programs are evaluated with a pre-post design with no control groups: researchers compare costs before versus after the disease management program was implemented. Disease management programs are often designed to admit people according to their results on medical test(s) with continuous or ordinal results — HbA1c or blood glucose (diabetes), blood pressure, cholesterol/lipids (coronary heart disease), ejection fraction (congestive heart failure), peak flow or forced expiratory volume (asthma) — so they are appropriate for regression discontinuity design evaluations.4 4Ariel Linden, John L. Adams, Nancy Roberts. Evaluating disease management programme effectiveness: an introduction to the regression discontinuity design. Journal of Evaluation in Clinical Practice. 2006;12(2):124– 131.\n\n\n15.3.2.2 Example: Medicaid expansion\nThe State Children’s Health Insurance Program expanded Medicaid to cover many more chil- dren. Researchers used regression discontinuity study by birthdate to evaluate later life health problems. Laura R Wherry, Sarah Miller, Robert Kaestner, Bruce D Meyer, Childhood Medicaid Coverage and Later Life Health Care Utilization. NBER Working Paper No. 20929 Issued in February 2015, Revised in October 2015. http://www.nber.org/papers/w20929 Many more Black children became eligible for SCHIP after the implementation:\nWhat do you notice about Medicaid receipt in 1992–96 and hospitalizations and hospital costs in 2009? (Caption: “Authors’ calculations from the National Health Interview Survey, 1992–1996. Cohorts born in 1983 are between the ages of 8 and 13 in these figures. The trend is estimated using children between the ages of 4 and 17.”)\n\n\n15.3.2.3 Example: Abortion gestational age limits\nFirst trimester abortion: n=273\nLess than 2 weeks within the limit (eligible for abortion): n=452\nNo abortion: more than 3 w post-limit n=231\nAt baseline, women who got abortions were equally likely to receive public assistance as women denied abortions (45%), but one year later, women denied abortions were more likely to receive public assistance (76%) than women who had abortions (44%). At baseline, the same number had household incomes below the federal poverty line (66%); one year later, women who got abortions were less likely to be below the federal poverty line (56%) than women who were denied abortions (67%) At baseline, 45% received public assistance, two thirds had household incomes below the federal poverty level (FPL) and the average household size was 3.7. One year later, 86% of women denied an abortion were living with the baby; 11% had placed the baby for adoption. Women denied abortion were more likely to be receiving public assistance (76% vs. 44%) and have household income below the FPL (67% vs. 56%) than women who received an abortion. The proportion of women denied an abortion who were working full time was lower than among women who received an abortion (48% vs. 58%). “Turnaways who ultimately gave birth increased use of drugs other than marijuana compared to women in the Near Limit Abortion Group (p=.041), who did not increase use.” (Roberts SC, Rocca CH, Foster DG. Receiving versus being denied an abortion and subsequent drug use. Drug Alcohol Depend. 2013 Sep 23.)\n\n\n15.3.2.4 Example: Drinking age impact on mortality\n(Carpenter and Dobkin, The Effect of Alcohol Consumption on Mortality: Regression Discontinuity Evidence from the Minimum Drinking Age, American Economic Journal: Applied Economics 2009, 1:1, 164–182. Carpenter and Dobkin, The Minimum Legal Drinking Age and Public Health, JEP 2011)\n\n\n\n15.3.3 Interrupted time series\nExample: Marijuana legalization and police stops Christopher Ingraham, Legalized marijuana is making it harder for police to search your car, June 26, 2017, Washington Post Wonkblog, https://www.washingtonpost.com/amphtml/news/wonk/wp/2017/06/26/legalized-marijuana-is-making-it-harder-for-poli based on data from Stanford Open Policing Project, https://openpolicing.stanford.edu/findings/ Similar decreases were not seen in states that did not legalize marijuana.\n\n\n15.3.4 Differences in differences\nInstruments and sudden discontinuities aren’t always available to answer a research question. When they aren’t, analysis of natural experiments uses a differences-in-differences framework. Often, when people use the term “quasi-experiment”, they mean differences-in-differences. The classic book Quasi-Experimentation: Design & Analysis Issues for Field Settings by Thomas Cook and Donald Campbell (1979) uses the notation X to refer to an intervention and Oi to refer to an observation at time i. The subscript can be omitted if there is only one. The simplest form of a differences-in-differences study is a pre-post study with control group.\nUsing Cook and Campbell’s notation, a pre-post with control study would look like this: O1 X O2 O1 O2 Or there may be multiple pre- and/or post- observations: Pre T1 Pre T2 …. Post T1 Post T2 Post T3 …. Treatment Control O1 O2 X O3 O4 O5 O1 O2 O3 O4 O5 Ideally, the pre-treatment observations for the treatment and control groups line up, and diverge after the treatment. When the pre-treatment observations do not line up, the synthetic matching method can be used. Example: Minimum wage and unemployment In April 1992, NJ increased its minimum wage from $4.25 to $5.05, and PA did not change its minimum wage. Card and Krueger compared employment and other outcomes at fast-food restaurants in New Jersey and eastern Pennsylvania (across the Delaware River from NJ) before versus after the increase: in February and November 1992.5 Their data came from a telephone survey of 410 fast-food restaurants listed in the telephone white pages in February 1992. They found no decrease in employment and no increase in meal costs, suggesting that moderate increases in the minimum wage does not have a negative economic impact on consumers or restaurant employees. 5David Card and Alan Kreuger, Minimum Wages and Employment: A Case Study of the Fast Food Industry in New Jersey and Pennsylvania, AER, September 1994.\nNeumark and Wascher 2000 did a similar analysis using payroll data and contend that NJ’s minimum wage increase resulted in declining employment. They claimed that the telephone survey data used in Card and Krueger caused errors.6 After the 1996 federal minimum wage increase to $4.75, which affected PA but not NJ, Card and Krueger updated their study using the Neumark and Wascher data. They also tested the sensitivity of their model to specifications, such as which regions of Pennsylvania .7 6Neumark, David, and William Wascher. 2000. Minimum Wages and Employment: A Case Study of the Fast-Food Industry in New Jersey and Pennsylvania: Comment. American Economic Review, 90(5): 1362-1396. 7Card, David, and Alan B. Krueger. 2000. Minimum Wages and Employment: A Case Study of the Fast-Food Industry in New Jersey and Pennsylvania: Reply. American Economic Review, 90(5): 1397-1420.\n\n15.3.4.1 Sidebar: Alan Kreuger\nFor this crucial empirical work testing an economic theory with empirical evidence, David Card was awarded the Nobel Memorial Prize in Economics in 2021 (https://www.nobelprize.org/prizes/economic-sciences/2021/card/facts/). If Alan Kreuger had been still alive in 2021, he would shared the Nobel Memorial Prize according to Card, but in 2019, Kreuger died by suicide at age 58 (Noah, Timothy. “Tragedy Kept Alan Krueger From Claiming a Nobel Prize, but He’s Not Forgotten”. The New Republic.October 14, 2021).\nPresident Obama’s eulogy: “Over the weekend, America lost a brilliant economist, and many of us lost a dear friend. When I asked Alan Krueger to serve as my chief economist in the White House, he’d already had a stellar career inside and outside of government. He spent the first two years of my administration helping to engineer our response to the worst financial crisis in 80 years, and to successfully prevent the chaos from spiraling into a second Great Depression. During his tenure as the Chair of my Council of Economic Advisors, he helped us return the economy to growth and sustained job creation, to bring down the deficit in a responsible way, and to set the stage for wages to rise again.\nBut Alan was someone who was deeper than numbers on a screen and charts on a page. He saw economic policy not as a matter of abstract theories, but as a way to make people’s lives better. He believed that facts, reason, and evidence could make government more responsive, and his enthusiasm and curiosity was truly infectious. It’s part of what made him not only a great economist but a great teacher – someone who could make complicated subjects accessible and even fun. A landmark, real-world study on the positive impact of the minimum wage. His creation of the “Gatsby Curve” that illustrated the connection between concentrated wealth and social mobility between generations. A rollicking speech at the Rock and Roll Hall of Fame on how understanding the economics of rock and roll might help us solve one of his deepest concerns: rebuilding the middle class in a changing economy. Through it all, he had a perpetual smile and a gentle spirit – even when he was correcting you. That’s what made him Alan – a fundamentally good and decent man.\nMy thoughts today are with his wife, Lisa, their kids, Ben and Sydney, his many students and colleagues, and everyone who loved and will miss Alan Krueger.”\n\n\n15.3.4.2 Example: School desegregation\nIn 1952, US states took 4 stances towards racial segregation in schools: 17 states mandated racial segregation, 4 states allowed segregation, 16 states banned racial segregation, and 11 states had no law on the topic. After the 1954 case, Brown vs. Board of Ed, court orders to desegregate schools occurred in 1057 school districts on varying dates between 1954 and 1980. Legislation in 1964 (Civil Rights Act) and 1965 (Elementary & Secondary Education Act) spurred desegregation. The timing of the court orders can be considered arbitrary/random. Children attended desegregated schools for varying numbers of years: if their local school district desegregated after they were age 17, they were assumed to have attended segregated schools. Rucker computed various outcomes by number of years of desegregation.\n\n\n\n15.3.5 Synthetic matching\nMany times, a political unit will attempt a policy innovation that has never been tried elsewhere: e.g., Colorado and later Washington State legalizing marijuana, Oregon making pseudoephedrine only available by prescription to prevent methamphetamine manufacture (precursor laws). Researchers attempt to study these innovations with pre-post studies without control, but these studies are inconclusive.\nA Abadie, A Diamond, J Hainmueller. Synthetic control methods for comparative case studies: Estimating the effect of California’s Tobacco Control Program. Journal of the American Statistical Association. 2010; 105 (490), 493-505\nSynthetic matching is an attempt to add rigor to a differences in differences framework to allow causal inference from these situations. Abadie evaluated the impact of California’s Proposition 99 tobacco control program on smokingprevalence.8 Proposition99 increased cigarette taxes by 25 cents to fund antismoking projects and media campaigns, funded tobaco-related research, and triggered 140 clean air laws between 1989 and 2000 that banned smoking in workplaces, so that by 1994 more than 90% of workers were covered. Smoking rates and per capita cigarette smoking decreased.\nWithout synthetic matching, the effects of the tobacco control initiative are unclear. How much of the decrease in smoking is attributable to Proposition 99?\n\nIt’s impossible to know in a pre-post study.\nHowever, the synthetic control method offers a way forward. State were included for synthetic California if they did not have statewide anti-tobacco laws (excludes MA, FL, AZ, OR) or tobacco tax increases greater than 50 cents from 1989–2000 (excludes AK, HI, MD, MI, NJ, NY, WA), so they considered 38 remaining states. Their outcome was cigarette packs sold per capita, which is available from state tax data and doesn’t rely on self-report. They matched on the following predictors of smoking prevalence averaged over 1980–88: average retail price of cigarettes, per capita state personal income (logged), the percentage of the population age 15–24, and per capita beer consumption. They also included smoking consumption in 1975, 1980, and 1988, prior to prop 99. Synthetic California is a combination of Colorado (0.164), Connecticut (0.069), Montana (0.199), Nevada (0.234), and Utah (0.334). This table compares synthetic and actual California on the matching variables.\n\n\n\n\n\n\n\n\n\n\n\nReal California\nSynthetic California\nAverage of 38 control states\n\n\n\n\n\nLog (GDP per capita) (1980–88)\n10.08\n9.86\n9.86\n\n\n\nPercent ages 15–24 (1980–88)\n17.40\n17.40\n17.29\n\n\n\nRetail price pack of cigarettes (1980–88)\n89.42\n89.42\n87.27\n\n\n\nBeer consumption per capita (1984–88)\n24.28\n24.20\n23.75\n\n\n\nCigarette sales packs per capita 1988\n90.10\n91.62\n114.20\n\n\n\nCigarette sales packs per capita 1980\n120.20\n120.43\n136.58\n\n\n\nCigarette sales packs per capita 1975\n127.10\n126.99\n132.81\n\n\n\n\n\nTo make sure that they didn’t just choose outliers, they also compared the gap between synthetic California with actual California, with the gap between synthetic California and all 38 control states."
  },
  {
    "objectID": "chapt13.html#exercise",
    "href": "chapt13.html#exercise",
    "title": "15  Randomized experiments and quasi-experiments",
    "section": "15.4 Exercise",
    "text": "15.4 Exercise\nThis exercise is based on the paper Ornstein KA, et al. “The Use of Life-Sustaining Procedures in the Last Month of Life Is Associated With More Depressive Symptoms in Surviving Spouses.” J Pain and Symptom Management. 2017;53(2):178–187.\n\nWhat kind of data does the study use?\nWhat is the research question?\nWhat is the primary predictor of interest in this study? Define it briefly. If categorical or dichotomous, list the categories of the variable.\nWhich are the primary outcome(s) in this study?\nLooking at the first 3 columns of Table 3, identify some potential confounders of the relationship between the predictor and the outcome(s)? Explain in detail how these variables could cause a spurious connection between receiving life-sustaining procedures and depressive symptoms in surviving spouses.\nDoes matching balance the two groups: those who received life-sustaining procedures with those who did not?\nDo you think that the relationship is causal? Take a stance and support it."
  },
  {
    "objectID": "chapt14.html#prospective-cohort-studies-to-study-a-specific-exposure",
    "href": "chapt14.html#prospective-cohort-studies-to-study-a-specific-exposure",
    "title": "16  Cohort studies",
    "section": "16.1 Prospective Cohort Studies to study a specific exposure",
    "text": "16.1 Prospective Cohort Studies to study a specific exposure\n\n16.1.1 SARS and MERS cohort studies\nIn 2002, the SARS virus began in China, spreading to a few locations including Canada. People who were infected with SARS were successfully isolated, but some health care workers became ill. As a novel virus, this disease was not well-understood, so people who were infected with SARS were followed over years. These follow-up studies found that several years after illness, 30-40% of SARS patients had a new-onset mental illness of varying types, about 30-40% met criteria for chronic fatigue syndrome, and about 30-40% did not go back to work; these were non-mutually exclusive, so some people had more than one of these, and some people had none of these.\nChildren who had been infected with SARS had reduced aerobic capacity about 18 months after infection, but it was thought this was due to deconditioning rather than the disease. Patients who had been treated with steroids had femoral head necrosis, likely an effect of steroids rather than disease.\nIn 200x, the MERS virus emerged. Similar cohorts were formed of people who had been infected with MERS and followed for years.\nThese cohort studies were useful when Covid-19 emerged because they foreshadowed possible effects of Covid-19, such as long covid."
  },
  {
    "objectID": "chapt14.html#prospective-cohort-studies-to-study-a-specific-disease",
    "href": "chapt14.html#prospective-cohort-studies-to-study-a-specific-disease",
    "title": "16  Cohort studies",
    "section": "16.2 Prospective Cohort Studies to study a specific disease",
    "text": "16.2 Prospective Cohort Studies to study a specific disease\nCohort studies may also be chosen by demographic characteristic and disease-free status, not by exposure status.\nAt the start, no subjects have the outcomes of interest.\nFramingham Heart Study: 5209 residents of Framingham, MA in 1948 ages 30–62 without heart disease (including my late step-grandfather).\nNurses Health Study follows 117,000 women without cancer or CVD who were nurses in 1976 (including my aunt)\nWhitehall Studies (UK): Whitehall I studied 17,530 male civil servants 1967–77; Whitehall II studies 10,308 civil servants ages 35–55 (2/3 male) 1985–2012.\nMillennium Cohort Study will follow 150,000 military personnel for 21+ years during and after service, recruited in 3 panels beginning in 2001."
  },
  {
    "objectID": "chapt14.html#longitudinalpanel-studies",
    "href": "chapt14.html#longitudinalpanel-studies",
    "title": "16  Cohort studies",
    "section": "16.3 Longitudinal/panel studies",
    "text": "16.3 Longitudinal/panel studies\nSometimes referred to simply as longitudinal or panel studies because they aren’t chosen by exposure status. Economists refer to longitudinal studies as panel studies.\n\n16.3.1 Economics: Longitudinal/Panel Studies.\nNot designed to study health outcomes but may be used for these purposes.\nNational Longitudinal Study of Youth (NLSY79 and NLSY97). https://www.nlsinfo.org\nPanel Study of Income Dynamics (PSID since 1968), and similar studies in other countries. Available here https://www.ipums.org/\nMedical Expenditure Panel Survey (MEPS). Available here: https://www.ipums.org/\n\n\n16.3.2 Life course studies\nYouth and human development\nFragile Families and Child Wellbeing Study followed 5000 children born to mostly unmarried mothers in 1998–2000 at birth, and ages 1, 3, 5, and 9 years old. Available here: https://opr.princeton.edu/archive/\nNorthwestern Juvenile Project: 1800 youth enrolled between 1995–98 from Chicago justice system, still following 1644.\nNational Longitudinal Study of Adolescent Health (Add Health).\n1958 National Child Development Study or 1958 Birth Cohort Study: 17,000 people born in the UK in a single week in 1958.\nBirth to Twenty in South Africa studied 3273 individuals born during the 7 weeks after Nelson Mandela’s release from prison in February 1990.\nNational Children’s Study will follow 100,000 US children from before birth to age 21. A pilot study at 40 locations is currently in progress.\nWisconsin Longitudinal Study followed a cohort of men and women born in 1939 from high school graduation to the present.\nProject Talent: 440,000 high school students (grades 9–12) in 1960, 1965, 1971.\nMidlife in the US (MIDUS): 7000 middle-aged people in 1995-96 and 2006.\n\n\n16.3.3 Educational studies\nAll conducted by Institute for Educational Sciences https://ies.ed.gov/, and available free online.\nEducation Longitudinal Study (ELS) is a longitudinal study of 16,197 high school sophomores surveyed in 2002 and followed in 2004, 2006, and 2012. The main outcomes of interest are educational, family formation, and employment.\nECLS-B follows a cohort from birth until kindergarden, beginning in 2001, and includes family structure, prenatal care, and early infancy factors.\nNELS (high school students followed post-graduation), ECLS (Early Childhood Longitudinal Studies), BPS (Beginning Postsecondary Studies: high school graduates followed in first year of post-secondary studies for several years)."
  },
  {
    "objectID": "chapt14.html#studies-by-compiling-data",
    "href": "chapt14.html#studies-by-compiling-data",
    "title": "16  Cohort studies",
    "section": "16.4 Studies by compiling data",
    "text": "16.4 Studies by compiling data\nSome epidemiology studies combine different sources of data, rather than using data collected in a unified way.\n\n16.4.1 Disadvantages of using an external comparison group\nChlamydia prevalence among men, by race/ethnicity, selected populations. This table illustrates how the prevalence of a disease (chlamydia) may vary when samples are taken from different, non-comparable populations.\n\n\n\n\n\n\n\n\n\nData source (years)\nBlack race\nWhite race\nHispanic ethnicity\n\n\n\n\nNHANES (1999–2000; ages 14–39)\n5.3\n1.5\n3.1\n\n\nAdd Health (2001–02; ages 18–26)\n11.1\n1.4\n7.2\n\n\nNational Job Training Program (2003–04; ages 16–24)\n13.0\n3.1\n5.7\n\n\nMSM Prevalence Monitoring Project (2005; ages 15–80)\n7.0\n6.0\n6.0\n\n\n\nSource: Satterwhite, Joesoef, Datta, Weinstock. Estimates of Chlamydia trachomatis Infections Among Men: United States, Sexually Transmitted Diseases, 2008: 35:S3-S7.\nPopulations may not actually be comparable.\nPopulations may differ in exposures other than the exposure of interest.\nMeasurement of exposure or outcome may differ between the two studies.\nIf significant proportion of the comparison group also has the risky exposure, results are biased, just as if the control group in an experiment is given the treatment."
  },
  {
    "objectID": "chapt14.html#exercise",
    "href": "chapt14.html#exercise",
    "title": "16  Cohort studies",
    "section": "16.5 Exercise",
    "text": "16.5 Exercise\nRead the abstract and look at the tables/figures for the attached study, DeBoer MD, Scharf RJ, Demmer RT, “Sugar-Sweetened Beverages and Weight Gain in 2- to 5-Year-Old Children”, Pediatrics, 2013;132(3):413–420. Do not read the paper itself.\n\nThe authors’ hypothesis is that sugar-sweetened beverages (SSBs) cause children to become overweight due to excess energy consumption. That could be true, but it could also be a spurious association caused by other factors — that is, internal validity could be compromised. Before reading the study, what do you think could be going on? That is, what could be causing the association between SSBs and childhood overweight other than the SSBs themselves?\nLook at the tables and figures. Do any of the tables/figures support your initial thoughts about potential threats to internal validity? Do they spark new ideas?\nBased just on the tables and figures, which approaches do the authors use to avoid con- founding?\nDescribe what Table 2 shows in your own words. What is the purpose of the three models? What happens as the analysis goes from Model 0 to Model 1 to Model 2, within each age?\nBased on Table 2, does the association between overweight/obesity status and SSB hold up after analyses?\nDo you think that the analysis in Table 2 adequately adjusts for each of the covariates in the respective models? Explain why or why not.\nDescribe in your own words what Figure 1 demonstrates. What do the * mean? What do the little Ts above the bars mean? Does Figure 1 demonstrate a dose-response rela- tionship?\nWhat’s the difference between Tables 2 and 3? What’s the advantage of each type of analysis?"
  },
  {
    "objectID": "chapt15.html#case-control-studies",
    "href": "chapt15.html#case-control-studies",
    "title": "17  Case-control studies",
    "section": "17.1 Case-control studies",
    "text": "17.1 Case-control studies\nAs we discussed in the previous chapter, cohort studies group by exposure. Case-control studies group by outcome: cases have the outcome and controls lack the outcome. Usually this outcome is a disease, but this research design can be used for any outcome with the same advantages of any case-control study. For example, I wanted to evaluate health conditions associated with community college and 4 year college degree completion. Participants were grouped over outcome: college graduation because little was known about which health conditions are associated with graduation.\nCase-control studies can be used to study outcomes that take a long time to emerge.\nAdvantages and disadvantages of case-control studies • More efficient for diseases with long latency periods: no need to wait a long time to find a case.\n• More efficient for rare diseases. No need to screen many inidividuals to find a case.\n• Less efficient for rare exposures: need to screen many individuals to find the exposure of interest. (“As a rule of thumb, cohort designs are more efficient in settings in which the incidence of outcome is higher than the prevalence of exposure.” — Lancet 2002)\n• Some case-control studies attempt a fishing expedition: finding factors associated with a poorly understood disease or condition. In this case, need to be careful about multiple comparisons.\nCase-control can mimic cohort study if populations drawn from same underlying population.\nGenome-wide association studies (GWAS) identify genes associated with diseases.\nCase-case or case-only studies: compare different variants of the same disease. Gillison et al, Evidence for a Causal Association Between Human Papillomavirus and a Subset of Head and Neck Cancers. Journal of the National Cancer Institute, Vol. 92, No. 9, May 3, 2000"
  },
  {
    "objectID": "chapt15.html#nested-case-control-studies",
    "href": "chapt15.html#nested-case-control-studies",
    "title": "17  Case-control studies",
    "section": "17.2 Nested case-control studies",
    "text": "17.2 Nested case-control studies\nIn nested case-control studies, controls and cases are chosen from a cohort study or longitudinal dataset. This nested approach has several advantages. First, the data already exist, so all advantages of using secondary data apply to nested case-control studies: low cost, quick access, and high quality. Second, the data are longitudinal, allowing clear temporal ordering of events; longitudinal datasets can potentially cover long time periods, allowing evaluation of distal exposures, such as good information about family backgrounds, childhood, and adolescence. Tnird, the controls and cases were chosen from the same population and given the same survey instruments, biomarker tests, and other measurements.\nHowever, the nested approach has disadvantages as well. First, the disadvantages of secondary data apply to nested case-control studies: the data may lack desired information relevant to the disease or outcome. Second, the disadvantages of long-term longitudinal studies may also apply: the baseline was designed so long ago that the measures of the earliest exposures may not follow the current conventions or they may not have collected measures we consider important now: these disadvantages apply for any study over a long time period and they are intrinsic to long-term longitudinal studies. Finally, if there is subjectivity in classifying participants’ outcomes, subjectivity could cause researchers to judge outcomes according to exposure status; in the case of most datasets that already exist, these subjective decisions do not occur.\nFor example, the National Longitudinal Study of Youth 1979 has followed people from adolescence through age 50 or older. These data were collected by the Bureau of Labor Statistics, which did not initially collect much health information, but later years included a great deal of health information.\nCautions that apply in all studies Make sure that population and sample are well-defined, uniform, and chosen ahead of time. While obvious, it’s easier said than done. Choosing cases As with cohort studies, choose incident (new) cases to be sure that diagnosis is uniform. Choosing controls Choose controls from the same population as cases. Controls represent people at risk of be- coming cases. • If controls and cases are chosen from different population, there’s a risk of selection bias. E.g., controls might not go to the same clinician if they got the disease. • Ideal to choose controls who have tested negative for the disease with the same provider as the cases have, so they are from the same population and have the same indications that lead the cases to get tested. Asymptomatic diseases are best because all cases will have been tested, and therefore from same population as controls who were also tested. • Can choose controls from same geographic area of the cases: e.g., physical neighbors, friends/relatives. Used to be able to identify controls from random-digit dialing in same geographic area, but less useful without landlines. • Hard to determine whether hospitals come from the same population as cases. Different departments/diseases within the same hospital may have different catchment areas. Choose controls independently of the exposure of interest. • Cases/controls should ideally be determined by people who do not know the subject’s exposure status, or who do not know the study’s hypothesis. • If cases are chosen after exposure is known, there is a risk of selective misclassification of cases. The clinician making diagnosis knows the participant’s exposure status and is more likely to diagnose the disease (e.g., aspirin and Reye’s syndrome.) • If controls have a disease that is also related to the exposure, bias towards the null. Determining exposure status • Questionnaires/interviews about past exposures: – Interviewers could bias the data collection if they are aware of the hypothesis or case/control status of participants. – Can use memory prompts such as pictures of all oral contraception brands and a blank calendar grid (Schulz and Grimes 2002). • Administrative records, lab records Rosenbaum 3 – Desired information not always available. • Some medical quantities do not change (e.g., blood type, lead in teeth), so can be measured at the time of the study. • Non-differential measurement error — i.e., measurement error that doesn’t vary between control and cases — does not introduce bias into the study. For instance, both cases and controls may have a hard time remembering the past exposures, but there is no difference in quality of memory between the cases and the controls. • Differential measurement error creates information bias, such as if cases remember expo- sures differently than controls do. Mothers of babies with birth defects may recall their exposure status differently than mothers of babies without birth defects.\nMeasuring outcomes Loss-to-follow-up does not bias results if it occurs non-differentially: in both exposed and unexposed groups. Loss-to-follow-up represents a bias when comparing a group with the general population, which does not have this attrition. Mortality can be observed from National Death Index. Scandinavia has a cancer registry, so can observe outcomes other than death for cancer patients, but other countries use death from cancer rather than other outcomes because that’s the data available to them.\nPrevalence vs. Incidence Need to observe a group for a period of time to observe incidence. Prevelance is easier to measure: can measure in cross-sectional study, but may under-estimate prevalence of traits that could cause someone not to be in the sample. e.g., an impair- ment that would cause someone to terminate their employment.\nObserving outcomes too soon after an exposure measurement can lead to reverse causality: e.g., colon cancer and cholesterol levels; brain tumors and anti-seizure medication.\nReducing confounding Studies use either matching or regression/stratification methods.\nExamples • Why exactly would this situation pose a problem? Spell out the problem. Suppose investigators selected individuals with myocardial infarction from the cardiology ward of a large, city hospital as cases, but identified people without infarction from the emergency medicine ward of the same hospital as controls. Bias might result. The cardiology ward is used as a referral centre for the entire state, whereas the emergency medicine department primarily serves only the city. Unfortunately, the exposure history for patients from the city would not usually accurately reflect that of patients statewide. For example, the exposure of interest — eg, a new blood pressure drug — might not be available to patients in outlying areas of the state but be commonly prescribed in the city. (Schulz and Grimes 2002)\n• Direction of bias = ? Assume that this new antihypertensive drug causes drowsiness and slows reac- tion time. Such side- effects might lead to automobile accidents, with injured drivers entering the emergency medicine department. Thus, the investigator’s control group would include an abnormally high proportion of individuals ex- posed to the new antihypertensive, a biased comparison with the case group. (Schulz and Grimes 2002)\n• Direction of bias = ? a case-control study of whether non-steroidal anti-inflammatory drugs (NSAIDs) prevent colorectal cancer. The study measures previous NSAID use by patients admitted to hospital with (cases) and without (controls) colorectal cancer. If the control group came from the rheumatology service, then the study would be biased, since individuals with arthritis use NSAIDs more often than do the gen- eral population from which the cases were chosen. Such a high level of NSAID use in controls would result in a spuriously low risk (odds ratio) calculation. Al- ternatively, if the control group came from the gastroenterology service, where many ulcer patients had been advised by their doctors to avoid NSAIDs, then that control group might yield a low level of NSAID use and a spuriously high risk (odds ratio) calculation. (Schulz and Grimes 2002)\n• Direction of bias = ? the researchers compared cases of AIDS diagnosed in San Francisco, CA, USA, between 1983 and 1984 with two HIV-uninfected control groups. One control group included individuals who attended a clinic for sexually transmitted dis- eases (STD), and the other included people identified from the neighbourhoods of the cases. The investigators compared the risk of AIDS in individuals with more than 100 sexual partners with that in people with no to five sexual part- ners. The resulting odds ratios were 2.9 with STD clinic controls, but 52.0 with neighbourhood controls. The magnitude of this difference shows the potential for huge biases due to selection of improper control groups. In this study, con- trols from the STD clinic proved inappropriate, since their selection was not independent of exposure (more than 100 sexual partners). Acquisition of STDs is associated with number of sexual partners, thus these controls generated a highly biased odds ratio estimate. (Schulz and Grimes 2002)\n• Direction of bias = ? In a Swedish study, investigators examined the potential link between induced abortion and later development of breast cancer. They gathered information about exposure (previous abortion) from cases and controls by means of per- sonal interviews and by looking through national medical records. When interviewed, fewer controls admitted to having had an abortion than was evident in vital statistics. This discrepancy did not arise among cases. (Schulz and Grimes 2002)"
  },
  {
    "objectID": "chapt15.html#example-genome-wide-association-study-of-schizophrenia",
    "href": "chapt15.html#example-genome-wide-association-study-of-schizophrenia",
    "title": "17  Case-control studies",
    "section": "17.3 Example: Genome-wide association study of schizophrenia",
    "text": "17.3 Example: Genome-wide association study of schizophrenia\nThe Schizophrenia Working Group of the Psychiatric Genomics Consortium published a paper in Nature identifying 108 genes associated with schizophrenia in a case-control study of 36,989 cases and 113,075 controls. The author list filled a full column of text from 208 instutional affiliations. Despite being an intensive genetics research project, it has elements common to epidemiologic studies: they created an index of risk called the risk profile score, estimated odds ratio of schizophrenia for each level of predicted risk, and estimated the predictive power of the risk profile score (area under the curve)."
  },
  {
    "objectID": "chapt15.html#exercise",
    "href": "chapt15.html#exercise",
    "title": "17  Case-control studies",
    "section": "17.4 Exercise",
    "text": "17.4 Exercise\nExercise: Concussion in Adolescence and Risk of Multiple Scle- rosis Montgomery S, Hiyoshi A, Burkill S, Alfredsson, L, Bahmanyar S, Olsson T. Concussion in Adolescence and Risk of Multiple Sclerosis. Annals of Neurology. 2017;82:554561\n\nThe study never says what kind of study design they use. What kind of study is this? How can you tell?\nWhy did the authors choose that type of study design?\nThe authors used prospectively recorded data in their study. What issue have the re- searchers avoided by using prospectively recorded data? Why might that issue normally affect the study design? Given that they are using prospectively recorded data, what is the more specific name of the type of study design?\nThe researchers only included individuals who were diagnosed with multiple sclerosis (MS) while currently resident in Sweden. Why is that?\nThe researchers adjusted for broken limb bones in childhood (ages 0–10 years) and adoles- cents (ages 11-20 years). What concern were they addressing by paying special attention to broken bones?\nThe researchers matched each of the individuals diagnosed with multiple sclerosis (MS) with 10 people without MS by age, sex, region, and age/vital status at MS diagnosis.\n\n\nWhy may the researchers have chosen to match on these factors?\nDoes matching on these factors reduce potential confounding significantly, or might confounding remain?\nWhy might the researchers have chosen to match 10 controls to each case, as opposed to a smaller number?\n\n\nWhat is the advantage for the study that concussions were measured in adolescence, as opposed to a later period?\nWhat evidence is presented that is consistent with the hypothesis that concussions in adolescents increase the risk of multiple sclerosis?"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "18  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]