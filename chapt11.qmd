# Example data analysis in YRBS

## Summary of statistical methods

Recall the table from chapter 1 for summarizing data from categorical (C) and quantitative (Q) variables. The types of analysis depend on the types of data.

We divide data into categorical (C) and quantitative (Q). The types of analysis depend on the types of data.

Categorical variables can further be categorized as ordinal or non-ordinal.

| Variable type          | Outcome Quantitative | Outcome Categorical |
|:-----------------------|:---------------------|:--------------------|
| Predictor quantitative | $Q \rightarrow Q$    | $Q \rightarrow C$   |
| Predictor categorical  | $C \rightarrow Q$    | $C \rightarrow C$   |

The displays and analysis types are not meant to correspond to each other.

This table is not meant to be a cookbook. This table demonstrates that some types of analysis definitely do not make sense for some types of data. E.g., scatterplot cannot be used instead of 2x2 table.

| Data                                   | Display                                | Analysis                                    |
|:------------------|:---------------------------------|:------------------|
| $Q \rightarrow Q$                      | scatterplots (xyplot)                  | linear regression (lm)                      |
| $Q \rightarrow C$ or $C \rightarrow Q$ | Box and whisker plot (bwplot)          |                                             |
|                                        | dotplot (w or w/o confidence interval) |                                             |
| Categorical variable is binary         | stratified density plot (densityplot)  | t-test, Wilcoxon                            |
| Categorical variable is binary         |                                        | Logistic regression glm( , family=binomial) |
| Categorical variable is not binary     |                                        | test for trend (if ordinal): e.g., Cuzick's |
| Categorical variable is not binary     |                                        | Tukey's HSD (anova followesd by TukeyHSD)   |
| Categorical variable is not binary     |                                        | transform to binary and use above methods   |
| $C \rightarrow C$                      | Contingency table (tally)              | chi-square test (chisq.test)                |
|                                        |                                        | Kruskal-Wallis test (kruskal.test)          |
|                                        |                                        | pairwise chi-square test                    |



## Logistic regression
The regression type that you use is determined by your outcome variable, not by your predictors. Many outcome variables are binary/dichotomous: that is, they take only the values 0 or 1 (or FALSE and TRUE). You can model binary outcome variables with four different methods: logistic regression, Poisson regression, ordinary linear regression, and probit regression. Logistic
regression is most commonly used in public health.

The coefficients in a logistic regression are log odds ratios; many statistical programs will
transform them automatically for you. The predicted values from a logistic regression are the
estimated probabilities of the event occurring.

### Variable selection and coding for data analysis
There are many guidelines for identifying covariates for data analysis. Here are some ideas:
• Important demographic features: socioeconomic status, race/ethnicity, gender, age. These may be important to control for, even if non-significant.
• Variables predicted to be potential confounders by relevant theories: e.g., health behavior theories often include a construct relevant to self-efficacy to carry out a health behavior.
• Variables used as control variables in other papers can suggest both which theories are important and empirically which variables are important.

### Examples of logistic regression in YRBS
We start out by defining necessary variables. I rename everything so that I can read the output more easily. I also change factors to a scale that makes sense. For all varaibles, consult the codebook. Each variable is listed at least twice: first, to show the wording of the question and the answer choices followed by a dichotomized version (if applicable); second, to show the distribution of the variable (how many respondents gave each answer) and the coding (e.g., 1 = yes and 2 = no).
For creating new variable:

```{r, eval=F}
# Setting new variable to be true if old variable is 1 and 0 otherwise
yrbs$newvariable=yrbs$oldvariable==1
# check it did what you expected tally(newvariable ~ oldvariable, data=yrbs)
```


Load necessary libraries and data. We are using a new library here called arm because it displays regression analysis results compactly. Check data has expected number of variables (columns) and observations (rows).

We use the Stata format because it reliably keeps the labels.
```{r, message=F}
library(readstata13)
library(mosaic)
library(arm)
yrbs=read.dta13("yrbs2019.dta")
dim(yrbs)
```


Age is originally on a scale from 1 to 7, but I express it as the actual age in years.

```{r}
tally(~Q1, data=yrbs)
yrbs$age = as.numeric(yrbs$Q1)+11
tally(Q1~age, data=yrbs)
```

```{r}
yrbs$female= yrbs$Q2=="Female"
tally(Q2~female, data=yrbs)
```


```{r}
# Define race/ethnicity categories
yrbs$black=yrbs$raceeth=="black or african american"
tally(black ~ raceeth, data=yrbs)
yrbs$hispanic=(yrbs$raceeth=="hispanic / latino" | yrbs$raceeth=="multiple - hispanic")
tally(hispanic ~ raceeth, data=yrbs)
yrbs$white=yrbs$raceeth=="white"
yrbs$asian=yrbs$raceeth=="asian"
yrbs$multi.nonhispanic=yrbs$raceeth=="multiple - non-hispanic"
```

Grade in school. Set grade to missing if grade is 13.

```{r}
yrbs$grade=as.numeric(yrbs$Q3)+8
is.na(yrbs$grade)=yrbs$grade==13
tally(~grade, data=yrbs)
```


```{r}
yrbs$age.for.grade=yrbs$age-yrbs$grade
tally(~age.for.grade, data=yrbs)
yrbs$appropriate.age.for.grade=yrbs$age.for.grade<=6
tally(appropriate.age.for.grade ~age.for.grade, data=yrbs)
```

Wearing a seatbelt never/rarely

```{r}
yrbs$rarely.seatbelt=yrbs$QN8==1
tally(rarely.seatbelt ~ Q8 , data=yrbs)
```

```{r}
yrbs$msm = (yrbs$Q65=="Males" & yrbs$female==0)
yrbs$wsw = (yrbs$Q65=="Females" & yrbs$female==1)
yrbs$same.sex.only= ( yrbs$msm | yrbs$wsw )
yrbs$same.sex= ( yrbs$same.sex.only | yrbs$Q65=="Females and males")
tally(same.sex ~ Q65, data=yrbs)
```


```{r}
yrbs$glb=yrbs$Q66=="Gay or lesbian" | yrbs$Q66=="Bisexual"
tally(glb ~ Q66, data=yrbs)
```
We also think that sexual orientation could be related. Define variables for which sex respondents have had sex with (MSM = males who have sex with males, WSW = women who have sex with women), and their sexual orientation. Note that MSM/WSW variables are associated with the predictor of number of sexual partners, so it’s problematic to use them as covariates.

```{r}
yrbs$glbq=yrbs$Q66=="Gay or lesbian" | yrbs$Q66=="Bisexual" | yrbs$Q66=="Not sure"
tally(glbq ~ Q66, data=yrbs)
```

```{r}
yrbs$any.sports.team=yrbs$QN82==1
tally(any.sports.team ~ Q82, data=yrbs)
```


## Strength training and sexual partners
Strength training and number of sexual partners
Our main predictor and outcome variables are number of sexual partners and days of strength training.

### Define variables


```{r}
yrbs$num.partners=as.numeric(yrbs$Q60) - 1
tally(num.partners ~ Q60, data=yrbs)
```


```{r}
yrbs$days.strength.training=as.numeric(yrbs$Q95) - 1
tally(Q95~days.strength.training, data=yrbs)
yrbs$any.strength.training=yrbs$days.strength.training >= 1
tally(Q95~any.strength.training, data=yrbs)
```


### Crude odds ratio



Evaluate whether strength training is associated with number of sexual partners. The first model estimates the crude odds ratio and its p-value. The second model estimates the adjusted odds ratio, adjusting for age, gender, and sports team participation.

```{r}
model0=glm(any.strength.training ~ num.partners, family="binomial", data=yrbs)
cbind(exp(coef(model0)), exp(confint(model0)))
```

### Adjusted odds ratio


```{r}
model1=glm(any.strength.training ~ num.partners + age + female + any.sports.team + any.sports.team*female + glb + glb*female , family="binomial", data=yrbs)
display(model1, detail=T)
cbind(exp(coef(model1)),exp(confint(model1)))
```


The crude odds ratio and 95% confidence interval for the association between number of sexual partners and engaging in any strength training is 1.03 (1.01, 1.06), and the adjusted odds ratio is 1.04 (1.01, 1.07), adjusting for age, sex, sexual orientation, and sports team participation. We can regard the coefficients on these control variables as nuisance parameters.
We can evaluate for effect modification by gender for both our main effect.

```{r}
model2=glm(any.strength.training ~ num.partners + age + female + any.sports.team + any.sports.team*female + glb + glb*female + num.partners*female, family="binomial", data=yrbs)
display(model2, detail=T)
cbind(exp(coef(model2)),exp(confint(model2)))
```



There is much effect modification, so we may prefer to create separate models for males and females.


```{r}
model2f=glm(any.strength.training ~ num.partners + age
+ any.sports.team + glb , family="binomial", data=yrbs, subset=female==1)
display(model2f, detail=T)
cbind(exp(coef(model2f)),exp(confint(model2f)))
model2m=glm(any.strength.training ~ num.partners + age + any.sports.team + glb , family="binomial", data=yrbs, subset=female==0)
display(model2m, detail=T)
cbind(exp(coef(model2m)), exp(confint(model2m)))
model1=glm(num.partners ~ days.strength.training + female + age + any.sports.team + glb, data=yrbs, family=poisson)
summary(model1)
```


### Example: asthma and smoking

Asthma and smoking in the past month
This analysis is based on a past student’s project, evaluating the association between asthma and smoking. The student wanted to evaluate whether males and females have different asso- ciations. They also thought that being older than the typical student in their grade may be a potential confounding factor. Here’s the start of an analysis.

Has a doctor or nurse ever told you that you have asthma?

```{r}
yrbs$asthma=yrbs$Q87=="Yes"
tally(asthma ~ Q87, data=yrbs)

yrbs$pastmonth_smoking=yrbs$QN32==1
tally(pastmonth_smoking ~ Q32, data=yrbs)


tally(asthma ~ pastmonth_smoking, data=yrbs, useNA="no", margins=T, format="percent")
chisq.test(tally(asthma ~ pastmonth_smoking, data=yrbs))
```


```{r}
model1=glm(pastmonth_smoking ~ asthma, data=yrbs, family=binomial)
display(model1, detail=T)
cbind(exp(coef(model1)),exp(confint(model1)))

model2=glm(pastmonth_smoking ~ asthma  + female +age + appropriate.age.for.grade, data=yrbs, family=binomial)
display(model2, detail=T)
cbind(exp(coef(model2)),exp(confint(model2)))
```


1. How do you interpret the bivariate results? Which direction would you report? 

2. How would you report and interpret the crude odds ratio?

3. How would you report and interpret the adjusted odds ratio?

4. What information would you put into a table of the logistic regression results?



### Example: suicidal ideation and grades in school


```{r}
yrbs$suicidal.ideation=yrbs$Q26=="Yes"
tally(suicidal.ideation ~ Q26, data=yrbs)
```


```{r}
yrbs$grades=yrbs$Q89
tally(grades ~ Q89, data=yrbs)
```
is.na(yrbs$grades) = yrbs$Q89=="None of these grades"



```{r}
tally(suicidal.ideation ~ grades, data=yrbs, format="percent")
plot(tally(suicidal.ideation ~ grades, data=yrbs, format="percent")[1,],
        type="b", ylab="Percent with suicidal ideation", ylim=c(0,100),
        axes=F, xlab="Grades in school")
axis(2)
axis(1, at=1:8, labels=c("As", "Bs", "Cs", "Ds", "Fs", "None", "Unsure", "Missing"))
```



```{r}
model1=glm(suicidal.ideation ~ grades, data=yrbs, family=binomial)
display(model1, detail=T)
cbind(exp(coef(model1)),exp(confint(model1)))
```


```{r}
model2=glm(suicidal.ideation ~ grades + female + age+ appropriate.age.for.grade, data=yrbs, family=binomial)
display(model2, detail=T)
cbind(exp(coef(model2)),exp(confint(model2)))
```


1. How do you report the bivariate results?
2. How would you report and interpret the crude odds ratio(s)?
3. How would you report and interpret the adjusted odds ratio(s)?
4. What information would you put into a table of the logistic regression results?


For a visual data display (not necessary for the project), you can display the multivariate results visually as adjusted odds ratios with or without confidence intervals. Andrew Gelman calls the data display “the secret weapon.”

```{r}
plot(exp(coef(model2))[2:5], ylab="OR", type="b", axes=F, xlab="Grades",
        ylim=c(1, 6))
abline(h=1, lty=2)
axis(2)
axis(1, at=1:4, labels=c("Mostly Bs", "Mostly Cs", "Mostly Ds", "Mostly Fs"))
```



To show the confidence intervals, we need another library, and we put the confidence intervals into a new variable to save on computational time. It may be helpful context to tell the viewer how many participants are in each category. The symbol
n tells R to insert a new line.

```{r, warning=F, message=F}
library(gplots)
ci=exp(confint(model2))
plotCI(exp(coef(model2))[2:5], li=ci[2:5,1], ui=ci[2:5,2], ylab="OR", type="b",
        axes=F, xlab="Grades", ylim=c(1, 7), pch=20, gap=0)
abline(h=1, lty=2)
axis(2)
axis(1, at=1:4, labels=c("Mostly Bs\n(n=5660)", "Mostly Cs\n(n=3031)",
"Mostly Ds\n(n=563)", "Mostly Fs\n(n=245)"), tick=F)
```


How do you interpret these findings? Is it more likely that poor grades cause suicidal ideation, that suicidal ideation causes poor grades, or that a third variable is responsible?
